[["index.html", "ENGE 5714 Course Notes 2021 Chapter 1 Prerequisites", " ENGE 5714 Course Notes 2021 A. Katz 2021-02-04 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandocs Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. "],["intro.html", "Chapter 2 Week 1", " Chapter 2 Week 1 In week one we just reviewed some of the materials from the fall semester. By the end we discussed R and RStudio, but this first week was primarily about getting to know each other and the outline of the course. "],["week-2-intro-stats-data-distributions-intro-r-rstudio.html", "Chapter 3 Week 2 - Intro stats, Data &amp; Distributions, Intro R &amp; RStudio 3.1 Very basics 3.2 Getting your R environment set up 3.3 Reading in data 3.4 Exploring the data 3.5 Plotting data", " Chapter 3 Week 2 - Intro stats, Data &amp; Distributions, Intro R &amp; RStudio Here is a review of existing methods. 3.1 Very basics x &lt;- seq(1:10) y &lt;- 2* x + 3 plot(x, y) 3.2 Getting your R environment set up One of the first things you will have in any script or .rmd file is a section to load all the libraries that you use in that script. You can install a library by using the install.packages() function, for example: install.packages(\"tidyverse\"), install.packages(\"janitor\"), and install.packages(\"psych\") with this installed, you can then load the package using the library() function library(tidyverse) ## -- Attaching packages ------------ tidyverse 1.3.0 -- ## v ggplot2 3.3.2 v purrr 0.3.4 ## v tibble 3.0.3 v dplyr 1.0.0 ## v tidyr 1.1.0 v stringr 1.4.0 ## v readr 1.3.1 v forcats 0.5.0 ## -- Conflicts --------------- tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(janitor) ## Warning: package &#39;janitor&#39; was built under R version 4.0.3 ## ## Attaching package: &#39;janitor&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## chisq.test, fisher.test library(psych) ## ## Attaching package: &#39;psych&#39; ## The following objects are masked from &#39;package:ggplot2&#39;: ## ## %+%, alpha 3.3 Reading in data A good first step is to check which directory you are working in with the getwd() function getwd() You can also check which files are in that directory with list.files(). If you notice that the file you are looking for is not there, then you can use setwd() to change your working directory setwd(\"./Week 2/\") After that, make sure you have switched to the correct working directory getwd() and then list.files() Assuming you have directed yourself to the correct place, you can now read in the file(s) that you want to be working with. prior_survey &lt;- read_csv(&quot;ENGE_5714_2021_pre_survey.csv&quot;) ## Parsed with column specification: ## cols( ## .default = col_character(), ## student_id = col_double() ## ) ## See spec(...) for full column specifications. 3.4 Exploring the data Take a look at the csv prior_survey ## # A tibble: 24 x 49 ## student_id `I have taken a~ `I am intereste~ `I know what a ~ ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Somewhat disagr~ Somewhat agree Strongly disagr~ ## 2 2 Strongly disagr~ Neither agree n~ Somewhat agree ## 3 3 Strongly disagr~ Somewhat agree Somewhat agree ## 4 4 Somewhat disagr~ Strongly agree Strongly disagr~ ## 5 5 Somewhat agree Strongly agree Somewhat agree ## 6 6 Somewhat disagr~ Somewhat agree Somewhat disagr~ ## 7 7 Strongly disagr~ Somewhat agree Strongly disagr~ ## 8 8 Somewhat agree Somewhat agree Somewhat agree ## 9 9 Strongly disagr~ Strongly agree Somewhat agree ## 10 10 Neither agree n~ Strongly agree Somewhat agree ## # ... with 14 more rows, and 45 more variables: `I know what a type II error ## # is` &lt;chr&gt;, `I know what a (statistical) confidence level is` &lt;chr&gt;, `I know ## # what a p value is` &lt;chr&gt;, `I know what p-hacking means` &lt;chr&gt;, `I know what ## # statistical power means` &lt;chr&gt;, `I have heard of frequentist statistics ## # before` &lt;chr&gt;, `I have heard of Bayesian statistics before` &lt;chr&gt;, `I have ## # heard the term &quot;parametric statistics&quot; before` &lt;chr&gt;, `I have heard the ## # term &quot;non-parametric statistics&quot; before` &lt;chr&gt;, `I know what a histogram ## # is.` &lt;chr&gt;, `I know what a probability distribution is.` &lt;chr&gt;, `I know ## # what a random variable is.` &lt;chr&gt;, `I know what a probability distribution ## # function is.` &lt;chr&gt;, `I know what a cumulative distribution function ## # is.` &lt;chr&gt;, `I know what the expectation of a random variable is.` &lt;chr&gt;, ## # `I know how to calculate the variance of a random variable.` &lt;chr&gt;, `I know ## # what a z score is.` &lt;chr&gt;, `I know how to calculate the correlation between ## # two variables.` &lt;chr&gt;, `I know how to interpret the correlation coefficient ## # between two variables` &lt;chr&gt;, `I have heard of linear regression` &lt;chr&gt;, `I ## # know how to run a linear regression (in some software...or by hand, if I&#39;m ## # feeling wild).` &lt;chr&gt;, `I know how to interpret a linear ## # regression.` &lt;chr&gt;, `I have heard of multiple regression` &lt;chr&gt;, `I know ## # how to perform a multiple regression` &lt;chr&gt;, `I know how to interpret a ## # multiple regression` &lt;chr&gt;, `I have heard of logistic regression.` &lt;chr&gt;, ## # `I understand when to use a logistic regression.` &lt;chr&gt;, `I know how to ## # interpret the results of a logistic regression` &lt;chr&gt;, `I have heard of ## # t-tests` &lt;chr&gt;, `I have performed a t-test before` &lt;chr&gt;, `I know how to ## # interpret the results of a t-test` &lt;chr&gt;, `I have heard of Analysis of ## # Variance.` &lt;chr&gt;, `I understand when to run an Analysis of Variance ## # (ANOVA)` &lt;chr&gt;, `I know how to interpret the results from an ANOVA` &lt;chr&gt;, ## # `I have heard of a chi-square test` &lt;chr&gt;, `I have used a chi-square test ## # before` &lt;chr&gt;, `I know how to interpret the results of a chi-square ## # test` &lt;chr&gt;, `I have heard of cluster analysis before` &lt;chr&gt;, `I have used ## # cluster analysis before` &lt;chr&gt;, `I know how to interpret the results of a ## # cluster analysis` &lt;chr&gt;, `I have heard of factor analysis (either ## # exploratory or confirmatory)` &lt;chr&gt;, `I have used factor analysis (either ## # exploratory or confirmatory)` &lt;chr&gt;, `I know how to interpret the results ## # of a factor analysis (either exploratory or confirmatory)` &lt;chr&gt;, `I ## # already have R and Rstudio downloaded to my computer.` &lt;chr&gt;, `I have used ## # R before` &lt;chr&gt; Next, try cleaning the column names with clean_names() from the janitor package. prior_survey &lt;- prior_survey %&gt;% clean_names() # from janitor package prior_survey$`I have heard the term &quot;non-parametric statistics&quot; before` ## Warning: Unknown or uninitialised column: `I have heard the term &quot;non-parametric ## statistics&quot; before`. ## NULL table(prior_survey$i_have_taken_a_quantitative_research_methods_course_before) ## ## Neither agree nor disagree Somewhat agree ## 2 5 ## Somewhat disagree Strongly agree ## 5 2 ## Strongly disagree ## 10 3.5 Plotting data There are multiple ways to plot data. Focusing on using ggplot, here are two. The first way passes the prior_survey dataframe explicitly to ggplot ggplot(data = prior_survey, mapping = aes(x = i_know_what_a_type_i_error_is)) + geom_bar() + coord_flip() The second way does this implicitly, using the pipe operator. Note that the results should be the same. prior_survey %&gt;% ggplot(mapping = aes(x = i_know_what_a_type_i_error_is)) + geom_bar() + coord_flip() If we wanted to get extra fancy, we could first convert the data from a wide format to a long format and then start plotting all the items together. Converting to long format would produce something like this: prior_survey %&gt;% gather(key = &quot;survey_item&quot;, value = &quot;survey_response&quot;) ## # A tibble: 1,176 x 2 ## survey_item survey_response ## &lt;chr&gt; &lt;chr&gt; ## 1 student_id 1 ## 2 student_id 2 ## 3 student_id 3 ## 4 student_id 4 ## 5 student_id 5 ## 6 student_id 6 ## 7 student_id 7 ## 8 student_id 8 ## 9 student_id 9 ## 10 student_id 10 ## # ... with 1,166 more rows Then we can combine that with the group_by() and summarize() functions and plot the results. prior_survey %&gt;% gather(key = &quot;survey_item&quot;, value = &quot;survey_response&quot;) %&gt;% group_by(survey_item, survey_response) %&gt;% summarize(n = n()) %&gt;% ggplot(mapping = aes(x = survey_response, y = survey_item, fill = n)) + geom_tile() ## `summarise()` regrouping output by &#39;survey_item&#39; (override with `.groups` argument) This plot is okay for giving a general sense of what is going on in these plots but there are a bunch of other ways to go about doing this. First, maybe we want to rename the response categories to a numerical scale. We can accomplish this with a mutate() and case_when(). prior_survey &lt;- prior_survey %&gt;% gather(key = &quot;survey_item&quot;, value = &quot;survey_response&quot;) %&gt;% mutate(survey_response_num = case_when(survey_response == &quot;Strongly disagree&quot; ~ 0, survey_response == &quot;Somewhat disagree&quot; ~ 1, survey_response == &quot;Neither agree nor disagree&quot; ~ 2, survey_response == &quot;Somewhat agree&quot; ~ 3, survey_response == &quot;Strongly agree&quot; ~ 4, )) Then we plot the same data but with the numerical scale along the x-axis. prior_survey %&gt;% group_by(survey_item, survey_response_num) %&gt;% summarize(n = n()) %&gt;% ggplot(mapping = aes(x = survey_response_num, y = survey_item, fill = n)) + geom_tile() ## `summarise()` regrouping output by &#39;survey_item&#39; (override with `.groups` argument) ## Warning: Removed 3 rows containing missing values (geom_tile). "],["week-3-data-cleaning-organizing-describing-and-communicating.html", "Chapter 4 Week 3 - Data Cleaning, Organizing, Describing, and Communicating 4.1 One continuous variable (either predictor or outcome variable) 4.2 One Discrete Variable (either predictor or outcome) 4.3 Discrete Predictor, Continuous Outcome 4.4 Continuous predictor and continuous outcome 4.5 Mutating Variables 4.6 Filtering and Selecting 4.7 Grouping and Summarizing", " Chapter 4 Week 3 - Data Cleaning, Organizing, Describing, and Communicating 4.1 One continuous variable (either predictor or outcome variable) num &lt;- 50 mu &lt;- 5 stdev &lt;- 2 x &lt;- rnorm(n = num, mean = mu, sd = stdev) hist(x) You can also do this using ggplot rather than base R graphics num &lt;- 50 mu &lt;- 5 stdev &lt;- 2 x_vec &lt;- rnorm(n = num, mean = mu, sd = stdev) x_df &lt;- tibble(x_col = x_vec) ggplot(data = x_df, mapping = aes(x = x)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. You can use geom_density() instead of geom_histogram() to get a smooth graph Just for fun, look at what happens to the the plot if you increase the sample size 4.2 One Discrete Variable (either predictor or outcome) ## load in the data survey_df &lt;- read_csv(&quot;ENGE_5714_2021_pre_survey.csv&quot;) ## Parsed with column specification: ## cols( ## .default = col_character(), ## student_id = col_double() ## ) ## See spec(...) for full column specifications. survey_df &lt;- survey_df %&gt;% clean_names() survey_df %&gt;% ggplot(aes(x = i_have_taken_a_quantitative_research_methods_course_before)) + geom_bar() Notice that the ordering is not quite what we would want. It is alphabetical. Try to find how we can fix this. Here is one way: q_levels &lt;- c(&quot;Strongly disagree&quot;, &quot;Somewhat disagree&quot;, &quot;Neither agree nor disagree&quot;, &quot;Somewhat agree&quot;, &quot;Strongly agree&quot;) survey_df$i_have_taken_a_quantitative_research_methods_course_before &lt;- factor(survey_df$i_have_taken_a_quantitative_research_methods_course_before, levels = q_levels, ordered = TRUE) ## Now try plotting survey_df %&gt;% ggplot(aes(x = i_have_taken_a_quantitative_research_methods_course_before)) + geom_bar() + coord_flip() + labs(x = &quot;I have taken a quantitative research methods course before&quot;, y = &quot;Count&quot;, title = &quot;Reordered Example&quot;) 4.2.1 Joining two datasets Lets imagine that we have a separate dataset that has information about the students who completed the pre-course prior knowledge survey. First, we will load in that dataset survey_info_df &lt;- read_csv(&quot;survey_student_info.csv&quot;) ## Parsed with column specification: ## cols( ## student_id = col_double(), ## standing = col_character(), ## college = col_character(), ## required = col_character() ## ) Next, lets join the two datasets based on the student id column, which is in each of the two dataframes. survey_df &lt;- survey_df %&gt;% inner_join(survey_info_df, by = &quot;student_id&quot;) Now we should have both datasets joined into one and saved as survey_df. With this, we can make some nicer plots and do something like use facet_grid() to look at students who are masters and doctoral students, for example. survey_df %&gt;% ggplot(aes(x = i_have_taken_a_quantitative_research_methods_course_before)) + geom_bar() + facet_grid(standing ~.) + labs(x = &quot;I have taken a quantitative research methods course before&quot;, y = &quot;Count&quot;, title = &quot;Reordered Example&quot;) The x axis looks a little crowded. What if we try coord_flip() survey_df %&gt;% filter(standing == &quot;doctoral&quot;) %&gt;% ggplot(aes(x = i_have_taken_a_quantitative_research_methods_course_before)) + geom_bar() + coord_flip() + facet_grid(standing ~.) + labs(x = &quot;I have taken a quantitative research methods course before&quot;, y = &quot;Count&quot;, title = &quot;Reordered Example&quot;) A quick note on filters survey_df %&gt;% filter(required == &quot;yes&quot;) ## # A tibble: 12 x 52 ## student_id i_have_taken_a_~ i_am_interested~ i_know_what_a_t~ ## &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Somewhat disagr~ Somewhat agree Strongly disagr~ ## 2 2 Strongly disagr~ Neither agree n~ Somewhat agree ## 3 4 Somewhat disagr~ Strongly agree Strongly disagr~ ## 4 8 Somewhat agree Somewhat agree Somewhat agree ## 5 9 Strongly disagr~ Strongly agree Somewhat agree ## 6 11 Strongly disagr~ Strongly agree Strongly disagr~ ## 7 16 Strongly agree Strongly agree Somewhat agree ## 8 17 Strongly disagr~ Strongly agree Strongly disagr~ ## 9 18 Somewhat disagr~ Somewhat agree Somewhat disagr~ ## 10 20 Strongly disagr~ Neither agree n~ Neither agree n~ ## 11 22 Strongly disagr~ Strongly agree Strongly disagr~ ## 12 23 Somewhat agree Strongly agree Somewhat agree ## # ... with 48 more variables: i_know_what_a_type_ii_error_is &lt;chr&gt;, ## # i_know_what_a_statistical_confidence_level_is &lt;chr&gt;, ## # i_know_what_a_p_value_is &lt;chr&gt;, i_know_what_p_hacking_means &lt;chr&gt;, ## # i_know_what_statistical_power_means &lt;chr&gt;, ## # i_have_heard_of_frequentist_statistics_before &lt;chr&gt;, ## # i_have_heard_of_bayesian_statistics_before &lt;chr&gt;, ## # i_have_heard_the_term_parametric_statistics_before &lt;chr&gt;, ## # i_have_heard_the_term_non_parametric_statistics_before &lt;chr&gt;, ## # i_know_what_a_histogram_is &lt;chr&gt;, ## # i_know_what_a_probability_distribution_is &lt;chr&gt;, ## # i_know_what_a_random_variable_is &lt;chr&gt;, ## # i_know_what_a_probability_distribution_function_is &lt;chr&gt;, ## # i_know_what_a_cumulative_distribution_function_is &lt;chr&gt;, ## # i_know_what_the_expectation_of_a_random_variable_is &lt;chr&gt;, ## # i_know_how_to_calculate_the_variance_of_a_random_variable &lt;chr&gt;, ## # i_know_what_a_z_score_is &lt;chr&gt;, ## # i_know_how_to_calculate_the_correlation_between_two_variables &lt;chr&gt;, ## # i_know_how_to_interpret_the_correlation_coefficient_between_two_variables &lt;chr&gt;, ## # i_have_heard_of_linear_regression &lt;chr&gt;, ## # i_know_how_to_run_a_linear_regression_in_some_software_or_by_hand_if_im_feeling_wild &lt;chr&gt;, ## # i_know_how_to_interpret_a_linear_regression &lt;chr&gt;, ## # i_have_heard_of_multiple_regression &lt;chr&gt;, ## # i_know_how_to_perform_a_multiple_regression &lt;chr&gt;, ## # i_know_how_to_interpret_a_multiple_regression &lt;chr&gt;, ## # i_have_heard_of_logistic_regression &lt;chr&gt;, ## # i_understand_when_to_use_a_logistic_regression &lt;chr&gt;, ## # i_know_how_to_interpret_the_results_of_a_logistic_regression &lt;chr&gt;, ## # i_have_heard_of_t_tests &lt;chr&gt;, i_have_performed_a_t_test_before &lt;chr&gt;, ## # i_know_how_to_interpret_the_results_of_a_t_test &lt;chr&gt;, ## # i_have_heard_of_analysis_of_variance &lt;chr&gt;, ## # i_understand_when_to_run_an_analysis_of_variance_anova &lt;chr&gt;, ## # i_know_how_to_interpret_the_results_from_an_anova &lt;chr&gt;, ## # i_have_heard_of_a_chi_square_test &lt;chr&gt;, ## # i_have_used_a_chi_square_test_before &lt;chr&gt;, ## # i_know_how_to_interpret_the_results_of_a_chi_square_test &lt;chr&gt;, ## # i_have_heard_of_cluster_analysis_before &lt;chr&gt;, ## # i_have_used_cluster_analysis_before &lt;chr&gt;, ## # i_know_how_to_interpret_the_results_of_a_cluster_analysis &lt;chr&gt;, ## # i_have_heard_of_factor_analysis_either_exploratory_or_confirmatory &lt;chr&gt;, ## # i_have_used_factor_analysis_either_exploratory_or_confirmatory &lt;chr&gt;, ## # i_know_how_to_interpret_the_results_of_a_factor_analysis_either_exploratory_or_confirmatory &lt;chr&gt;, ## # i_already_have_r_and_rstudio_downloaded_to_my_computer &lt;chr&gt;, ## # i_have_used_r_before &lt;chr&gt;, standing &lt;chr&gt;, college &lt;chr&gt;, required &lt;chr&gt; filtered_df &lt;- survey_df %&gt;% filter(required == &quot;yes&quot;) 4.2.1.1 A little more about plotting We are going to shift gears again and look at a few different kinds of plots. The main thing to remember here is that you want to think about whether the variables you have are nominal, ordinal, or continuous (that includes interval and ratio). 4.3 Discrete Predictor, Continuous Outcome group_size &lt;- 20 chem_e_scores &lt;- rnorm(n = group_size, mean = 85, sd = 4) chem_scores &lt;- rnorm(n = group_size, mean = 78, sd = 6) data_df &lt;- tibble( discipline = rep(c(&quot;ChemE&quot;, &quot;Chemistry&quot;), each = group_size), score = c(chem_e_scores, chem_scores) ) data_df %&gt;% ggplot(aes(x = discipline, y = score)) + geom_boxplot() You can make a few modifications to possibly make this easier to read. The first is to put the discrete category on the y axis instead of the x axis. The second is to use geom_jitter() in addition to geom_boxplot() to show the individual points in each group. data_df %&gt;% ggplot(aes(y = score, x = discipline)) + geom_boxplot() + geom_jitter() 4.4 Continuous predictor and continuous outcome First, lets re-do a lot of the steps in this weeks script for reading in data and transforming it a little mydata &lt;- read_csv(&quot;Free Reduced Lunch by Schools and Grade Structures 2008-2017_final.csv&quot;) ## Parsed with column specification: ## cols( ## .default = col_character(), ## div_num = col_double() ## ) ## See spec(...) for full column specifications. # check the structure of the data (this output is a bit long) str(mydata) ## tibble [2,101 x 137] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ sch_id : chr [1:2101] &quot;001-0070&quot; &quot;001-0080&quot; &quot;001-0530&quot; &quot;001-0540&quot; ... ## $ div_num : num [1:2101] 1 1 1 1 1 1 1 1 1 1 ... ## $ div_name : chr [1:2101] &quot;Accomack County&quot; &quot;Accomack County&quot; &quot;Accomack County&quot; &quot;Accomack County&quot; ... ## $ school_num : chr [1:2101] &quot;0070&lt;U+00A0&gt;&quot; &quot;0080&lt;U+00A0&gt;&quot; &quot;0530&lt;U+00A0&gt;&quot; &quot;0540&lt;U+00A0&gt;&quot; ... ## $ school_name : chr [1:2101] &quot;NANDUA HIGH&quot; &quot;CHINCOTEAGUE ELEM&quot; &quot;TANGIER COMBINED&quot; &quot;ARCADIA HIGH&quot; ... ## $ school_name2 : chr [1:2101] NA NA NA NA ... ## $ type0809 : chr [1:2101] &quot;SCH-HIGH&quot; &quot;SCH-ELEM&quot; &quot;SCH-COMB&quot; &quot;SCH-HIGH&quot; ... ## $ lowgrade_2008 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2008 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2008 : chr [1:2101] &quot;731&quot; &quot;263&quot; &quot;80&quot; &quot;638&quot; ... ## $ total_2008 : chr [1:2101] &quot;731&quot; &quot;263&quot; &quot;80&quot; &quot;638&quot; ... ## $ snp_0809 : chr [1:2101] &quot;659&quot; &quot;257&quot; &quot;80&quot; &quot;622&quot; ... ## $ free_elig_0809: chr [1:2101] &quot;306&quot; &quot;95&quot; &quot;38&quot; &quot;289&quot; ... ## $ free_per_0809 : chr [1:2101] &quot;46.43%&quot; &quot;36.96%&quot; &quot;47.50%&quot; &quot;46.46%&quot; ... ## $ red_elig_0809 : chr [1:2101] &quot;64&quot; &quot;8&quot; &quot;0&quot; &quot;56&quot; ... ## $ red_per_0809 : chr [1:2101] &quot;9.71%&quot; &quot;3.11%&quot; &quot;0.00%&quot; &quot;9.00%&quot; ... ## $ totalFRL_0809 : chr [1:2101] &quot;370&quot; &quot;103&quot; &quot;38&quot; &quot;345&quot; ... ## $ totalper_0809 : chr [1:2101] &quot;56.15%&quot; &quot;40.08%&quot; &quot;47.50%&quot; &quot;55.47%&quot; ... ## $ type0910 : chr [1:2101] &quot;SCH-HIGH&quot; &quot;SCH-ELEM&quot; &quot;SCH-COMB&quot; &quot;SCH-HIGH&quot; ... ## $ lowgrade_2009 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2009 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2009 : chr [1:2101] &quot;654&quot; &quot;266&quot; &quot;78&quot; &quot;634&quot; ... ## $ total_2009 : chr [1:2101] &quot;654&quot; &quot;266&quot; &quot;78&quot; &quot;634&quot; ... ## $ snp_0910 : chr [1:2101] &quot;655&quot; &quot;266&quot; &quot;78&quot; &quot;635&quot; ... ## $ free_elig_0910: chr [1:2101] &quot;290&quot; &quot;99&quot; &quot;36&quot; &quot;286&quot; ... ## $ free_per_0910 : chr [1:2101] &quot;44.27%&quot; &quot;37.22%&quot; &quot;46.15%&quot; &quot;45.04%&quot; ... ## $ red_elig_0910 : chr [1:2101] &quot;37&quot; &quot;14&quot; &quot;0&quot; &quot;66&quot; ... ## $ red_per_0910 : chr [1:2101] &quot;5.65%&quot; &quot;5.26%&quot; &quot;0.00%&quot; &quot;10.39%&quot; ... ## $ totalFRL_09010: chr [1:2101] &quot;327&quot; &quot;113&quot; &quot;36&quot; &quot;352&quot; ... ## $ totalper_0910 : chr [1:2101] &quot;49.92%&quot; &quot;42.48%&quot; &quot;46.15%&quot; &quot;55.43%&quot; ... ## $ type1011 : chr [1:2101] &quot;SCH-HIGH&quot; &quot;SCH-ELEM&quot; &quot;SCH-COMB&quot; &quot;SCH-HIGH&quot; ... ## $ lowgrade_2010 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2010 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2010 : chr [1:2101] &quot;603&quot; &quot;268&quot; &quot;74&quot; &quot;614&quot; ... ## $ total_2010 : chr [1:2101] &quot;603&quot; &quot;268&quot; &quot;74&quot; &quot;614&quot; ... ## $ snp_1011 : chr [1:2101] &quot;603&quot; &quot;277&quot; &quot;74&quot; &quot;606&quot; ... ## $ free_elig_1011: chr [1:2101] &quot;285&quot; &quot;108&quot; &quot;32&quot; &quot;308&quot; ... ## $ free_per_1011 : chr [1:2101] &quot;47.26%&quot; &quot;38.99%&quot; &quot;43.24%&quot; &quot;50.83%&quot; ... ## $ red_elig_1011 : chr [1:2101] &quot;46&quot; &quot;8&quot; &quot;0&quot; &quot;50&quot; ... ## $ red_per_1011 : chr [1:2101] &quot;7.63%&quot; &quot;2.89%&quot; &quot;0.00%&quot; &quot;8.25%&quot; ... ## $ totalFRL_1011 : chr [1:2101] &quot;331&quot; &quot;116&quot; &quot;32&quot; &quot;358&quot; ... ## $ totalper_1011 : chr [1:2101] &quot;54.89%&quot; &quot;41.88%&quot; &quot;43.24%&quot; &quot;59.08%&quot; ... ## $ type1112 : chr [1:2101] &quot;SCH-HIGH&quot; &quot;SCH-ELEM&quot; &quot;SCH-COMB&quot; &quot;SCH-HIGH&quot; ... ## $ lowgrade_2011 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2011 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2011 : chr [1:2101] &quot;593&quot; &quot;276&quot; &quot;73&quot; &quot;605&quot; ... ## $ total_2011 : chr [1:2101] &quot;593&quot; &quot;276&quot; &quot;73&quot; &quot;605&quot; ... ## $ snp_1112 : chr [1:2101] &quot;593&quot; &quot;281&quot; &quot;73&quot; &quot;611&quot; ... ## $ free_elig_1112: chr [1:2101] &quot;289&quot; &quot;116&quot; &quot;31&quot; &quot;318&quot; ... ## $ free_per_1112 : chr [1:2101] &quot;48.74%&quot; &quot;41.28%&quot; &quot;42.47%&quot; &quot;52.05%&quot; ... ## $ red_elig_1112 : chr [1:2101] &quot;50&quot; &quot;14&quot; &quot;0&quot; &quot;44&quot; ... ## $ red_per_1112 : chr [1:2101] &quot;8.43%&quot; &quot;4.98%&quot; &quot;0.00%&quot; &quot;7.20%&quot; ... ## $ totalFRL_1112 : chr [1:2101] &quot;339&quot; &quot;130&quot; &quot;31&quot; &quot;362&quot; ... ## $ totalper_1112 : chr [1:2101] &quot;57.17%&quot; &quot;46.26%&quot; &quot;42.47%&quot; &quot;59.25%&quot; ... ## $ type1213 : chr [1:2101] &quot;SCH-HIGH&quot; &quot;SCH-ELEM&quot; &quot;SCH-COMB&quot; &quot;SCH-HIGH&quot; ... ## $ lowgrade_2012 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2012 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2012 : chr [1:2101] &quot;637&quot; &quot;258&quot; &quot;68&quot; &quot;579&quot; ... ## $ total_2012 : chr [1:2101] &quot;637&quot; &quot;258&quot; &quot;68&quot; &quot;579&quot; ... ## $ snp_1213 : chr [1:2101] &quot;633&quot; &quot;259&quot; &quot;68&quot; &quot;579&quot; ... ## $ free_elig_1213: chr [1:2101] &quot;324&quot; &quot;117&quot; &quot;21&quot; &quot;348&quot; ... ## $ free_per_1213 : chr [1:2101] &quot;51.18%&quot; &quot;45.17%&quot; &quot;30.88%&quot; &quot;60.10%&quot; ... ## $ red_elig_1213 : chr [1:2101] &quot;42&quot; &quot;20&quot; &quot;5&quot; &quot;33&quot; ... ## $ red_per_1213 : chr [1:2101] &quot;6.64%&quot; &quot;7.72%&quot; &quot;7.35%&quot; &quot;5.70%&quot; ... ## $ totalFRL_1213 : chr [1:2101] &quot;366&quot; &quot;137&quot; &quot;26&quot; &quot;381&quot; ... ## $ totalper_1213 : chr [1:2101] &quot;57.82%&quot; &quot;52.90%&quot; &quot;38.24%&quot; &quot;65.80%&quot; ... ## $ type1314 : chr [1:2101] &quot;SCH-HIGH&quot; &quot;SCH-ELEM&quot; &quot;SCH-COMB&quot; &quot;SCH-HIGH&quot; ... ## $ lowgrade_2013 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2013 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2013 : chr [1:2101] &quot;670&quot; &quot;238&quot; &quot;66&quot; &quot;582&quot; ... ## $ total_2013 : chr [1:2101] &quot;670&quot; &quot;238&quot; &quot;66&quot; &quot;582&quot; ... ## $ snp_1314 : chr [1:2101] &quot;668&quot; &quot;239&quot; &quot;56&quot; &quot;589&quot; ... ## $ free_elig_1314: chr [1:2101] &quot;346&quot; &quot;102&quot; &quot;12&quot; &quot;347&quot; ... ## $ free_per_1314 : chr [1:2101] &quot;51.80%&quot; &quot;42.68%&quot; &quot;21.43%&quot; &quot;58.91%&quot; ... ## $ red_elig_1314 : chr [1:2101] &quot;44&quot; &quot;19&quot; &quot;4&quot; &quot;54&quot; ... ## $ red_per_1314 : chr [1:2101] &quot;6.59%&quot; &quot;7.95%&quot; &quot;7.14%&quot; &quot;9.17%&quot; ... ## $ totalFRL_1314 : chr [1:2101] &quot;390&quot; &quot;121&quot; &quot;16&quot; &quot;401&quot; ... ## $ totalper_1314 : chr [1:2101] &quot;58.38%&quot; &quot;50.63%&quot; &quot;28.57%&quot; &quot;68.08%&quot; ... ## $ type1415 : chr [1:2101] NA NA NA NA ... ## $ lowgrade_2014 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2014 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2014 : chr [1:2101] &quot;685&quot; &quot;251&quot; &quot;65&quot; &quot;581&quot; ... ## $ total_2014 : chr [1:2101] &quot;685&quot; &quot;251&quot; &quot;65&quot; &quot;581&quot; ... ## $ snp_1415 : chr [1:2101] &quot;672&quot; &quot;239&quot; &quot;61&quot; &quot;586&quot; ... ## $ free_elig_1415: chr [1:2101] &quot;361&quot; &quot;93&quot; &quot;14&quot; &quot;351&quot; ... ## $ free_per_1415 : chr [1:2101] &quot;53.72%&quot; &quot;38.91%&quot; &quot;22.95%&quot; &quot;59.90%&quot; ... ## $ red_elig_1415 : chr [1:2101] &quot;40&quot; &quot;17&quot; &quot;4&quot; &quot;40&quot; ... ## $ red_per_1415 : chr [1:2101] &quot;5.95%&quot; &quot;7.11%&quot; &quot;6.56%&quot; &quot;6.83%&quot; ... ## $ totalFRL_1415 : chr [1:2101] &quot;401&quot; &quot;110&quot; &quot;18&quot; &quot;391&quot; ... ## $ totalper_1415 : chr [1:2101] &quot;59.67%&quot; &quot;46.03%&quot; &quot;29.51%&quot; &quot;66.72%&quot; ... ## $ CEP_1516 : chr [1:2101] &quot;#NULL!&quot; &quot;#NULL!&quot; &quot;#NULL!&quot; &quot;#NULL!&quot; ... ## $ type1516 : chr [1:2101] &quot;SCH-HIGH&quot; &quot;SCH-ELEM&quot; &quot;SCH-COMB&quot; &quot;SCH-HIGH&quot; ... ## $ lowgrade_2015 : chr [1:2101] &quot;9&quot; &quot;PK&quot; &quot;KG&quot; &quot;9&quot; ... ## $ higrade_2015 : chr [1:2101] &quot;12&quot; &quot;5&quot; &quot;12&quot; &quot;12&quot; ... ## $ totalFT_2015 : chr [1:2101] &quot;737&quot; &quot;259&quot; &quot;65&quot; &quot;621&quot; ... ## $ total_2015 : chr [1:2101] &quot;737&quot; &quot;259&quot; &quot;65&quot; &quot;621&quot; ... ## $ snp_1516 : chr [1:2101] &quot;728&quot; &quot;268&quot; &quot;67&quot; &quot;608&quot; ... ## $ free_elig_1516: chr [1:2101] &quot;362&quot; &quot;109&quot; &quot;12&quot; &quot;339&quot; ... ## $ free_per_1516 : chr [1:2101] &quot;49.73%&quot; &quot;40.67%&quot; &quot;17.91%&quot; &quot;55.76%&quot; ... ## [list output truncated] ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. sch_id = col_character(), ## .. div_num = col_double(), ## .. div_name = col_character(), ## .. school_num = col_character(), ## .. school_name = col_character(), ## .. school_name2 = col_character(), ## .. type0809 = col_character(), ## .. lowgrade_2008 = col_character(), ## .. higrade_2008 = col_character(), ## .. totalFT_2008 = col_character(), ## .. total_2008 = col_character(), ## .. snp_0809 = col_character(), ## .. free_elig_0809 = col_character(), ## .. free_per_0809 = col_character(), ## .. red_elig_0809 = col_character(), ## .. red_per_0809 = col_character(), ## .. totalFRL_0809 = col_character(), ## .. totalper_0809 = col_character(), ## .. type0910 = col_character(), ## .. lowgrade_2009 = col_character(), ## .. higrade_2009 = col_character(), ## .. totalFT_2009 = col_character(), ## .. total_2009 = col_character(), ## .. snp_0910 = col_character(), ## .. free_elig_0910 = col_character(), ## .. free_per_0910 = col_character(), ## .. red_elig_0910 = col_character(), ## .. red_per_0910 = col_character(), ## .. totalFRL_09010 = col_character(), ## .. totalper_0910 = col_character(), ## .. type1011 = col_character(), ## .. lowgrade_2010 = col_character(), ## .. higrade_2010 = col_character(), ## .. totalFT_2010 = col_character(), ## .. total_2010 = col_character(), ## .. snp_1011 = col_character(), ## .. free_elig_1011 = col_character(), ## .. free_per_1011 = col_character(), ## .. red_elig_1011 = col_character(), ## .. red_per_1011 = col_character(), ## .. totalFRL_1011 = col_character(), ## .. totalper_1011 = col_character(), ## .. type1112 = col_character(), ## .. lowgrade_2011 = col_character(), ## .. higrade_2011 = col_character(), ## .. totalFT_2011 = col_character(), ## .. total_2011 = col_character(), ## .. snp_1112 = col_character(), ## .. free_elig_1112 = col_character(), ## .. free_per_1112 = col_character(), ## .. red_elig_1112 = col_character(), ## .. red_per_1112 = col_character(), ## .. totalFRL_1112 = col_character(), ## .. totalper_1112 = col_character(), ## .. type1213 = col_character(), ## .. lowgrade_2012 = col_character(), ## .. higrade_2012 = col_character(), ## .. totalFT_2012 = col_character(), ## .. total_2012 = col_character(), ## .. snp_1213 = col_character(), ## .. free_elig_1213 = col_character(), ## .. free_per_1213 = col_character(), ## .. red_elig_1213 = col_character(), ## .. red_per_1213 = col_character(), ## .. totalFRL_1213 = col_character(), ## .. totalper_1213 = col_character(), ## .. type1314 = col_character(), ## .. lowgrade_2013 = col_character(), ## .. higrade_2013 = col_character(), ## .. totalFT_2013 = col_character(), ## .. total_2013 = col_character(), ## .. snp_1314 = col_character(), ## .. free_elig_1314 = col_character(), ## .. free_per_1314 = col_character(), ## .. red_elig_1314 = col_character(), ## .. red_per_1314 = col_character(), ## .. totalFRL_1314 = col_character(), ## .. totalper_1314 = col_character(), ## .. type1415 = col_character(), ## .. lowgrade_2014 = col_character(), ## .. higrade_2014 = col_character(), ## .. totalFT_2014 = col_character(), ## .. total_2014 = col_character(), ## .. snp_1415 = col_character(), ## .. free_elig_1415 = col_character(), ## .. free_per_1415 = col_character(), ## .. red_elig_1415 = col_character(), ## .. red_per_1415 = col_character(), ## .. totalFRL_1415 = col_character(), ## .. totalper_1415 = col_character(), ## .. CEP_1516 = col_character(), ## .. type1516 = col_character(), ## .. lowgrade_2015 = col_character(), ## .. higrade_2015 = col_character(), ## .. totalFT_2015 = col_character(), ## .. total_2015 = col_character(), ## .. snp_1516 = col_character(), ## .. free_elig_1516 = col_character(), ## .. free_per_1516 = col_character(), ## .. red_elig_1516 = col_character(), ## .. red_Per_1516 = col_character(), ## .. totalFRL_1516 = col_character(), ## .. totalper_1516 = col_character(), ## .. CEP_1617 = col_character(), ## .. type1617 = col_character(), ## .. lowgrade_2016 = col_character(), ## .. higrade_2016 = col_character(), ## .. totalFT_2016 = col_character(), ## .. total_2016 = col_character(), ## .. snp_2016 = col_character(), ## .. free_elig_1617 = col_character(), ## .. free_per_1617 = col_character(), ## .. red_elig_1617 = col_character(), ## .. red_per_1617 = col_character(), ## .. totalFRL_1617 = col_character(), ## .. totalper_1617 = col_character(), ## .. CEP_1718 = col_character(), ## .. type1718 = col_character(), ## .. lowgrade_2017 = col_character(), ## .. higrade_2017 = col_character(), ## .. totalFT_2017 = col_character(), ## .. total_2017 = col_character(), ## .. snp_1718 = col_character(), ## .. free_elig_1718 = col_character(), ## .. free_per_1718 = col_character(), ## .. red_elig_1718 = col_character(), ## .. red_per_1718 = col_character(), ## .. totalFRL_1718 = col_character(), ## .. totalper_1718 = col_character(), ## .. stable = col_character(), ## .. new = col_character(), ## .. closed = col_character(), ## .. close_yr = col_character(), ## .. reuseid = col_character(), ## .. gradechg = col_character(), ## .. gradechg_yr = col_character(), ## .. grchgyr_2 = col_character() ## .. ) str(mydata$total_2017) ## chr [1:2101] &quot;742&quot; &quot;236&quot; &quot;60&quot; &quot;624&quot; &quot;286&quot; &quot;485&quot; &quot;583&quot; &quot;550&quot; &quot;600&quot; &quot;514&quot; ... NOTE: When you have a lot of variables, running this str() function is not a great idea - the output is a little too cumbersome 4.5 Mutating Variables Note that almost all of the data reads in as a character data type which are just strings, This can create issues. We know that many of the columns are actually storing numbers or numeric values as R refers to them. We need to fix this. Lets tell R that these columns (at least the two we are going to use) are numeric. We are going to see two interchangeable ways to do this. First, we use the $ operator which lets me specify a specific column within my data frame in combination with the as.numeric() function mydata$total_2017&lt;-as.numeric(mydata$total_2017) mydata$totalFRL_1718&lt;-as.numeric(mydata$totalFRL_1718) Some columns have a percent symbol, which you will need to remove before coercing to numeric data type mydata &lt;- mydata %&gt;% mutate(totalper_0809 = str_remove(totalper_0809, &quot;%&quot;)) Then we can change the column from character to numeric mydata$totalper_0809 &lt;- as.numeric(mydata$totalper_0809) ## Warning: NAs introduced by coercion Check to make sure it converted the column type correctly using str(). str(mydata$totalper_0809) ## num [1:2101] 56.1 40.1 47.5 55.5 33.4 ... Second, alternatively, we can do this for a whole set of variables at once. We just need to specify a matching criteria. newdf &lt;- mydata %&gt;% mutate_at(vars(starts_with(&quot;total&quot;)), as.numeric) ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion newdf &lt;- newdf %&gt;% mutate_at(vars(starts_with(&quot;totalFRL&quot;)), as.numeric) Check whether the old and new variables are stored differently (old as a character, new as a numeric variable) str(mydata$total_2008) ## chr [1:2101] &quot;731&quot; &quot;263&quot; &quot;80&quot; &quot;638&quot; &quot;333&quot; &quot;536&quot; &quot;610&quot; &quot;490&quot; &quot;585&quot; &quot;450&quot; ... str(newdf$total_2008) ## num [1:2101] 731 263 80 638 333 536 610 490 585 450 ... 4.6 Filtering and Selecting A basic operation we do a lot is to filter the data so that we are working with a subset of all that we have. We can do this with the filter() function, part of the dplyr package (in the tidyverse collection of packages). Lets say we want to look at the schools with div_num values less than 50. newdf %&gt;% filter(div_num &lt; 50) ## # A tibble: 800 x 137 ## sch_id div_num div_name school_num school_name school_name2 type0809 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 001-0~ 1 Accomac~ &quot;0070\\xa0&quot; NANDUA HIGH &lt;NA&gt; SCH-HIGH ## 2 001-0~ 1 Accomac~ &quot;0080\\xa0&quot; CHINCOTEAG~ &lt;NA&gt; SCH-ELEM ## 3 001-0~ 1 Accomac~ &quot;0530\\xa0&quot; TANGIER CO~ &lt;NA&gt; SCH-COMB ## 4 001-0~ 1 Accomac~ &quot;0540\\xa0&quot; ARCADIA HI~ &lt;NA&gt; SCH-HIGH ## 5 001-0~ 1 Accomac~ &quot;0580\\xa0&quot; CHINCOTEAG~ &lt;NA&gt; SCH-COMB ## 6 001-0~ 1 Accomac~ &quot;0590\\xa0&quot; PUNGOTEAGU~ &lt;NA&gt; SCH-ELEM ## 7 001-0~ 1 Accomac~ &quot;0600\\xa0&quot; KEGOTANK E~ &lt;NA&gt; SCH-ELEM ## 8 001-0~ 1 Accomac~ &quot;0701\\xa0&quot; ACCAWMACKE~ &lt;NA&gt; SCH-ELEM ## 9 001-0~ 1 Accomac~ &quot;0702\\xa0&quot; METOMPKIN ~ &lt;NA&gt; SCH-ELEM ## 10 001-0~ 1 Accomac~ &quot;0703\\xa0&quot; NANDUA MID~ &lt;NA&gt; SCH-MID ## # ... with 790 more rows, and 130 more variables: lowgrade_2008 &lt;chr&gt;, ## # higrade_2008 &lt;chr&gt;, totalFT_2008 &lt;dbl&gt;, total_2008 &lt;dbl&gt;, snp_0809 &lt;chr&gt;, ## # free_elig_0809 &lt;chr&gt;, free_per_0809 &lt;chr&gt;, red_elig_0809 &lt;chr&gt;, ## # red_per_0809 &lt;chr&gt;, totalFRL_0809 &lt;dbl&gt;, totalper_0809 &lt;dbl&gt;, ## # type0910 &lt;chr&gt;, lowgrade_2009 &lt;chr&gt;, higrade_2009 &lt;chr&gt;, ## # totalFT_2009 &lt;dbl&gt;, total_2009 &lt;dbl&gt;, snp_0910 &lt;chr&gt;, free_elig_0910 &lt;chr&gt;, ## # free_per_0910 &lt;chr&gt;, red_elig_0910 &lt;chr&gt;, red_per_0910 &lt;chr&gt;, ## # totalFRL_09010 &lt;dbl&gt;, totalper_0910 &lt;dbl&gt;, type1011 &lt;chr&gt;, ## # lowgrade_2010 &lt;chr&gt;, higrade_2010 &lt;chr&gt;, totalFT_2010 &lt;dbl&gt;, ## # total_2010 &lt;dbl&gt;, snp_1011 &lt;chr&gt;, free_elig_1011 &lt;chr&gt;, ## # free_per_1011 &lt;chr&gt;, red_elig_1011 &lt;chr&gt;, red_per_1011 &lt;chr&gt;, ## # totalFRL_1011 &lt;dbl&gt;, totalper_1011 &lt;dbl&gt;, type1112 &lt;chr&gt;, ## # lowgrade_2011 &lt;chr&gt;, higrade_2011 &lt;chr&gt;, totalFT_2011 &lt;dbl&gt;, ## # total_2011 &lt;dbl&gt;, snp_1112 &lt;chr&gt;, free_elig_1112 &lt;chr&gt;, ## # free_per_1112 &lt;chr&gt;, red_elig_1112 &lt;chr&gt;, red_per_1112 &lt;chr&gt;, ## # totalFRL_1112 &lt;dbl&gt;, totalper_1112 &lt;dbl&gt;, type1213 &lt;chr&gt;, ## # lowgrade_2012 &lt;chr&gt;, higrade_2012 &lt;chr&gt;, totalFT_2012 &lt;dbl&gt;, ## # total_2012 &lt;dbl&gt;, snp_1213 &lt;chr&gt;, free_elig_1213 &lt;chr&gt;, ## # free_per_1213 &lt;chr&gt;, red_elig_1213 &lt;chr&gt;, red_per_1213 &lt;chr&gt;, ## # totalFRL_1213 &lt;dbl&gt;, totalper_1213 &lt;dbl&gt;, type1314 &lt;chr&gt;, ## # lowgrade_2013 &lt;chr&gt;, higrade_2013 &lt;chr&gt;, totalFT_2013 &lt;dbl&gt;, ## # total_2013 &lt;dbl&gt;, snp_1314 &lt;chr&gt;, free_elig_1314 &lt;chr&gt;, ## # free_per_1314 &lt;chr&gt;, red_elig_1314 &lt;chr&gt;, red_per_1314 &lt;chr&gt;, ## # totalFRL_1314 &lt;dbl&gt;, totalper_1314 &lt;dbl&gt;, type1415 &lt;chr&gt;, ## # lowgrade_2014 &lt;chr&gt;, higrade_2014 &lt;chr&gt;, totalFT_2014 &lt;dbl&gt;, ## # total_2014 &lt;dbl&gt;, snp_1415 &lt;chr&gt;, free_elig_1415 &lt;chr&gt;, ## # free_per_1415 &lt;chr&gt;, red_elig_1415 &lt;chr&gt;, red_per_1415 &lt;chr&gt;, ## # totalFRL_1415 &lt;dbl&gt;, totalper_1415 &lt;dbl&gt;, CEP_1516 &lt;chr&gt;, type1516 &lt;chr&gt;, ## # lowgrade_2015 &lt;chr&gt;, higrade_2015 &lt;chr&gt;, totalFT_2015 &lt;dbl&gt;, ## # total_2015 &lt;dbl&gt;, snp_1516 &lt;chr&gt;, free_elig_1516 &lt;chr&gt;, ## # free_per_1516 &lt;chr&gt;, red_elig_1516 &lt;chr&gt;, red_Per_1516 &lt;chr&gt;, ## # totalFRL_1516 &lt;dbl&gt;, totalper_1516 &lt;dbl&gt;, CEP_1617 &lt;chr&gt;, type1617 &lt;chr&gt;, ## # lowgrade_2016 &lt;chr&gt;, higrade_2016 &lt;chr&gt;, ... Or, if we want to look at schools where the highest grade in 2008 was grade five, we can try: newdf %&gt;% filter(higrade_2008 == &quot;5&quot;) # this returns a subsetted dataframe with 878 rows ## # A tibble: 878 x 137 ## sch_id div_num div_name school_num school_name school_name2 type0809 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 001-0~ 1 Accomac~ &quot;0080\\xa0&quot; CHINCOTEAG~ &lt;NA&gt; SCH-ELEM ## 2 001-0~ 1 Accomac~ &quot;0590\\xa0&quot; PUNGOTEAGU~ &lt;NA&gt; SCH-ELEM ## 3 001-0~ 1 Accomac~ &quot;0600\\xa0&quot; KEGOTANK E~ &lt;NA&gt; SCH-ELEM ## 4 001-0~ 1 Accomac~ &quot;0701\\xa0&quot; ACCAWMACKE~ &lt;NA&gt; SCH-ELEM ## 5 001-0~ 1 Accomac~ &quot;0702\\xa0&quot; METOMPKIN ~ &lt;NA&gt; SCH-ELEM ## 6 002-0~ 2 Albemar~ &quot;0010\\xa0&quot; HOLLYMEAD ~ &lt;NA&gt; SCH-ELEM ## 7 002-0~ 2 Albemar~ &quot;0030\\xa0&quot; SCOTTSVILL~ &lt;NA&gt; SCH-ELEM ## 8 002-0~ 2 Albemar~ &quot;0040\\xa0&quot; MARY CARR ~ &lt;NA&gt; SCH-ELEM ## 9 002-0~ 2 Albemar~ &quot;0100\\xa0&quot; BROADUS WO~ &lt;NA&gt; SCH-ELEM ## 10 002-0~ 2 Albemar~ &quot;0150\\xa0&quot; PAUL H CAL~ &lt;NA&gt; SCH-ELEM ## # ... with 868 more rows, and 130 more variables: lowgrade_2008 &lt;chr&gt;, ## # higrade_2008 &lt;chr&gt;, totalFT_2008 &lt;dbl&gt;, total_2008 &lt;dbl&gt;, snp_0809 &lt;chr&gt;, ## # free_elig_0809 &lt;chr&gt;, free_per_0809 &lt;chr&gt;, red_elig_0809 &lt;chr&gt;, ## # red_per_0809 &lt;chr&gt;, totalFRL_0809 &lt;dbl&gt;, totalper_0809 &lt;dbl&gt;, ## # type0910 &lt;chr&gt;, lowgrade_2009 &lt;chr&gt;, higrade_2009 &lt;chr&gt;, ## # totalFT_2009 &lt;dbl&gt;, total_2009 &lt;dbl&gt;, snp_0910 &lt;chr&gt;, free_elig_0910 &lt;chr&gt;, ## # free_per_0910 &lt;chr&gt;, red_elig_0910 &lt;chr&gt;, red_per_0910 &lt;chr&gt;, ## # totalFRL_09010 &lt;dbl&gt;, totalper_0910 &lt;dbl&gt;, type1011 &lt;chr&gt;, ## # lowgrade_2010 &lt;chr&gt;, higrade_2010 &lt;chr&gt;, totalFT_2010 &lt;dbl&gt;, ## # total_2010 &lt;dbl&gt;, snp_1011 &lt;chr&gt;, free_elig_1011 &lt;chr&gt;, ## # free_per_1011 &lt;chr&gt;, red_elig_1011 &lt;chr&gt;, red_per_1011 &lt;chr&gt;, ## # totalFRL_1011 &lt;dbl&gt;, totalper_1011 &lt;dbl&gt;, type1112 &lt;chr&gt;, ## # lowgrade_2011 &lt;chr&gt;, higrade_2011 &lt;chr&gt;, totalFT_2011 &lt;dbl&gt;, ## # total_2011 &lt;dbl&gt;, snp_1112 &lt;chr&gt;, free_elig_1112 &lt;chr&gt;, ## # free_per_1112 &lt;chr&gt;, red_elig_1112 &lt;chr&gt;, red_per_1112 &lt;chr&gt;, ## # totalFRL_1112 &lt;dbl&gt;, totalper_1112 &lt;dbl&gt;, type1213 &lt;chr&gt;, ## # lowgrade_2012 &lt;chr&gt;, higrade_2012 &lt;chr&gt;, totalFT_2012 &lt;dbl&gt;, ## # total_2012 &lt;dbl&gt;, snp_1213 &lt;chr&gt;, free_elig_1213 &lt;chr&gt;, ## # free_per_1213 &lt;chr&gt;, red_elig_1213 &lt;chr&gt;, red_per_1213 &lt;chr&gt;, ## # totalFRL_1213 &lt;dbl&gt;, totalper_1213 &lt;dbl&gt;, type1314 &lt;chr&gt;, ## # lowgrade_2013 &lt;chr&gt;, higrade_2013 &lt;chr&gt;, totalFT_2013 &lt;dbl&gt;, ## # total_2013 &lt;dbl&gt;, snp_1314 &lt;chr&gt;, free_elig_1314 &lt;chr&gt;, ## # free_per_1314 &lt;chr&gt;, red_elig_1314 &lt;chr&gt;, red_per_1314 &lt;chr&gt;, ## # totalFRL_1314 &lt;dbl&gt;, totalper_1314 &lt;dbl&gt;, type1415 &lt;chr&gt;, ## # lowgrade_2014 &lt;chr&gt;, higrade_2014 &lt;chr&gt;, totalFT_2014 &lt;dbl&gt;, ## # total_2014 &lt;dbl&gt;, snp_1415 &lt;chr&gt;, free_elig_1415 &lt;chr&gt;, ## # free_per_1415 &lt;chr&gt;, red_elig_1415 &lt;chr&gt;, red_per_1415 &lt;chr&gt;, ## # totalFRL_1415 &lt;dbl&gt;, totalper_1415 &lt;dbl&gt;, CEP_1516 &lt;chr&gt;, type1516 &lt;chr&gt;, ## # lowgrade_2015 &lt;chr&gt;, higrade_2015 &lt;chr&gt;, totalFT_2015 &lt;dbl&gt;, ## # total_2015 &lt;dbl&gt;, snp_1516 &lt;chr&gt;, free_elig_1516 &lt;chr&gt;, ## # free_per_1516 &lt;chr&gt;, red_elig_1516 &lt;chr&gt;, red_Per_1516 &lt;chr&gt;, ## # totalFRL_1516 &lt;dbl&gt;, totalper_1516 &lt;dbl&gt;, CEP_1617 &lt;chr&gt;, type1617 &lt;chr&gt;, ## # lowgrade_2016 &lt;chr&gt;, higrade_2016 &lt;chr&gt;, ... Note that we had to set it equal to the character value 5 rather than the numeric value 5. Why? If we wanted to filter on numeric values instead, we would want to do something like this: newdf %&gt;% mutate(higrade_2008 = as.numeric(higrade_2008)) %&gt;% filter(higrade_2008 == 5) # again, this returns a subsetted dataframe with 878 rows ## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion ## # A tibble: 878 x 137 ## sch_id div_num div_name school_num school_name school_name2 type0809 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 001-0~ 1 Accomac~ &quot;0080\\xa0&quot; CHINCOTEAG~ &lt;NA&gt; SCH-ELEM ## 2 001-0~ 1 Accomac~ &quot;0590\\xa0&quot; PUNGOTEAGU~ &lt;NA&gt; SCH-ELEM ## 3 001-0~ 1 Accomac~ &quot;0600\\xa0&quot; KEGOTANK E~ &lt;NA&gt; SCH-ELEM ## 4 001-0~ 1 Accomac~ &quot;0701\\xa0&quot; ACCAWMACKE~ &lt;NA&gt; SCH-ELEM ## 5 001-0~ 1 Accomac~ &quot;0702\\xa0&quot; METOMPKIN ~ &lt;NA&gt; SCH-ELEM ## 6 002-0~ 2 Albemar~ &quot;0010\\xa0&quot; HOLLYMEAD ~ &lt;NA&gt; SCH-ELEM ## 7 002-0~ 2 Albemar~ &quot;0030\\xa0&quot; SCOTTSVILL~ &lt;NA&gt; SCH-ELEM ## 8 002-0~ 2 Albemar~ &quot;0040\\xa0&quot; MARY CARR ~ &lt;NA&gt; SCH-ELEM ## 9 002-0~ 2 Albemar~ &quot;0100\\xa0&quot; BROADUS WO~ &lt;NA&gt; SCH-ELEM ## 10 002-0~ 2 Albemar~ &quot;0150\\xa0&quot; PAUL H CAL~ &lt;NA&gt; SCH-ELEM ## # ... with 868 more rows, and 130 more variables: lowgrade_2008 &lt;chr&gt;, ## # higrade_2008 &lt;dbl&gt;, totalFT_2008 &lt;dbl&gt;, total_2008 &lt;dbl&gt;, snp_0809 &lt;chr&gt;, ## # free_elig_0809 &lt;chr&gt;, free_per_0809 &lt;chr&gt;, red_elig_0809 &lt;chr&gt;, ## # red_per_0809 &lt;chr&gt;, totalFRL_0809 &lt;dbl&gt;, totalper_0809 &lt;dbl&gt;, ## # type0910 &lt;chr&gt;, lowgrade_2009 &lt;chr&gt;, higrade_2009 &lt;chr&gt;, ## # totalFT_2009 &lt;dbl&gt;, total_2009 &lt;dbl&gt;, snp_0910 &lt;chr&gt;, free_elig_0910 &lt;chr&gt;, ## # free_per_0910 &lt;chr&gt;, red_elig_0910 &lt;chr&gt;, red_per_0910 &lt;chr&gt;, ## # totalFRL_09010 &lt;dbl&gt;, totalper_0910 &lt;dbl&gt;, type1011 &lt;chr&gt;, ## # lowgrade_2010 &lt;chr&gt;, higrade_2010 &lt;chr&gt;, totalFT_2010 &lt;dbl&gt;, ## # total_2010 &lt;dbl&gt;, snp_1011 &lt;chr&gt;, free_elig_1011 &lt;chr&gt;, ## # free_per_1011 &lt;chr&gt;, red_elig_1011 &lt;chr&gt;, red_per_1011 &lt;chr&gt;, ## # totalFRL_1011 &lt;dbl&gt;, totalper_1011 &lt;dbl&gt;, type1112 &lt;chr&gt;, ## # lowgrade_2011 &lt;chr&gt;, higrade_2011 &lt;chr&gt;, totalFT_2011 &lt;dbl&gt;, ## # total_2011 &lt;dbl&gt;, snp_1112 &lt;chr&gt;, free_elig_1112 &lt;chr&gt;, ## # free_per_1112 &lt;chr&gt;, red_elig_1112 &lt;chr&gt;, red_per_1112 &lt;chr&gt;, ## # totalFRL_1112 &lt;dbl&gt;, totalper_1112 &lt;dbl&gt;, type1213 &lt;chr&gt;, ## # lowgrade_2012 &lt;chr&gt;, higrade_2012 &lt;chr&gt;, totalFT_2012 &lt;dbl&gt;, ## # total_2012 &lt;dbl&gt;, snp_1213 &lt;chr&gt;, free_elig_1213 &lt;chr&gt;, ## # free_per_1213 &lt;chr&gt;, red_elig_1213 &lt;chr&gt;, red_per_1213 &lt;chr&gt;, ## # totalFRL_1213 &lt;dbl&gt;, totalper_1213 &lt;dbl&gt;, type1314 &lt;chr&gt;, ## # lowgrade_2013 &lt;chr&gt;, higrade_2013 &lt;chr&gt;, totalFT_2013 &lt;dbl&gt;, ## # total_2013 &lt;dbl&gt;, snp_1314 &lt;chr&gt;, free_elig_1314 &lt;chr&gt;, ## # free_per_1314 &lt;chr&gt;, red_elig_1314 &lt;chr&gt;, red_per_1314 &lt;chr&gt;, ## # totalFRL_1314 &lt;dbl&gt;, totalper_1314 &lt;dbl&gt;, type1415 &lt;chr&gt;, ## # lowgrade_2014 &lt;chr&gt;, higrade_2014 &lt;chr&gt;, totalFT_2014 &lt;dbl&gt;, ## # total_2014 &lt;dbl&gt;, snp_1415 &lt;chr&gt;, free_elig_1415 &lt;chr&gt;, ## # free_per_1415 &lt;chr&gt;, red_elig_1415 &lt;chr&gt;, red_per_1415 &lt;chr&gt;, ## # totalFRL_1415 &lt;dbl&gt;, totalper_1415 &lt;dbl&gt;, CEP_1516 &lt;chr&gt;, type1516 &lt;chr&gt;, ## # lowgrade_2015 &lt;chr&gt;, higrade_2015 &lt;chr&gt;, totalFT_2015 &lt;dbl&gt;, ## # total_2015 &lt;dbl&gt;, snp_1516 &lt;chr&gt;, free_elig_1516 &lt;chr&gt;, ## # free_per_1516 &lt;chr&gt;, red_elig_1516 &lt;chr&gt;, red_Per_1516 &lt;chr&gt;, ## # totalFRL_1516 &lt;dbl&gt;, totalper_1516 &lt;dbl&gt;, CEP_1617 &lt;chr&gt;, type1617 &lt;chr&gt;, ## # lowgrade_2016 &lt;chr&gt;, higrade_2016 &lt;chr&gt;, ... 4.7 Grouping and Summarizing Lets shift gears to a different combination of operations Lets go ahead and try using tidyverse to narrow to what we want. Imagine we want to see the county level aggregate numbers for FRL in the 2017-2018 school year. We will start out with our entire data frame and then use pipes (the %&gt;% operator) to work from there. The final result will be stored in our new data frame that we are creating, called county_level_aggregate. First, select will pick columns Next, group_by and summarize work together to get us our aggregate totals. county_level_aggregate &lt;- newdf %&gt;% select(div_name, total_2017, totalFRL_1718) %&gt;% group_by(div_name) %&gt;% summarize(totalstudents = sum(total_2017), totalFRL = sum(totalFRL_1718)) ## `summarise()` ungrouping output (override with `.groups` argument) Now, we can compute percentages if we like and we can specify a new column by referring to. One that doesnt exist yet but will after we run this code. We will do this two interchangeable ways. First, the old school way: county_level_aggregate$percent_FRL &lt;- county_level_aggregate$totalFRL/county_level_aggregate$totalstudents*100 Second, the tidyverse way: county_level_aggregate &lt;- county_level_aggregate %&gt;% mutate(percent_frl = totalFRL / totalstudents * 100) Just for fun, lets see how this could have been incorporated into our summarize call county_level_percents &lt;- newdf %&gt;% select(div_name, total_2017, totalFRL_1718) %&gt;% group_by(div_name) %&gt;% summarize(percentFRL=sum(totalFRL_1718)/sum(total_2017) * 100) ## `summarise()` ungrouping output (override with `.groups` argument) Something is going to look weird with this plot newdf %&gt;% ggplot(aes(totalFRL_0809, totalFT_2008)) + geom_point() + labs(title = &quot;FRL 2008&quot;, x = &quot;totalFRL_0809&quot;) ## Warning: Removed 236 rows containing missing values (geom_point). Lets see if we can fix it newdf %&gt;% filter(!is.na(totalFRL_0809)) %&gt;% ggplot(aes(totalFRL_0809, totalFT_2008)) + geom_point() + labs(title = &quot;FRL 2008&quot;, x = &quot;totalFRL_0809&quot;) + xlim(0, 1000) + ylim(0, 1000) ## Warning: Removed 324 rows containing missing values (geom_point). "],["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],["references.html", "References", " References "]]
