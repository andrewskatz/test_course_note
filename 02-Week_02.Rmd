# Week 2: Intro stats, Data & Distributions, Intro R & RStudio

This week, we discuss some very basic ideas related to statistics, data, and working in R. 



## First steps in R


We can create a new variable by assigning it a value with the `<-` operator. Let's create a vector of numbers 1 to 10 with the `seq()` function and then a separate vector that takes each of the x values, multiplies it by 2, and adds 3.
```{r}
x <- seq(1:10)
y <- 2* x + 3
```

Just to make sure everything worked as expected, we can then just type `x` and `y` and R will print their values. We could also look in the "environment" window to see whether those variables (and their expected values) were actually created.

```{r}
x
y

```

So far, so good. If we want to quickly visualize this, we could create a simple scatter plot with the `plot()` command (note: we will come back to plotting data much more in week 3). 

```{r}
plot(x, y)
```


## Getting your R environment set up

One of the first things you will have in any script or .rmd file is a section to load all the libraries that you use in that script.

You can install a library by using the install.packages() function, for example:

`install.packages("tidyverse")`, `install.packages("janitor")`, and `install.packages("psych")`


with this installed, you can then load the package using the library() function

```{r}
library(tidyverse)
library(janitor)
library(psych)
```




## Reading in data

A good first step when working in R is to check which directory you are working in with the `getwd()` function. You should get a directory in response.

```{r}
getwd()

```


You can also check which files are in that directory with `list.files()`.

```{r}

list.files()
```

If you notice that the file you are looking for is not there, then you can use setwd() to change your working directory

`setwd("./Week 2/")`



After that, make sure you have switched to the correct working directory
`getwd()` and then `list.files()`.

Assuming you have directed yourself to the correct place, you can now read in the file(s) that you want to be working with. There are a _lot_ of ways to do this. Since we will be spending a lot of time in class working with .csv files, we will focus on using the `read_csv()` function from the readr package (part of the tidyverse collection of packages). This function will read in the .csv file and store the data as a tibble (a tidyverse version of a data frame, which we can think of as a collection of observations stored in rows with values for variables for each observation stored in columns).

```{r}
prior_survey <- read_csv("ENGE_5714_2021_pre_survey.csv")


```


## Exploring the data

Now that we have loaded in the data, let's take a look at the csv. If we just run a line with the name of the tibble - i.e., `prior_survey` then we should receive a printout that shows the first several rows of that tibble and a listing of all the columns, along with the data types (i.e., double for numeric values, character for strings, etc) of each column.

```{r}
prior_survey

```


When we do this, we see that there are a bunch of columns that have spaces in their names. This is okay (in the sense that R can handle this), but it can be a little frustrating to work with. Let's try cleaning the column names with `clean_names()` from the janitor package. This function will replace the spaces in the column names with underscores and make everything lower case. So, a column name like "I have take a statistics course before" will be changed to "i_have_taken_a_statistics_course_before".

```{r}
prior_survey <- prior_survey %>% clean_names() # from janitor package

```

Look at the data in prior_survey again and see if anything looks different (hint: it should).
```{r}
prior_survey
```


One other function that will we see more in the future is the `table()` function, which will create a table with the counts of the values for a variable. For example, if we wanted to quickly know how students answered the "I have taken a quantitative research methods course before" question, we can run the following:

```{r}
table(prior_survey$i_have_taken_a_quantitative_research_methods_course_before)
```





## Plotting data

We will discuss plotting more next week, but here is a brief preview of what's to come...


There are multiple ways to plot data. Focusing on using ggplot, here are two.

The first way passes the prior_survey dataframe explicitly to ggplot
```{r}
ggplot(data = prior_survey, mapping = aes(x = i_know_what_a_type_i_error_is)) +
  geom_bar() +
  coord_flip()
```

The second way does this implicitly, using the pipe operator. Note that the results should be the same.

```{r}

prior_survey %>% 
  ggplot(mapping = aes(x = i_know_what_a_type_i_error_is)) +
  geom_bar() +
  coord_flip()
```


If we wanted to get extra fancy, we could first convert the data from a wide format to a long format and then start plotting all the items together.


Converting to long format would produce something like this:
```{r}
prior_survey %>% 
  gather(key = "survey_item", value = "survey_response")
```  
  

Then we can combine that with the `group_by()` and `summarize()` functions and plot the results.
```{r}
prior_survey %>% 
  gather(key = "survey_item", value = "survey_response") %>% 
  group_by(survey_item, survey_response) %>% 
  summarize(n = n()) %>% 
  ggplot(mapping = aes(x = survey_response, y = survey_item, fill = n)) +
  geom_tile()
```


This plot is okay for giving a general sense of what is going on in these plots but there are a bunch of other ways to go about doing this.

First, maybe we want to rename the response categories to a numerical scale. We can accomplish this with a `mutate()` and `case_when()`.
```{r}
prior_survey <- prior_survey %>% 
  gather(key = "survey_item", value = "survey_response") %>% 
  mutate(survey_response_num = case_when(survey_response == "Strongly disagree" ~ 0,
                                         survey_response == "Somewhat disagree" ~ 1,
                                         survey_response == "Neither agree nor disagree" ~ 2,
                                         survey_response == "Somewhat agree" ~ 3,
                                         survey_response == "Strongly agree" ~ 4,
                                         )) 
```



Then we plot the same data but with the numerical scale along the x-axis.

```{r}
prior_survey %>% 
  group_by(survey_item, survey_response_num) %>% 
  summarize(n = n()) %>% 
  ggplot(mapping = aes(x = survey_response_num, y = survey_item, fill = n)) +
  geom_tile()
```
  



## Some brief stats

In this week's reading, there was also discussion about standard errors and the central limit theorem. These are fairly important theoretical concepts to grasp. To some extent they deal with the scenario where you go out and repeatedly sample from a population and calculate a statistic from each of those samples. The distributions _of that statistic_ is what we will call the sampling distribution (as opposed to the sample distribution, which would more accurately describe the distribution of the data that we get in any one sample that we draw from the population).




### Central Limit Theorem and Standard Error Demo ----

```{r}
pop_students <- 10000

zoom_min_pop <- rnorm(n = pop_students, mean = 600, sd = 100)

hist(zoom_min_pop)


zoom_min_sample <- sample(x = zoom_min_pop,
                          size = 200,
                          replace = FALSE)


hist(zoom_min_sample)
mean(zoom_min_sample)
sd(zoom_min_sample)
```

As a brief aside, let's review the idea of a loop
```{r}
num_reps <- 100

data_vec <- rep(NA, num_reps) # this creates an empty vector of size num_reps with NA in each entry

# this loops through the vector starting at position 1 and ending at the final position (num_reps). For demonstration purposes, we replacing the NA in each entry with the number of that entry (i.e., the NA in the 20th entry is replaced with the number 20)

for (i in 1:num_reps){
  data_vec[i] <- i
}
```

Okay, so that's how we create an empty vector and how we loop through its different entries. For this demo, we will also need to remenber how to generate random numbers from a norm distribution with a specified mean and standard deviation.

```{r}
rnorm(n = 10, mean = 5, sd = 2) # n is the number of random numbers we draw from this normal distribution
```


Okay, so that's not bad. Now, that command will produce a vector with 10 random numbers. We can calculate the mean and standard deviation of those 10 numbers (which should be close to the values that we specified in `rnorm()` with the `mean()` and `sd()` functions.
```{r}
mean(rnorm(n = 10, mean = 5, sd = 2))
sd(rnorm(n = 10, mean = 5, sd = 2))
```



Next, let's act as if we are drawing a certain sample of size `samp_size` of data points for `num_reps` number of times. Keep in mind that, in practice, when we are collecting data ourselves in our own research, num_reps will almost always be 1. We are just demonstrating the underlying assumptions for how we can calculate some of the statistics that we use.

```{r}
num_reps <- 1000 # specify how many times to take a sample
samp_size <- 200 # specify the size of each sample
data_vec <- rep(NA, num_reps) # create an empty vector of size num_reps with NA in each entry.
for (i in 1:num_reps){
  data_vec[i] <- mean(rnorm(n = samp_size, mean = 600, sd = 100)) # store the mean of each of the num_rep samples
}
```

With this, we have a vector `data_vec` of size `num_reps` with the mean of each of our samples that we drew. This vector contains our sampling distribution of our sample means. **NOTE**: The standard deviation of this sampling mean is what we are calling our _standard error_. 

We can plot a histogram of this sampling distribution and calculate the standard deviation of the sampling mean.

```{r}
hist(data_vec)
sd(data_vec)
```

On your own, try copying this code and changing the num_reps and sample_size variables to larger and smaller values. Focus on how the x-axis values in your histogram change when you change the num_reps and samp_size variables.

Hint: CLT will explain the normal distribution of the sampling mean (the shape you see in the histogram) while the Weak Law of Large Numbers will explain the concentration around the true mean as samp_size increases (i.e., when we draw a larger sample size from the population, our sample mean gets closer to the population mean).


```{r}
## Quick note on the rep() function: notice what happens when you specify "each" vs "times".
rep(c(1, 2), times = 5)

rep(c(1, 2), each = 5)


```

