<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter7 Week 7: Logistic Regression | ENGE 5714 Course Notes 2021</title>
  <meta name="description" content="This is a test for organizing course notes in bookdown. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter7 Week 7: Logistic Regression | ENGE 5714 Course Notes 2021" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a test for organizing course notes in bookdown. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter7 Week 7: Logistic Regression | ENGE 5714 Course Notes 2021" />
  
  <meta name="twitter:description" content="This is a test for organizing course notes in bookdown. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Dr. Katz" />


<meta name="date" content="2021-03-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="week-6-regression-ii.html"/>
<link rel="next" href="week-8-comparing-two-means-t-tests.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ENGE 5714 - Quantitative Research Methods</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preamble</a></li>
<li class="chapter" data-level="1" data-path="week-1-introductions.html"><a href="week-1-introductions.html"><i class="fa fa-check"></i><b>1</b> Week 1: Introductions</a></li>
<li class="chapter" data-level="2" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><i class="fa fa-check"></i><b>2</b> Week 2: Intro stats, Data &amp; Distributions, Intro R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="2.1" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html#first-steps-in-r"><i class="fa fa-check"></i><b>2.1</b> First steps in R</a></li>
<li class="chapter" data-level="2.2" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html#getting-your-r-environment-set-up"><i class="fa fa-check"></i><b>2.2</b> Getting your R environment set up</a></li>
<li class="chapter" data-level="2.3" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html#reading-in-data"><i class="fa fa-check"></i><b>2.3</b> Reading in data</a></li>
<li class="chapter" data-level="2.4" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html#exploring-the-data"><i class="fa fa-check"></i><b>2.4</b> Exploring the data</a></li>
<li class="chapter" data-level="2.5" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html#plotting-data"><i class="fa fa-check"></i><b>2.5</b> Plotting data</a></li>
<li class="chapter" data-level="2.6" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html#some-brief-stats"><i class="fa fa-check"></i><b>2.6</b> Some brief stats</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="week-2-intro-stats-data-distributions-intro-r-rstudio.html"><a href="week-2-intro-stats-data-distributions-intro-r-rstudio.html#central-limit-theorem-and-standard-error-demo--"><i class="fa fa-check"></i><b>2.6.1</b> Central Limit Theorem and Standard Error Demo —-</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html"><i class="fa fa-check"></i><b>3</b> Week 3: Data Cleaning, Organizing, Describing, and Communicating</a>
<ul>
<li class="chapter" data-level="3.1" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#visualizing-your-data"><i class="fa fa-check"></i><b>3.1</b> Visualizing your data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#one-continuous-variable-either-predictor-or-outcome-variable"><i class="fa fa-check"></i><b>3.1.1</b> One continuous variable (either predictor or outcome variable)</a></li>
<li class="chapter" data-level="3.1.2" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#one-discrete-variable-either-predictor-or-outcome"><i class="fa fa-check"></i><b>3.1.2</b> One Discrete Variable (either predictor or outcome)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#joining-two-datasets"><i class="fa fa-check"></i><b>3.2</b> Joining two datasets</a></li>
<li class="chapter" data-level="3.3" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#discrete-predictor-continuous-outcome"><i class="fa fa-check"></i><b>3.3</b> Discrete Predictor, Continuous Outcome</a></li>
<li class="chapter" data-level="3.4" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#continuous-predictor-and-continuous-outcome"><i class="fa fa-check"></i><b>3.4</b> Continuous predictor and continuous outcome</a></li>
<li class="chapter" data-level="3.5" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#mutating-variables"><i class="fa fa-check"></i><b>3.5</b> Mutating Variables</a></li>
<li class="chapter" data-level="3.6" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#filtering-and-selecting"><i class="fa fa-check"></i><b>3.6</b> Filtering and Selecting</a></li>
<li class="chapter" data-level="3.7" data-path="week-3-data-cleaning-organizing-describing-and-communicating.html"><a href="week-3-data-cleaning-organizing-describing-and-communicating.html#grouping-and-summarizing"><i class="fa fa-check"></i><b>3.7</b> Grouping and Summarizing</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html"><i class="fa fa-check"></i><b>4</b> Week 4: Assumptions and Correlations</a>
<ul>
<li class="chapter" data-level="4.1" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#assumptions"><i class="fa fa-check"></i><b>4.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#normally-distributed-data"><i class="fa fa-check"></i><b>4.1.1</b> Normally distributed data</a></li>
<li class="chapter" data-level="4.1.2" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#homogeneity-of-variance"><i class="fa fa-check"></i><b>4.1.2</b> Homogeneity of variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#interval-data"><i class="fa fa-check"></i><b>4.1.3</b> Interval data</a></li>
<li class="chapter" data-level="4.1.4" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#independence"><i class="fa fa-check"></i><b>4.1.4</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#correlation"><i class="fa fa-check"></i><b>4.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#covariance"><i class="fa fa-check"></i><b>4.2.1</b> Covariance</a></li>
<li class="chapter" data-level="4.2.2" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#correlation-coefficient"><i class="fa fa-check"></i><b>4.2.2</b> Correlation coefficient</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#another-worked-example-for-cleaning-and-prelim-analysis"><i class="fa fa-check"></i><b>4.3</b> Another worked example for cleaning and prelim analysis</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#loading-in-data"><i class="fa fa-check"></i><b>4.3.1</b> Loading in data</a></li>
<li class="chapter" data-level="4.3.2" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#data-prep-and-cleaning"><i class="fa fa-check"></i><b>4.3.2</b> Data prep and cleaning</a></li>
<li class="chapter" data-level="4.3.3" data-path="week-4-assumptions-and-correlations.html"><a href="week-4-assumptions-and-correlations.html#preliminary-analysis"><i class="fa fa-check"></i><b>4.3.3</b> Preliminary analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="week-5-simple-regression.html"><a href="week-5-simple-regression.html"><i class="fa fa-check"></i><b>5</b> Week 5: Simple Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="week-5-simple-regression.html"><a href="week-5-simple-regression.html#general-modeling-philosophy"><i class="fa fa-check"></i><b>5.1</b> General Modeling Philosophy</a></li>
<li class="chapter" data-level="5.2" data-path="week-5-simple-regression.html"><a href="week-5-simple-regression.html#data-generation-demo---one-set-sample-size"><i class="fa fa-check"></i><b>5.2</b> Data generation demo - one set sample size</a></li>
<li class="chapter" data-level="5.3" data-path="week-5-simple-regression.html"><a href="week-5-simple-regression.html#data-generation-demo---one-set-sample-size-1"><i class="fa fa-check"></i><b>5.3</b> Data generation demo - one set sample size;</a></li>
<li class="chapter" data-level="5.4" data-path="week-5-simple-regression.html"><a href="week-5-simple-regression.html#data-generation-with-three-different-sample-sizes"><i class="fa fa-check"></i><b>5.4</b> Data generation with three different sample sizes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="week-6-regression-ii.html"><a href="week-6-regression-ii.html"><i class="fa fa-check"></i><b>6</b> Week 6: Regression II</a>
<ul>
<li class="chapter" data-level="6.1" data-path="week-6-regression-ii.html"><a href="week-6-regression-ii.html#explore-the-child-aggression-data-set"><i class="fa fa-check"></i><b>6.1</b> Explore the child aggression data set</a></li>
<li class="chapter" data-level="6.2" data-path="week-6-regression-ii.html"><a href="week-6-regression-ii.html#multiple-regression"><i class="fa fa-check"></i><b>6.2</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="week-6-regression-ii.html"><a href="week-6-regression-ii.html#assumption-testing"><i class="fa fa-check"></i><b>6.2.1</b> Assumption testing</a></li>
<li class="chapter" data-level="6.2.2" data-path="week-6-regression-ii.html"><a href="week-6-regression-ii.html#detour-cumulative-distribution-function-cdf-empirical-cdf-and-qq-plot-discussion"><i class="fa fa-check"></i><b>6.2.2</b> Detour: Cumulative Distribution Function (CDF), empirical CDF, and QQ Plot Discussion</a></li>
<li class="chapter" data-level="6.2.3" data-path="week-6-regression-ii.html"><a href="week-6-regression-ii.html#generating-data-for-student-happiness-exercise."><i class="fa fa-check"></i><b>6.2.3</b> Generating data for student happiness exercise.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="week-7-logistic-regression.html"><a href="week-7-logistic-regression.html"><i class="fa fa-check"></i><b>7</b> Week 7: Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="week-7-logistic-regression.html"><a href="week-7-logistic-regression.html#round-1---no-systematic-variation-in-outcomes"><i class="fa fa-check"></i><b>7.1</b> Round 1 - No systematic variation in outcomes</a></li>
<li class="chapter" data-level="7.2" data-path="week-7-logistic-regression.html"><a href="week-7-logistic-regression.html#round-2---systematic-varation-in-outcomes-as-a-function-of-discipline"><i class="fa fa-check"></i><b>7.2</b> Round 2 - Systematic varation in outcomes as a function of discipline</a></li>
<li class="chapter" data-level="7.3" data-path="week-7-logistic-regression.html"><a href="week-7-logistic-regression.html#round-3---systematic-varation-in-outcomes-as-a-function-of-discipline-and-gpa"><i class="fa fa-check"></i><b>7.3</b> Round 3 - Systematic varation in outcomes as a function of discipline and gpa</a></li>
<li class="chapter" data-level="7.4" data-path="week-7-logistic-regression.html"><a href="week-7-logistic-regression.html#round-4---gpa-and-persistence-vary-by-discipline"><i class="fa fa-check"></i><b>7.4</b> Round 4 - GPA and persistence vary by discipline</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="week-7-logistic-regression.html"><a href="week-7-logistic-regression.html#interlude-looking-at-poisson-distribution"><i class="fa fa-check"></i><b>7.4.1</b> Interlude looking at poisson distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="week-8-comparing-two-means-t-tests.html"><a href="week-8-comparing-two-means-t-tests.html"><i class="fa fa-check"></i><b>8</b> Week 8: Comparing two means (t-tests)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="week-8-comparing-two-means-t-tests.html"><a href="week-8-comparing-two-means-t-tests.html#demo-1---comparing-salary-data-for-chemical-engineering-and-environmental-engineering"><i class="fa fa-check"></i><b>8.1</b> Demo 1 - Comparing salary data for chemical engineering and environmental engineering</a></li>
<li class="chapter" data-level="8.2" data-path="week-8-comparing-two-means-t-tests.html"><a href="week-8-comparing-two-means-t-tests.html#demo-2---student-sat-scores"><i class="fa fa-check"></i><b>8.2</b> Demo 2 - Student SAT scores</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ENGE 5714 Course Notes 2021</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="week-7-logistic-regression" class="section level1" number="7">
<h1><span class="header-section-number">Chapter7</span> Week 7: Logistic Regression</h1>
<p>To study how to run a logistic regression model in R, we are going to create simulate some data.</p>
<p>NOTE: Simulating data is a good way to get a sense of how the model works since you already know the data-generate process that you are trying to characterize with the model. This means you already know the “ground truth.” In practice, we do not have this luxury when we run our studies - it is this “ground truth” that we’re looking for.
Nonetheless, it can be helpful to remove one piece of uncertainty when learning the technical aspects by using data that are already characterized because you made them.</p>
<p>We will proceed through several rounds of data generation to see how the model may vary.</p>
<div id="round-1---no-systematic-variation-in-outcomes" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Round 1 - No systematic variation in outcomes</h2>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="week-7-logistic-regression.html#cb359-1" aria-hidden="true" tabindex="-1"></a>disciplines <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;civil&quot;</span>, <span class="st">&quot;mechanical&quot;</span>, <span class="st">&quot;electrical&quot;</span>, <span class="st">&quot;systems&quot;</span>)</span>
<span id="cb359-2"><a href="week-7-logistic-regression.html#cb359-2" aria-hidden="true" tabindex="-1"></a>disciplines_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.3</span>, <span class="fl">0.35</span>, <span class="fl">0.1</span>)</span>
<span id="cb359-3"><a href="week-7-logistic-regression.html#cb359-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-4"><a href="week-7-logistic-regression.html#cb359-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-5"><a href="week-7-logistic-regression.html#cb359-5" aria-hidden="true" tabindex="-1"></a>know_engineer <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;immediate_fam&quot;</span>, <span class="st">&quot;distant_fam&quot;</span>, <span class="st">&quot;friend&quot;</span>, <span class="st">&quot;none&quot;</span>)</span>
<span id="cb359-6"><a href="week-7-logistic-regression.html#cb359-6" aria-hidden="true" tabindex="-1"></a>know_engineer_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>)</span>
<span id="cb359-7"><a href="week-7-logistic-regression.html#cb359-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-8"><a href="week-7-logistic-regression.html#cb359-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-9"><a href="week-7-logistic-regression.html#cb359-9" aria-hidden="true" tabindex="-1"></a>persistence <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>, <span class="st">&quot;no&quot;</span>)</span>
<span id="cb359-10"><a href="week-7-logistic-regression.html#cb359-10" aria-hidden="true" tabindex="-1"></a>persistence_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.2</span>)</span></code></pre></div>
<p>Now we will generate the actual sample of 500 students</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="week-7-logistic-regression.html#cb360-1" aria-hidden="true" tabindex="-1"></a>samp_size <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb360-2"><a href="week-7-logistic-regression.html#cb360-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb360-3"><a href="week-7-logistic-regression.html#cb360-3" aria-hidden="true" tabindex="-1"></a>disc_samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> disciplines, <span class="at">size =</span> samp_size, <span class="at">prob =</span> disciplines_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb360-4"><a href="week-7-logistic-regression.html#cb360-4" aria-hidden="true" tabindex="-1"></a>know_samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> know_engineer, <span class="at">size =</span> samp_size, <span class="at">prob =</span> know_engineer_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb360-5"><a href="week-7-logistic-regression.html#cb360-5" aria-hidden="true" tabindex="-1"></a>pers_samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> persistence, <span class="at">size =</span> samp_size, <span class="at">prob =</span> persistence_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb360-6"><a href="week-7-logistic-regression.html#cb360-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb360-7"><a href="week-7-logistic-regression.html#cb360-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb360-8"><a href="week-7-logistic-regression.html#cb360-8" aria-hidden="true" tabindex="-1"></a>samp_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">discipline =</span> disc_samp,</span>
<span id="cb360-9"><a href="week-7-logistic-regression.html#cb360-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">know_eng =</span> know_samp,</span>
<span id="cb360-10"><a href="week-7-logistic-regression.html#cb360-10" aria-hidden="true" tabindex="-1"></a>                  <span class="at">persist =</span> pers_samp,</span>
<span id="cb360-11"><a href="week-7-logistic-regression.html#cb360-11" aria-hidden="true" tabindex="-1"></a>                  <span class="at">gpa =</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="at">n =</span> samp_size, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="fl">0.3</span>), <span class="dv">2</span>))</span></code></pre></div>
<p>Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis</p>
<p>First, add in a new binary column for the persistence variable (coding “yes” as 1 and “no” as 0)</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="week-7-logistic-regression.html#cb361-1" aria-hidden="true" tabindex="-1"></a>samp_df <span class="ot">&lt;-</span> samp_df <span class="sc">%&gt;%</span> </span>
<span id="cb361-2"><a href="week-7-logistic-regression.html#cb361-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">persist_bin =</span> <span class="fu">case_when</span>(persist <span class="sc">==</span> <span class="st">&quot;yes&quot;</span> <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb361-3"><a href="week-7-logistic-regression.html#cb361-3" aria-hidden="true" tabindex="-1"></a>                                 persist <span class="sc">==</span> <span class="st">&quot;no&quot;</span> <span class="sc">~</span> <span class="dv">0</span>))</span></code></pre></div>
<p>Second, get a sense of the distributions of some of the variables in our model</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="week-7-logistic-regression.html#cb362-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(samp_df)</span></code></pre></div>
<pre><code>## tibble [500 x 5] (S3: tbl_df/tbl/data.frame)
##  $ discipline : chr [1:500] &quot;systems&quot; &quot;electrical&quot; &quot;electrical&quot; &quot;mechanical&quot; ...
##  $ know_eng   : chr [1:500] &quot;none&quot; &quot;distant_fam&quot; &quot;immediate_fam&quot; &quot;friend&quot; ...
##  $ persist    : chr [1:500] &quot;yes&quot; &quot;no&quot; &quot;yes&quot; &quot;yes&quot; ...
##  $ gpa        : num [1:500] 3.16 3 3.42 3.08 2.98 2.74 2.95 2.79 3.24 3.32 ...
##  $ persist_bin: num [1:500] 1 0 1 1 1 1 1 0 0 0 ...</code></pre>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="week-7-logistic-regression.html#cb364-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(samp_df<span class="sc">$</span>persist)</span></code></pre></div>
<pre><code>## 
##  no yes 
##  91 409</code></pre>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="week-7-logistic-regression.html#cb366-1" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(samp_df)</span></code></pre></div>
<pre><code>## Warning in describe(samp_df): NAs introduced by coercion

## Warning in describe(samp_df): NAs introduced by coercion

## Warning in describe(samp_df): NAs introduced by coercion</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf</code></pre>
<pre><code>##             vars   n mean   sd median trimmed mad  min  max range  skew
## discipline*    1 500  NaN   NA     NA     NaN  NA  Inf -Inf  -Inf    NA
## know_eng*      2 500  NaN   NA     NA     NaN  NA  Inf -Inf  -Inf    NA
## persist*       3 500  NaN   NA     NA     NaN  NA  Inf -Inf  -Inf    NA
## gpa            4 500 3.01 0.31   3.01    3.01 0.3 2.03 3.91  1.88 -0.01
## persist_bin    5 500 0.82 0.39   1.00    0.90 0.0 0.00 1.00  1.00 -1.64
##             kurtosis   se
## discipline*       NA   NA
## know_eng*         NA   NA
## persist*          NA   NA
## gpa            -0.06 0.01
## persist_bin     0.70 0.02</code></pre>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="week-7-logistic-regression.html#cb371-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(samp_df<span class="sc">$</span>discipline)</span></code></pre></div>
<pre><code>## 
##      civil electrical mechanical    systems 
##        128        185        144         43</code></pre>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="week-7-logistic-regression.html#cb373-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span>(<span class="sc">~</span> discipline <span class="sc">+</span> persist_bin, <span class="at">data =</span> samp_df)</span></code></pre></div>
<pre><code>##             persist_bin
## discipline     0   1
##   civil       28 100
##   electrical  34 151
##   mechanical  21 123
##   systems      8  35</code></pre>
<p>Third, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="week-7-logistic-regression.html#cb375-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(persist_bin <span class="sc">~</span> discipline <span class="sc">+</span> know_eng <span class="sc">+</span> gpa, <span class="at">data =</span> samp_df, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb375-2"><a href="week-7-logistic-regression.html#cb375-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1568   0.5063   0.6005   0.6719   0.8277  
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)             2.2773     1.1906   1.913   0.0558 .
## disciplineelectrical    0.2254     0.2873   0.785   0.4327  
## disciplinemechanical    0.5008     0.3200   1.565   0.1175  
## disciplinesystems       0.1977     0.4483   0.441   0.6592  
## know_engfriend          0.1037     0.2672   0.388   0.6979  
## know_engimmediate_fam   0.5073     0.3589   1.414   0.1574  
## know_engnone            0.3165     0.4495   0.704   0.4814  
## gpa                    -0.3808     0.3797  -1.003   0.3159  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 474.41  on 499  degrees of freedom
## Residual deviance: 468.21  on 492  degrees of freedom
## AIC: 484.21
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="week-7-logistic-regression.html#cb377-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(model)</span></code></pre></div>
<pre><code>## # A tibble: 8 x 5
##   term                  estimate std.error statistic p.value
##   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)              2.28      1.19      1.91   0.0558
## 2 disciplineelectrical     0.225     0.287     0.785  0.433 
## 3 disciplinemechanical     0.501     0.320     1.57   0.118 
## 4 disciplinesystems        0.198     0.448     0.441  0.659 
## 5 know_engfriend           0.104     0.267     0.388  0.698 
## 6 know_engimmediate_fam    0.507     0.359     1.41   0.157 
## 7 know_engnone             0.317     0.450     0.704  0.481 
## 8 gpa                     -0.381     0.380    -1.00   0.316</code></pre>
<p>Since we generated the data without any relationships between the predictors and the binary outcome, we do not expect any of the predictor variables to be statistically significant. Sometimes there will be a significant predictor, but that emphasizes the idea p values are not necessarily the most reliable indicator of importance.</p>
</div>
<div id="round-2---systematic-varation-in-outcomes-as-a-function-of-discipline" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Round 2 - Systematic varation in outcomes as a function of discipline</h2>
<p>Now, to introduce some systematic variation, we will change the probabilities of persistence (the outcome variable we are modeling) as a function of major but not as a function of the other two predictors</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="week-7-logistic-regression.html#cb379-1" aria-hidden="true" tabindex="-1"></a>disciplines <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;civil&quot;</span>, <span class="st">&quot;mechanical&quot;</span>, <span class="st">&quot;electrical&quot;</span>, <span class="st">&quot;systems&quot;</span>)</span>
<span id="cb379-2"><a href="week-7-logistic-regression.html#cb379-2" aria-hidden="true" tabindex="-1"></a>disciplines_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.3</span>, <span class="fl">0.35</span>, <span class="fl">0.1</span>)</span>
<span id="cb379-3"><a href="week-7-logistic-regression.html#cb379-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-4"><a href="week-7-logistic-regression.html#cb379-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-5"><a href="week-7-logistic-regression.html#cb379-5" aria-hidden="true" tabindex="-1"></a>know_engineer <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;immediate_fam&quot;</span>, <span class="st">&quot;distant_fam&quot;</span>, <span class="st">&quot;friend&quot;</span>, <span class="st">&quot;none&quot;</span>)</span>
<span id="cb379-6"><a href="week-7-logistic-regression.html#cb379-6" aria-hidden="true" tabindex="-1"></a>know_engineer_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>)</span></code></pre></div>
<p>We generate the actual data here.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="week-7-logistic-regression.html#cb380-1" aria-hidden="true" tabindex="-1"></a>samp_size <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb380-2"><a href="week-7-logistic-regression.html#cb380-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb380-3"><a href="week-7-logistic-regression.html#cb380-3" aria-hidden="true" tabindex="-1"></a>disc_samp_2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> disciplines, <span class="at">size =</span> samp_size, <span class="at">prob =</span> disciplines_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb380-4"><a href="week-7-logistic-regression.html#cb380-4" aria-hidden="true" tabindex="-1"></a>know_samp_2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> know_engineer, <span class="at">size =</span> samp_size, <span class="at">prob =</span> know_engineer_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb380-5"><a href="week-7-logistic-regression.html#cb380-5" aria-hidden="true" tabindex="-1"></a><span class="co">#pers_samp_2 &lt;- sample(x = persistence, size = samp_size, prob = persistence_prob, replace = TRUE)</span></span></code></pre></div>
<p>Now we will combine our data into one dataframe.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="week-7-logistic-regression.html#cb381-1" aria-hidden="true" tabindex="-1"></a>samp_df_2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">discipline =</span> disc_samp_2,</span>
<span id="cb381-2"><a href="week-7-logistic-regression.html#cb381-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">know_eng =</span> know_samp_2,</span>
<span id="cb381-3"><a href="week-7-logistic-regression.html#cb381-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">gpa =</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="at">n =</span> samp_size, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="fl">0.3</span>), <span class="dv">2</span>))</span></code></pre></div>
<p>Now we want to have some different outcomes whose probabilities vary by discipline. We’ll create a new column called persist_prob that describes the probability of persisting from year one to year two (e.g., 0.6 means there is a 0.6 prob of a student persisting)</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="week-7-logistic-regression.html#cb382-1" aria-hidden="true" tabindex="-1"></a>samp_df_2 <span class="ot">&lt;-</span> samp_df_2 <span class="sc">%&gt;%</span> </span>
<span id="cb382-2"><a href="week-7-logistic-regression.html#cb382-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">persist_prob =</span> <span class="fu">case_when</span>(discipline <span class="sc">==</span> <span class="st">&quot;civil&quot;</span> <span class="sc">~</span> <span class="fl">0.6</span>,</span>
<span id="cb382-3"><a href="week-7-logistic-regression.html#cb382-3" aria-hidden="true" tabindex="-1"></a>                             discipline <span class="sc">==</span> <span class="st">&quot;mechanical&quot;</span> <span class="sc">~</span> <span class="fl">0.7</span>,</span>
<span id="cb382-4"><a href="week-7-logistic-regression.html#cb382-4" aria-hidden="true" tabindex="-1"></a>                             discipline <span class="sc">==</span> <span class="st">&quot;electrical&quot;</span> <span class="sc">~</span> <span class="fl">0.8</span>,</span>
<span id="cb382-5"><a href="week-7-logistic-regression.html#cb382-5" aria-hidden="true" tabindex="-1"></a>                             discipline <span class="sc">==</span> <span class="st">&quot;systems&quot;</span> <span class="sc">~</span> <span class="fl">0.9</span>))</span></code></pre></div>
<p>We will create a vector that samples depending on the value of the persistence probability at that index. That value varies depending on the discipline for that student at that index value in the vector.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="week-7-logistic-regression.html#cb383-1" aria-hidden="true" tabindex="-1"></a>persist_outcome <span class="ot">&lt;-</span> <span class="fu">modify</span>(<span class="at">.x =</span> samp_df_2<span class="sc">$</span>persist_prob, <span class="at">.f =</span> <span class="sc">~</span><span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> .x))</span></code></pre></div>
<p>Now we add that persistence outcome column to our dataframe</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="week-7-logistic-regression.html#cb384-1" aria-hidden="true" tabindex="-1"></a>samp_df_2<span class="sc">$</span>persist_bin <span class="ot">&lt;-</span> persist_outcome</span></code></pre></div>
<p>Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis,</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="week-7-logistic-regression.html#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(samp_df_2)</span></code></pre></div>
<pre><code>## tibble [5,000 x 5] (S3: tbl_df/tbl/data.frame)
##  $ discipline  : chr [1:5000] &quot;electrical&quot; &quot;mechanical&quot; &quot;electrical&quot; &quot;electrical&quot; ...
##  $ know_eng    : chr [1:5000] &quot;friend&quot; &quot;distant_fam&quot; &quot;distant_fam&quot; &quot;distant_fam&quot; ...
##  $ gpa         : num [1:5000] 3.5 3.07 3.03 2.57 3.13 2.8 2.76 3.42 3.01 2.85 ...
##  $ persist_prob: num [1:5000] 0.8 0.7 0.8 0.8 0.6 0.8 0.6 0.9 0.6 0.6 ...
##  $ persist_bin : num [1:5000] 1 1 1 1 1 1 0 1 1 0 ...</code></pre>
<p>Let’s check on the distribution of persistence by major. xtabs() is a function that creates a contingency table (more on that in 2 weeks)</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="week-7-logistic-regression.html#cb387-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span>(<span class="sc">~</span> persist_bin <span class="sc">+</span> discipline, <span class="at">data=</span>samp_df_2)</span></code></pre></div>
<pre><code>##            discipline
## persist_bin civil electrical mechanical systems
##           0   526        326        477      60
##           1   737       1357       1064     453</code></pre>
<p>Or we can use <code>describe()</code></p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="week-7-logistic-regression.html#cb389-1" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(samp_df_2)</span></code></pre></div>
<pre><code>## Warning in describe(samp_df_2): NAs introduced by coercion

## Warning in describe(samp_df_2): NAs introduced by coercion</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf</code></pre>
<pre><code>##              vars    n mean   sd median trimmed  mad  min  max range  skew
## discipline*     1 5000  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## know_eng*       2 5000  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## gpa             3 5000 3.01 0.30    3.0    3.01 0.30 1.91 4.12  2.21  0.06
## persist_prob    4 5000 0.73 0.10    0.7    0.72 0.15 0.60 0.90  0.30  0.10
## persist_bin     5 5000 0.72 0.45    1.0    0.78 0.00 0.00 1.00  1.00 -0.99
##              kurtosis   se
## discipline*        NA   NA
## know_eng*          NA   NA
## gpa              0.06 0.00
## persist_prob    -1.02 0.00
## persist_bin     -1.02 0.01</code></pre>
<p>Or even use <code>table()</code></p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="week-7-logistic-regression.html#cb394-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(samp_df_2<span class="sc">$</span>discipline)</span></code></pre></div>
<pre><code>## 
##      civil electrical mechanical    systems 
##       1263       1683       1541        513</code></pre>
<p>Now, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="week-7-logistic-regression.html#cb396-1" aria-hidden="true" tabindex="-1"></a>model_2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(persist_bin <span class="sc">~</span> discipline <span class="sc">+</span> know_eng <span class="sc">+</span> gpa, <span class="at">data =</span> samp_df_2, <span class="at">family =</span> <span class="fu">binomial</span>())</span></code></pre></div>
<p>And examine the model output with either <code>summary()</code>…</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="week-7-logistic-regression.html#cb397-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df_2)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1424  -1.2855   0.6611   0.8680   1.0852  
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)            0.35145    0.33153   1.060  0.28911    
## disciplineelectrical   1.08537    0.08412  12.902  &lt; 2e-16 ***
## disciplinemechanical   0.46340    0.07944   5.834 5.42e-09 ***
## disciplinesystems      1.68832    0.14888  11.340  &lt; 2e-16 ***
## know_engfriend         0.23347    0.07935   2.942  0.00326 ** 
## know_engimmediate_fam  0.08323    0.08782   0.948  0.34328    
## know_engnone           0.06379    0.11337   0.563  0.57363    
## gpa                   -0.03448    0.10778  -0.320  0.74907    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 5908.6  on 4999  degrees of freedom
## Residual deviance: 5638.2  on 4992  degrees of freedom
## AIC: 5654.2
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>…or <code>tidy()</code></p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="week-7-logistic-regression.html#cb399-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(model_2)</span></code></pre></div>
<pre><code>## # A tibble: 8 x 5
##   term                  estimate std.error statistic  p.value
##   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)             0.351     0.332      1.06  2.89e- 1
## 2 disciplineelectrical    1.09      0.0841    12.9   4.38e-38
## 3 disciplinemechanical    0.463     0.0794     5.83  5.42e- 9
## 4 disciplinesystems       1.69      0.149     11.3   8.27e-30
## 5 know_engfriend          0.233     0.0794     2.94  3.26e- 3
## 6 know_engimmediate_fam   0.0832    0.0878     0.948 3.43e- 1
## 7 know_engnone            0.0638    0.113      0.563 5.74e- 1
## 8 gpa                    -0.0345    0.108     -0.320 7.49e- 1</code></pre>
</div>
<div id="round-3---systematic-varation-in-outcomes-as-a-function-of-discipline-and-gpa" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Round 3 - Systematic varation in outcomes as a function of discipline and gpa</h2>
<p>Now, to introduce some systematic variation, we will change the probabilities of persistence (the outcome variable we are modeling) as a function of major and gpa but not as a function of knowing an engineer.</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="week-7-logistic-regression.html#cb401-1" aria-hidden="true" tabindex="-1"></a>disciplines <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;civil&quot;</span>, <span class="st">&quot;mechanical&quot;</span>, <span class="st">&quot;electrical&quot;</span>, <span class="st">&quot;systems&quot;</span>)</span>
<span id="cb401-2"><a href="week-7-logistic-regression.html#cb401-2" aria-hidden="true" tabindex="-1"></a>disciplines_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.3</span>, <span class="fl">0.35</span>, <span class="fl">0.1</span>)</span>
<span id="cb401-3"><a href="week-7-logistic-regression.html#cb401-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb401-4"><a href="week-7-logistic-regression.html#cb401-4" aria-hidden="true" tabindex="-1"></a>know_engineer <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;immediate_fam&quot;</span>, <span class="st">&quot;distant_fam&quot;</span>, <span class="st">&quot;friend&quot;</span>, <span class="st">&quot;none&quot;</span>)</span>
<span id="cb401-5"><a href="week-7-logistic-regression.html#cb401-5" aria-hidden="true" tabindex="-1"></a>know_engineer_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>)</span></code></pre></div>
<p>Simulate the dataf or disciplines, knowing an engineer, and the persistence outcome</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="week-7-logistic-regression.html#cb402-1" aria-hidden="true" tabindex="-1"></a>samp_size <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb402-2"><a href="week-7-logistic-regression.html#cb402-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-3"><a href="week-7-logistic-regression.html#cb402-3" aria-hidden="true" tabindex="-1"></a>disc_samp_3 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> disciplines, <span class="at">size =</span> samp_size, <span class="at">prob =</span> disciplines_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb402-4"><a href="week-7-logistic-regression.html#cb402-4" aria-hidden="true" tabindex="-1"></a>know_samp_3 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> know_engineer, <span class="at">size =</span> samp_size, <span class="at">prob =</span> know_engineer_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb402-5"><a href="week-7-logistic-regression.html#cb402-5" aria-hidden="true" tabindex="-1"></a>pers_samp_3 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> persistence, <span class="at">size =</span> samp_size, <span class="at">prob =</span> persistence_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>And combine all the generated data into one dataframe with <code>tibble()</code>.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="week-7-logistic-regression.html#cb403-1" aria-hidden="true" tabindex="-1"></a>samp_df_3 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">discipline =</span> disc_samp_3,</span>
<span id="cb403-2"><a href="week-7-logistic-regression.html#cb403-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">know_eng =</span> know_samp_3,</span>
<span id="cb403-3"><a href="week-7-logistic-regression.html#cb403-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">persist =</span> pers_samp_3)</span></code></pre></div>
<p>Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting out analysis</p>
<p>To run the logistic regression, we need our outcome coded as 0/1, not no/yes to address this, we add in a new binary column for the persistence variable (coding “yes” as 1 and “no” as 0)</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="week-7-logistic-regression.html#cb404-1" aria-hidden="true" tabindex="-1"></a>samp_df_3 <span class="ot">&lt;-</span> samp_df_3 <span class="sc">%&gt;%</span> </span>
<span id="cb404-2"><a href="week-7-logistic-regression.html#cb404-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">persist_bin =</span> <span class="fu">case_when</span>(persist <span class="sc">==</span> <span class="st">&quot;yes&quot;</span> <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb404-3"><a href="week-7-logistic-regression.html#cb404-3" aria-hidden="true" tabindex="-1"></a>                                 persist <span class="sc">==</span> <span class="st">&quot;no&quot;</span> <span class="sc">~</span> <span class="dv">0</span>))</span></code></pre></div>
<p>Now, since we want to look at the potential effect of gpa on persistence, we create a bookkeeping column for gpa_mean for students who do and do not persist to year two.</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="week-7-logistic-regression.html#cb405-1" aria-hidden="true" tabindex="-1"></a>samp_df_3 <span class="ot">&lt;-</span> samp_df_3 <span class="sc">%&gt;%</span> </span>
<span id="cb405-2"><a href="week-7-logistic-regression.html#cb405-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gpa_mean =</span> <span class="fu">case_when</span>(persist <span class="sc">==</span> <span class="st">&quot;yes&quot;</span> <span class="sc">~</span> <span class="fl">3.4</span>,</span>
<span id="cb405-3"><a href="week-7-logistic-regression.html#cb405-3" aria-hidden="true" tabindex="-1"></a>                              persist <span class="sc">==</span> <span class="st">&quot;no&quot;</span> <span class="sc">~</span> <span class="fl">3.0</span>))</span></code></pre></div>
<p>Simulate the gpa data</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="week-7-logistic-regression.html#cb406-1" aria-hidden="true" tabindex="-1"></a>gpa_vec <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">modify</span>(<span class="at">.x =</span> samp_df_3<span class="sc">$</span>gpa_mean, <span class="at">.f =</span> <span class="sc">~</span><span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">1</span>, <span class="at">mean =</span> .x, <span class="at">sd =</span> .<span class="dv">2</span>)), <span class="dv">2</span>)</span></code></pre></div>
<p>Add the simulated data back to our data frame</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="week-7-logistic-regression.html#cb407-1" aria-hidden="true" tabindex="-1"></a>samp_df_3<span class="sc">$</span>gpa <span class="ot">&lt;-</span> gpa_vec</span></code></pre></div>
<p>Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis</p>
<p>Check the structure of the dataframe to make sure it looks as expected</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="week-7-logistic-regression.html#cb408-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(samp_df_3)</span></code></pre></div>
<pre><code>## tibble [500 x 6] (S3: tbl_df/tbl/data.frame)
##  $ discipline : chr [1:500] &quot;mechanical&quot; &quot;electrical&quot; &quot;civil&quot; &quot;civil&quot; ...
##  $ know_eng   : chr [1:500] &quot;friend&quot; &quot;immediate_fam&quot; &quot;immediate_fam&quot; &quot;distant_fam&quot; ...
##  $ persist    : chr [1:500] &quot;yes&quot; &quot;yes&quot; &quot;yes&quot; &quot;yes&quot; ...
##  $ persist_bin: num [1:500] 1 1 1 1 1 1 1 1 0 1 ...
##  $ gpa_mean   : num [1:500] 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3 3.4 ...
##  $ gpa        : num [1:500] 3.45 3.82 3.42 3.63 3.45 3.26 3.83 3.23 3.15 3.14 ...</code></pre>
<p>Let’s check on the distribution of persistence by major. xtabs() is a function that creates a contingency table (more on that in 2 weeks)</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="week-7-logistic-regression.html#cb410-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span>(<span class="sc">~</span> persist_bin <span class="sc">+</span> discipline, <span class="at">data=</span>samp_df_3)</span></code></pre></div>
<pre><code>##            discipline
## persist_bin civil electrical mechanical systems
##           0    30         35         36       5
##           1   100        127        130      37</code></pre>
<p>…or with <code>describe()</code>…</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="week-7-logistic-regression.html#cb412-1" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(samp_df_3)</span></code></pre></div>
<pre><code>## Warning in describe(samp_df_3): NAs introduced by coercion

## Warning in describe(samp_df_3): NAs introduced by coercion

## Warning in describe(samp_df_3): NAs introduced by coercion</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf</code></pre>
<pre><code>##             vars   n mean   sd median trimmed  mad  min  max range  skew
## discipline*    1 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## know_eng*      2 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## persist*       3 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## persist_bin    4 500 0.79 0.41   1.00    0.86 0.00 0.00 1.00  1.00 -1.41
## gpa_mean       5 500 3.32 0.16   3.40    3.34 0.00 3.00 3.40  0.40 -1.41
## gpa            6 500 3.31 0.26   3.34    3.32 0.27 2.56 3.88  1.32 -0.34
##             kurtosis   se
## discipline*       NA   NA
## know_eng*         NA   NA
## persist*          NA   NA
## persist_bin    -0.03 0.02
## gpa_mean       -0.03 0.01
## gpa            -0.24 0.01</code></pre>
<p>…or with <code>table()</code>.</p>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="week-7-logistic-regression.html#cb417-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(samp_df_3<span class="sc">$</span>discipline)</span></code></pre></div>
<pre><code>## 
##      civil electrical mechanical    systems 
##        130        162        166         42</code></pre>
<p>Check the distribution of the gpa values by discipline, just to make sure</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="week-7-logistic-regression.html#cb419-1" aria-hidden="true" tabindex="-1"></a>samp_df_3 <span class="sc">%&gt;%</span> </span>
<span id="cb419-2"><a href="week-7-logistic-regression.html#cb419-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> gpa, <span class="at">fill =</span> discipline)) <span class="sc">+</span></span>
<span id="cb419-3"><a href="week-7-logistic-regression.html#cb419-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">position =</span> <span class="st">&quot;identity&quot;</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="test_course_notes_files/figure-html/unnamed-chunk-176-1.png" width="672" /></p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="week-7-logistic-regression.html#cb421-1" aria-hidden="true" tabindex="-1"></a><span class="co"># be sure to put alpha before position</span></span></code></pre></div>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="week-7-logistic-regression.html#cb422-1" aria-hidden="true" tabindex="-1"></a>samp_df_3 <span class="sc">%&gt;%</span> </span>
<span id="cb422-2"><a href="week-7-logistic-regression.html#cb422-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> gpa, <span class="at">fill =</span> persist)) <span class="sc">+</span></span>
<span id="cb422-3"><a href="week-7-logistic-regression.html#cb422-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">position =</span> <span class="st">&quot;identity&quot;</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="test_course_notes_files/figure-html/unnamed-chunk-177-1.png" width="672" /></p>
<p>Now, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="week-7-logistic-regression.html#cb424-1" aria-hidden="true" tabindex="-1"></a>model_3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(persist_bin <span class="sc">~</span> discipline <span class="sc">+</span> know_eng <span class="sc">+</span> gpa, <span class="at">data =</span> samp_df_3, <span class="at">family =</span> <span class="fu">binomial</span>())</span></code></pre></div>
<p>And examine the results with <code>summary()</code> or <code>tidy()</code></p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="week-7-logistic-regression.html#cb425-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_3)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df_3)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.95665   0.05105   0.18222   0.41311   2.17923  
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)           -30.9280     3.1802  -9.725   &lt;2e-16 ***
## disciplineelectrical    0.6007     0.4104   1.464    0.143    
## disciplinemechanical    0.1713     0.4070   0.421    0.674    
## disciplinesystems       1.1028     0.6992   1.577    0.115    
## know_engfriend         -0.4395     0.3893  -1.129    0.259    
## know_engimmediate_fam  -0.1139     0.4268  -0.267    0.790    
## know_engnone           -0.6012     0.5407  -1.112    0.266    
## gpa                    10.0531     1.0073   9.980   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 516.59  on 499  degrees of freedom
## Residual deviance: 274.07  on 492  degrees of freedom
## AIC: 290.07
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="week-7-logistic-regression.html#cb427-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(model_3)</span></code></pre></div>
<pre><code>## # A tibble: 8 x 5
##   term                  estimate std.error statistic  p.value
##   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)            -30.9       3.18     -9.73  2.35e-22
## 2 disciplineelectrical     0.601     0.410     1.46  1.43e- 1
## 3 disciplinemechanical     0.171     0.407     0.421 6.74e- 1
## 4 disciplinesystems        1.10      0.699     1.58  1.15e- 1
## 5 know_engfriend          -0.439     0.389    -1.13  2.59e- 1
## 6 know_engimmediate_fam   -0.114     0.427    -0.267 7.90e- 1
## 7 know_engnone            -0.601     0.541    -1.11  2.66e- 1
## 8 gpa                     10.1       1.01      9.98  1.87e-23</code></pre>
</div>
<div id="round-4---gpa-and-persistence-vary-by-discipline" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Round 4 - GPA and persistence vary by discipline</h2>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="week-7-logistic-regression.html#cb429-1" aria-hidden="true" tabindex="-1"></a>disciplines <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;civil&quot;</span>, <span class="st">&quot;mechanical&quot;</span>, <span class="st">&quot;electrical&quot;</span>, <span class="st">&quot;systems&quot;</span>)</span>
<span id="cb429-2"><a href="week-7-logistic-regression.html#cb429-2" aria-hidden="true" tabindex="-1"></a>disciplines_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.3</span>, <span class="fl">0.35</span>, <span class="fl">0.1</span>)</span>
<span id="cb429-3"><a href="week-7-logistic-regression.html#cb429-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb429-4"><a href="week-7-logistic-regression.html#cb429-4" aria-hidden="true" tabindex="-1"></a>know_engineer <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;immediate_fam&quot;</span>, <span class="st">&quot;distant_fam&quot;</span>, <span class="st">&quot;friend&quot;</span>, <span class="st">&quot;none&quot;</span>)</span>
<span id="cb429-5"><a href="week-7-logistic-regression.html#cb429-5" aria-hidden="true" tabindex="-1"></a>know_engineer_prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>)</span></code></pre></div>
<p>Simulate the data for disciplines, knowing an engineer, and the persistence outcome</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="week-7-logistic-regression.html#cb430-1" aria-hidden="true" tabindex="-1"></a>samp_size <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb430-2"><a href="week-7-logistic-regression.html#cb430-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb430-3"><a href="week-7-logistic-regression.html#cb430-3" aria-hidden="true" tabindex="-1"></a>student_id <span class="ot">&lt;-</span> <span class="fu">seq</span>(samp_size)</span>
<span id="cb430-4"><a href="week-7-logistic-regression.html#cb430-4" aria-hidden="true" tabindex="-1"></a>disc_samp_4 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> disciplines, <span class="at">size =</span> samp_size, <span class="at">prob =</span> disciplines_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb430-5"><a href="week-7-logistic-regression.html#cb430-5" aria-hidden="true" tabindex="-1"></a>know_samp_4 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> know_engineer, <span class="at">size =</span> samp_size, <span class="at">prob =</span> know_engineer_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb430-6"><a href="week-7-logistic-regression.html#cb430-6" aria-hidden="true" tabindex="-1"></a>pers_samp_4 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> persistence, <span class="at">size =</span> samp_size, <span class="at">prob =</span> persistence_prob, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Combine these all together in <code>tibble()</code>.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="week-7-logistic-regression.html#cb431-1" aria-hidden="true" tabindex="-1"></a>samp_df_4 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sid =</span> student_id,</span>
<span id="cb431-2"><a href="week-7-logistic-regression.html#cb431-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">discipline =</span> disc_samp_4,</span>
<span id="cb431-3"><a href="week-7-logistic-regression.html#cb431-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">know_eng =</span> know_samp_4)</span></code></pre></div>
<p>Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting out analysis</p>
<p>Start the data analysis for logistic regression here</p>
<p>Now, since we want to look at the potential effect of gpa on persistence, we create a bookkeeping column for gpa_mean for students who do and do not persist to year two.</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="week-7-logistic-regression.html#cb432-1" aria-hidden="true" tabindex="-1"></a>samp_df_4 <span class="ot">&lt;-</span> samp_df_4 <span class="sc">%&gt;%</span> </span>
<span id="cb432-2"><a href="week-7-logistic-regression.html#cb432-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gpa_mean =</span> <span class="fu">case_when</span>(discipline <span class="sc">==</span> <span class="st">&quot;civil&quot;</span> <span class="sc">~</span> <span class="fl">3.0</span>,</span>
<span id="cb432-3"><a href="week-7-logistic-regression.html#cb432-3" aria-hidden="true" tabindex="-1"></a>                              discipline <span class="sc">==</span> <span class="st">&quot;electrical&quot;</span> <span class="sc">~</span> <span class="fl">3.15</span>,</span>
<span id="cb432-4"><a href="week-7-logistic-regression.html#cb432-4" aria-hidden="true" tabindex="-1"></a>                              discipline <span class="sc">==</span> <span class="st">&quot;mechanical&quot;</span> <span class="sc">~</span> <span class="fl">3.3</span>,</span>
<span id="cb432-5"><a href="week-7-logistic-regression.html#cb432-5" aria-hidden="true" tabindex="-1"></a>                              discipline <span class="sc">==</span> <span class="st">&quot;systems&quot;</span> <span class="sc">~</span> <span class="fl">3.45</span>))</span></code></pre></div>
<p>Simulate the gpa data.</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="week-7-logistic-regression.html#cb433-1" aria-hidden="true" tabindex="-1"></a>gpa_vec <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">modify</span>(<span class="at">.x =</span> samp_df_4<span class="sc">$</span>gpa_mean, <span class="at">.f =</span> <span class="sc">~</span><span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">1</span>, <span class="at">mean =</span> .x, <span class="at">sd =</span> .<span class="dv">1</span>)), <span class="dv">2</span>)</span></code></pre></div>
<p>Add the simulated data back to our data frame</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="week-7-logistic-regression.html#cb434-1" aria-hidden="true" tabindex="-1"></a>samp_df_4<span class="sc">$</span>gpa <span class="ot">&lt;-</span> gpa_vec</span></code></pre></div>
<p>We will create a vector that samples depending on the value of the persistence probability at that index.</p>
<p>That value varies depending on the discipline for that student at that index value in the vector.</p>
<p>Now we want to have some different outcomes whose probabilities vary by discipline. We’ll create a new column called.</p>
<p>persist_prob that describes the probability of persisting from year one to year two (e.g., 0.6 means there is a 0.6 prob of a student persisting)</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="week-7-logistic-regression.html#cb435-1" aria-hidden="true" tabindex="-1"></a>samp_df_4 <span class="ot">&lt;-</span> samp_df_4 <span class="sc">%&gt;%</span> </span>
<span id="cb435-2"><a href="week-7-logistic-regression.html#cb435-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">persist_prob =</span> <span class="fu">case_when</span>(discipline <span class="sc">==</span> <span class="st">&quot;civil&quot;</span> <span class="sc">~</span> <span class="fl">0.6</span>,</span>
<span id="cb435-3"><a href="week-7-logistic-regression.html#cb435-3" aria-hidden="true" tabindex="-1"></a>                                  discipline <span class="sc">==</span> <span class="st">&quot;mechanical&quot;</span> <span class="sc">~</span> <span class="fl">0.7</span>,</span>
<span id="cb435-4"><a href="week-7-logistic-regression.html#cb435-4" aria-hidden="true" tabindex="-1"></a>                                  discipline <span class="sc">==</span> <span class="st">&quot;electrical&quot;</span> <span class="sc">~</span> <span class="fl">0.8</span>,</span>
<span id="cb435-5"><a href="week-7-logistic-regression.html#cb435-5" aria-hidden="true" tabindex="-1"></a>                                  discipline <span class="sc">==</span> <span class="st">&quot;systems&quot;</span> <span class="sc">~</span> <span class="fl">0.9</span>))</span></code></pre></div>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="week-7-logistic-regression.html#cb436-1" aria-hidden="true" tabindex="-1"></a>persist_outcome <span class="ot">&lt;-</span> <span class="fu">modify</span>(<span class="at">.x =</span> samp_df_4<span class="sc">$</span>persist_prob, <span class="at">.f =</span> <span class="sc">~</span><span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> .x))</span></code></pre></div>
<p>Now we add that persistence outcome column to our dataframe</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="week-7-logistic-regression.html#cb437-1" aria-hidden="true" tabindex="-1"></a>samp_df_4<span class="sc">$</span>persist_bin <span class="ot">&lt;-</span> persist_outcome</span></code></pre></div>
<p>Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis</p>
<p>Check the structure of the dataframe to make sure it looks as expected.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="week-7-logistic-regression.html#cb438-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(samp_df_4)</span></code></pre></div>
<pre><code>## tibble [500 x 7] (S3: tbl_df/tbl/data.frame)
##  $ sid         : int [1:500] 1 2 3 4 5 6 7 8 9 10 ...
##  $ discipline  : chr [1:500] &quot;electrical&quot; &quot;electrical&quot; &quot;electrical&quot; &quot;mechanical&quot; ...
##  $ know_eng    : chr [1:500] &quot;distant_fam&quot; &quot;immediate_fam&quot; &quot;friend&quot; &quot;distant_fam&quot; ...
##  $ gpa_mean    : num [1:500] 3.15 3.15 3.15 3.3 3 3.45 3 3.15 3.15 3.3 ...
##  $ gpa         : num [1:500] 2.99 2.95 3.13 3.23 3.09 3.57 2.88 3.25 3.39 3.09 ...
##  $ persist_prob: num [1:500] 0.8 0.8 0.8 0.7 0.6 0.9 0.6 0.8 0.8 0.7 ...
##  $ persist_bin : num [1:500] 1 0 1 1 0 1 0 0 1 1 ...</code></pre>
<p>Let’s check on the distribution of persistence by major. xtabs() is a function that creates a contingency table (more on that in 2 weeks).</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="week-7-logistic-regression.html#cb440-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span>(<span class="sc">~</span> persist_bin <span class="sc">+</span> discipline, <span class="at">data=</span>samp_df_4)</span></code></pre></div>
<pre><code>##            discipline
## persist_bin civil electrical mechanical systems
##           0    49         34         43       9
##           1    73        144        112      36</code></pre>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="week-7-logistic-regression.html#cb442-1" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(samp_df_4)</span></code></pre></div>
<pre><code>## Warning in describe(samp_df_4): NAs introduced by coercion

## Warning in describe(samp_df_4): NAs introduced by coercion</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf</code></pre>
<pre><code>## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf</code></pre>
<pre><code>##              vars   n   mean     sd median trimmed    mad  min    max  range
## sid             1 500 250.50 144.48 250.50  250.50 185.32 1.00 500.00 499.00
## discipline*     2 500    NaN     NA     NA     NaN     NA  Inf   -Inf   -Inf
## know_eng*       3 500    NaN     NA     NA     NaN     NA  Inf   -Inf   -Inf
## gpa_mean        4 500   3.19   0.14   3.15    3.18   0.22 3.00   3.45   0.45
## gpa             5 500   3.19   0.17   3.20    3.19   0.17 2.78   3.63   0.85
## persist_prob    6 500   0.73   0.09   0.70    0.73   0.15 0.60   0.90   0.30
## persist_bin     7 500   0.73   0.44   1.00    0.79   0.00 0.00   1.00   1.00
##               skew kurtosis   se
## sid           0.00    -1.21 6.46
## discipline*     NA       NA   NA
## know_eng*       NA       NA   NA
## gpa_mean      0.18    -0.89 0.01
## gpa           0.11    -0.35 0.01
## persist_prob  0.05    -1.00 0.00
## persist_bin  -1.03    -0.93 0.02</code></pre>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="week-7-logistic-regression.html#cb447-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(samp_df_4<span class="sc">$</span>discipline)</span></code></pre></div>
<pre><code>## 
##      civil electrical mechanical    systems 
##        122        178        155         45</code></pre>
<p>Check the distribution of the gpa values by discipline, just to make sure.</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="week-7-logistic-regression.html#cb449-1" aria-hidden="true" tabindex="-1"></a>samp_df_4 <span class="sc">%&gt;%</span> </span>
<span id="cb449-2"><a href="week-7-logistic-regression.html#cb449-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> gpa, <span class="at">fill =</span> discipline)) <span class="sc">+</span></span>
<span id="cb449-3"><a href="week-7-logistic-regression.html#cb449-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">position =</span> <span class="st">&quot;identity&quot;</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="test_course_notes_files/figure-html/unnamed-chunk-193-1.png" width="672" /></p>
<ul>
<li>be sure to put alpha before position</li>
</ul>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="week-7-logistic-regression.html#cb451-1" aria-hidden="true" tabindex="-1"></a>samp_df_4 <span class="sc">%&gt;%</span> </span>
<span id="cb451-2"><a href="week-7-logistic-regression.html#cb451-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> gpa, <span class="at">fill =</span> <span class="fu">as_factor</span>(persist_bin))) <span class="sc">+</span></span>
<span id="cb451-3"><a href="week-7-logistic-regression.html#cb451-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">position =</span> <span class="st">&quot;identity&quot;</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="test_course_notes_files/figure-html/unnamed-chunk-194-1.png" width="672" /></p>
<p>Now, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="week-7-logistic-regression.html#cb453-1" aria-hidden="true" tabindex="-1"></a>model_4 <span class="ot">&lt;-</span> <span class="fu">glm</span>(persist_bin <span class="sc">~</span> discipline <span class="sc">+</span> know_eng <span class="sc">+</span> gpa, <span class="at">data =</span> samp_df_4, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb453-2"><a href="week-7-logistic-regression.html#cb453-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_4)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df_4)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.9664  -1.2860   0.6731   0.8202   1.1175  
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)             1.8297     3.1549   0.580 0.561930    
## disciplineelectrical    1.1537     0.3209   3.595 0.000324 ***
## disciplinemechanical    0.7242     0.4162   1.740 0.081795 .  
## disciplinesystems       1.2693     0.6369   1.993 0.046249 *  
## know_engfriend          0.3072     0.2690   1.142 0.253381    
## know_engimmediate_fam  -0.0742     0.2590  -0.287 0.774492    
## know_engnone           -0.2379     0.3837  -0.620 0.535200    
## gpa                    -0.4946     1.0495  -0.471 0.637426    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 583.26  on 499  degrees of freedom
## Residual deviance: 563.31  on 492  degrees of freedom
## AIC: 579.31
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="week-7-logistic-regression.html#cb455-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(model_4)</span></code></pre></div>
<pre><code>## # A tibble: 8 x 5
##   term                  estimate std.error statistic  p.value
##   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)             1.83       3.15      0.580 0.562   
## 2 disciplineelectrical    1.15       0.321     3.60  0.000324
## 3 disciplinemechanical    0.724      0.416     1.74  0.0818  
## 4 disciplinesystems       1.27       0.637     1.99  0.0462  
## 5 know_engfriend          0.307      0.269     1.14  0.253   
## 6 know_engimmediate_fam  -0.0742     0.259    -0.287 0.774   
## 7 know_engnone           -0.238      0.384    -0.620 0.535   
## 8 gpa                    -0.495      1.05     -0.471 0.637</code></pre>
<div id="interlude-looking-at-poisson-distribution" class="section level3" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Interlude looking at poisson distribution</h3>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="week-7-logistic-regression.html#cb457-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb457-2"><a href="week-7-logistic-regression.html#cb457-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb457-3"><a href="week-7-logistic-regression.html#cb457-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb457-4"><a href="week-7-logistic-regression.html#cb457-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb457-5"><a href="week-7-logistic-regression.html#cb457-5" aria-hidden="true" tabindex="-1"></a>x_samp_5 <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> <span class="dv">5</span>)</span>
<span id="cb457-6"><a href="week-7-logistic-regression.html#cb457-6" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x_samp_5)</span></code></pre></div>
<p><img src="test_course_notes_files/figure-html/unnamed-chunk-196-1.png" width="672" /></p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="week-7-logistic-regression.html#cb458-1" aria-hidden="true" tabindex="-1"></a>x_samp_10 <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> <span class="dv">10</span>)</span>
<span id="cb458-2"><a href="week-7-logistic-regression.html#cb458-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x_samp_10)</span></code></pre></div>
<p><img src="test_course_notes_files/figure-html/unnamed-chunk-197-1.png" width="672" /></p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="week-7-logistic-regression.html#cb459-1" aria-hidden="true" tabindex="-1"></a>param_vect <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>), <span class="at">each =</span> n)</span>
<span id="cb459-2"><a href="week-7-logistic-regression.html#cb459-2" aria-hidden="true" tabindex="-1"></a>samp_vect <span class="ot">&lt;-</span> <span class="fu">modify</span>(<span class="at">.x =</span> param_vect, <span class="at">.f =</span> <span class="sc">~</span> <span class="fu">rpois</span>(<span class="at">n =</span> <span class="dv">1</span>, <span class="at">lambda =</span> .x))</span></code></pre></div>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="week-7-logistic-regression.html#cb460-1" aria-hidden="true" tabindex="-1"></a>samp_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">param_val =</span> param_vect,</span>
<span id="cb460-2"><a href="week-7-logistic-regression.html#cb460-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">sample_val =</span> samp_vect)</span></code></pre></div>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="week-7-logistic-regression.html#cb461-1" aria-hidden="true" tabindex="-1"></a>samp_df <span class="sc">%&gt;%</span></span>
<span id="cb461-2"><a href="week-7-logistic-regression.html#cb461-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> sample_val)) <span class="sc">+</span></span>
<span id="cb461-3"><a href="week-7-logistic-regression.html#cb461-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb461-4"><a href="week-7-logistic-regression.html#cb461-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(param_val <span class="sc">~</span> .)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="test_course_notes_files/figure-html/unnamed-chunk-200-1.png" width="672" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="week-6-regression-ii.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="week-8-comparing-two-means-t-tests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["test_course_notes.pdf", "test_course_notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
