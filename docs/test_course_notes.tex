% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={ENGE 5714 Course Notes 2021},
  pdfauthor={Dr.~Katz},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{ENGE 5714 Course Notes 2021}
\author{Dr.~Katz}
\date{2021-03-14}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preamble}{%
\chapter*{Preamble}\label{preamble}}
\addcontentsline{toc}{chapter}{Preamble}

This book will be a living document of notes for ENGE 5714 - Quantitative Research Methods in Engineering Education. I will try to keep it updated and post alerts about updates in our course Slack workspace.

\hypertarget{week-1-introductions}{%
\chapter{Week 1: Introductions}\label{week-1-introductions}}

In week one we just reviewed some of the materials from the fall semester. By the end we discussed R and RStudio, but this first week was primarily about getting to know each other and the outline of the course.

\hypertarget{week-2-intro-stats-data-distributions-intro-r-rstudio}{%
\chapter{Week 2: Intro stats, Data \& Distributions, Intro R \& RStudio}\label{week-2-intro-stats-data-distributions-intro-r-rstudio}}

This week, we discuss some very basic ideas related to statistics, data, and working in R.

\hypertarget{first-steps-in-r}{%
\section{First steps in R}\label{first-steps-in-r}}

We can create a new variable by assigning it a value with the \texttt{\textless{}-} operator. Let's create a vector of numbers 1 to 10 with the \texttt{seq()} function and then a separate vector that takes each of the x values, multiplies it by 2, and adds 3.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \DecValTok{3}
\end{Highlighting}
\end{Shaded}

Just to make sure everything worked as expected, we can then just type \texttt{x} and \texttt{y} and R will print their values. We could also look in the ``environment'' window to see whether those variables (and their expected values) were actually created.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  5  7  9 11 13 15 17 19 21 23
\end{verbatim}

So far, so good. If we want to quickly visualize this, we could create a simple scatter plot with the \texttt{plot()} command (note: we will come back to plotting data much more in week 3).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-3-1.pdf}

\hypertarget{getting-your-r-environment-set-up}{%
\section{Getting your R environment set up}\label{getting-your-r-environment-set-up}}

One of the first things you will have in any script or .rmd file is a section to load all the libraries that you use in that script.

You can install a library by using the install.packages() function, for example:

\texttt{install.packages("tidyverse")}, \texttt{install.packages("janitor")}, and \texttt{install.packages("psych")}

with this installed, you can then load the package using the library() function

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching packages --- tidyverse 1.3.0 --
\end{verbatim}

\begin{verbatim}
## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.0.3     v dplyr   1.0.0
## v tidyr   1.1.0     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.5.0
\end{verbatim}

\begin{verbatim}
## -- Conflicts ------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(janitor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'janitor' was built under R version 4.0.3
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'janitor'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     chisq.test, fisher.test
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(psych)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'psych'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:ggplot2':
## 
##     %+%, alpha
\end{verbatim}

\hypertarget{reading-in-data}{%
\section{Reading in data}\label{reading-in-data}}

A good first step when working in R is to check which directory you are working in with the \texttt{getwd()} function. You should get a directory in response.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "C:/Users/akatz4/Desktop/test_course_note"
\end{verbatim}

You can also check which files are in that directory with \texttt{list.files()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{list.files}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "_book"                                                                 
##  [2] "_bookdown.yml"                                                         
##  [3] "_bookdown_files"                                                       
##  [4] "_output.yml"                                                           
##  [5] "01-Week_01.Rmd"                                                        
##  [6] "02-Week_02.Rmd"                                                        
##  [7] "03-Week_03.Rmd"                                                        
##  [8] "04-Week_04.Rmd"                                                        
##  [9] "05-Week_05.Rmd"                                                        
## [10] "06-Week_06.Rmd"                                                        
## [11] "07-Week_07.Rmd"                                                        
## [12] "08-Week_08.Rmd"                                                        
## [13] "book.bib"                                                              
## [14] "ChildAggression.dat"                                                   
## [15] "docs"                                                                  
## [16] "ENGE_5714_2021_pre_survey.csv"                                         
## [17] "Free Reduced Lunch by Schools and Grade Structures 2008-2017_final.csv"
## [18] "index.Rmd"                                                             
## [19] "packages.bib"                                                          
## [20] "preamble.tex"                                                          
## [21] "README.md"                                                             
## [22] "RExam.dat"                                                             
## [23] "seniorsurvey.csv"                                                      
## [24] "student_happiness.csv"                                                 
## [25] "style.css"                                                             
## [26] "survey_student_info.csv"                                               
## [27] "test_course_note.Rproj"                                                
## [28] "test_course_notes.Rmd"                                                 
## [29] "test_course_notes_files"
\end{verbatim}

If you notice that the file you are looking for is not there, then you can use setwd() to change your working directory

\texttt{setwd("./Week\ 2/")}

After that, make sure you have switched to the correct working directory
\texttt{getwd()} and then \texttt{list.files()}.

Assuming you have directed yourself to the correct place, you can now read in the file(s) that you want to be working with. There are a \emph{lot} of ways to do this. Since we will be spending a lot of time in class working with .csv files, we will focus on using the \texttt{read\_csv()} function from the readr package (part of the tidyverse collection of packages). This function will read in the .csv file and store the data as a tibble (a tidyverse version of a data frame, which we can think of as a collection of observations stored in rows with values for variables for each observation stored in columns).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"ENGE\_5714\_2021\_pre\_survey.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   .default = col_character(),
##   student_id = col_double()
## )
\end{verbatim}

\begin{verbatim}
## See spec(...) for full column specifications.
\end{verbatim}

\hypertarget{exploring-the-data}{%
\section{Exploring the data}\label{exploring-the-data}}

Now that we have loaded in the data, let's take a look at the csv. If we just run a line with the name of the tibble - i.e., \texttt{prior\_survey} then we should receive a printout that shows the first several rows of that tibble and a listing of all the columns, along with the data types (i.e., double for numeric values, character for strings, etc) of each column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 24 x 49
##    student_id `I have taken a~ `I am intereste~ `I know what a ~
##         <dbl> <chr>            <chr>            <chr>           
##  1          1 Somewhat disagr~ Somewhat agree   Strongly disagr~
##  2          2 Strongly disagr~ Neither agree n~ Somewhat agree  
##  3          3 Strongly disagr~ Somewhat agree   Somewhat agree  
##  4          4 Somewhat disagr~ Strongly agree   Strongly disagr~
##  5          5 Somewhat agree   Strongly agree   Somewhat agree  
##  6          6 Somewhat disagr~ Somewhat agree   Somewhat disagr~
##  7          7 Strongly disagr~ Somewhat agree   Strongly disagr~
##  8          8 Somewhat agree   Somewhat agree   Somewhat agree  
##  9          9 Strongly disagr~ Strongly agree   Somewhat agree  
## 10         10 Neither agree n~ Strongly agree   Somewhat agree  
## # ... with 14 more rows, and 45 more variables: `I know what a type II error
## #   is` <chr>, `I know what a (statistical) confidence level is` <chr>, `I know
## #   what a p value is` <chr>, `I know what p-hacking means` <chr>, `I know what
## #   statistical power means` <chr>, `I have heard of frequentist statistics
## #   before` <chr>, `I have heard of Bayesian statistics before` <chr>, `I have
## #   heard the term "parametric statistics" before` <chr>, `I have heard the
## #   term "non-parametric statistics" before` <chr>, `I know what a histogram
## #   is.` <chr>, `I know what a probability distribution is.` <chr>, `I know
## #   what a random variable is.` <chr>, `I know what a probability distribution
## #   function is.` <chr>, `I know what a cumulative distribution function
## #   is.` <chr>, `I know what the expectation of a random variable is.` <chr>,
## #   `I know how to calculate the variance of a random variable.` <chr>, `I know
## #   what a z score is.` <chr>, `I know how to calculate the correlation between
## #   two variables.` <chr>, `I know how to interpret the correlation coefficient
## #   between two variables` <chr>, `I have heard of linear regression` <chr>, `I
## #   know how to run a linear regression (in some software...or by hand, if I'm
## #   feeling wild).` <chr>, `I know how to interpret a linear
## #   regression.` <chr>, `I have heard of multiple regression` <chr>, `I know
## #   how to perform a multiple regression` <chr>, `I know how to interpret a
## #   multiple regression` <chr>, `I have heard of logistic regression.` <chr>,
## #   `I understand when to use a logistic regression.` <chr>, `I know how to
## #   interpret the results of a logistic regression` <chr>, `I have heard of
## #   t-tests` <chr>, `I have performed a t-test before` <chr>, `I know how to
## #   interpret the results of a t-test` <chr>, `I have heard of Analysis of
## #   Variance.` <chr>, `I understand when to run an Analysis of Variance
## #   (ANOVA)` <chr>, `I know how to interpret the results from an ANOVA` <chr>,
## #   `I have heard of a chi-square test` <chr>, `I have used a chi-square test
## #   before` <chr>, `I know how to interpret the results of a chi-square
## #   test` <chr>, `I have heard of cluster analysis before` <chr>, `I have used
## #   cluster analysis before` <chr>, `I know how to interpret the results of a
## #   cluster analysis` <chr>, `I have heard of factor analysis (either
## #   exploratory or confirmatory)` <chr>, `I have used factor analysis (either
## #   exploratory or confirmatory)` <chr>, `I know how to interpret the results
## #   of a factor analysis (either exploratory or confirmatory)` <chr>, `I
## #   already have R and Rstudio downloaded to my computer.` <chr>, `I have used
## #   R before` <chr>
\end{verbatim}

When we do this, we see that there are a bunch of columns that have spaces in their names. This is okay (in the sense that R can handle this), but it can be a little frustrating to work with. Let's try cleaning the column names with \texttt{clean\_names()} from the janitor package. This function will replace the spaces in the column names with underscores and make everything lower case. So, a column name like ``I have take a statistics course before'' will be changed to ``i\_have\_taken\_a\_statistics\_course\_before''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey }\OtherTok{\textless{}{-}}\NormalTok{ prior\_survey }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{clean\_names}\NormalTok{() }\CommentTok{\# from janitor package}
\end{Highlighting}
\end{Shaded}

Look at the data in prior\_survey again and see if anything looks different (hint: it should).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 24 x 49
##    student_id i_have_taken_a_~ i_am_interested~ i_know_what_a_t~
##         <dbl> <chr>            <chr>            <chr>           
##  1          1 Somewhat disagr~ Somewhat agree   Strongly disagr~
##  2          2 Strongly disagr~ Neither agree n~ Somewhat agree  
##  3          3 Strongly disagr~ Somewhat agree   Somewhat agree  
##  4          4 Somewhat disagr~ Strongly agree   Strongly disagr~
##  5          5 Somewhat agree   Strongly agree   Somewhat agree  
##  6          6 Somewhat disagr~ Somewhat agree   Somewhat disagr~
##  7          7 Strongly disagr~ Somewhat agree   Strongly disagr~
##  8          8 Somewhat agree   Somewhat agree   Somewhat agree  
##  9          9 Strongly disagr~ Strongly agree   Somewhat agree  
## 10         10 Neither agree n~ Strongly agree   Somewhat agree  
## # ... with 14 more rows, and 45 more variables:
## #   i_know_what_a_type_ii_error_is <chr>,
## #   i_know_what_a_statistical_confidence_level_is <chr>,
## #   i_know_what_a_p_value_is <chr>, i_know_what_p_hacking_means <chr>,
## #   i_know_what_statistical_power_means <chr>,
## #   i_have_heard_of_frequentist_statistics_before <chr>,
## #   i_have_heard_of_bayesian_statistics_before <chr>,
## #   i_have_heard_the_term_parametric_statistics_before <chr>,
## #   i_have_heard_the_term_non_parametric_statistics_before <chr>,
## #   i_know_what_a_histogram_is <chr>,
## #   i_know_what_a_probability_distribution_is <chr>,
## #   i_know_what_a_random_variable_is <chr>,
## #   i_know_what_a_probability_distribution_function_is <chr>,
## #   i_know_what_a_cumulative_distribution_function_is <chr>,
## #   i_know_what_the_expectation_of_a_random_variable_is <chr>,
## #   i_know_how_to_calculate_the_variance_of_a_random_variable <chr>,
## #   i_know_what_a_z_score_is <chr>,
## #   i_know_how_to_calculate_the_correlation_between_two_variables <chr>,
## #   i_know_how_to_interpret_the_correlation_coefficient_between_two_variables <chr>,
## #   i_have_heard_of_linear_regression <chr>,
## #   i_know_how_to_run_a_linear_regression_in_some_software_or_by_hand_if_im_feeling_wild <chr>,
## #   i_know_how_to_interpret_a_linear_regression <chr>,
## #   i_have_heard_of_multiple_regression <chr>,
## #   i_know_how_to_perform_a_multiple_regression <chr>,
## #   i_know_how_to_interpret_a_multiple_regression <chr>,
## #   i_have_heard_of_logistic_regression <chr>,
## #   i_understand_when_to_use_a_logistic_regression <chr>,
## #   i_know_how_to_interpret_the_results_of_a_logistic_regression <chr>,
## #   i_have_heard_of_t_tests <chr>, i_have_performed_a_t_test_before <chr>,
## #   i_know_how_to_interpret_the_results_of_a_t_test <chr>,
## #   i_have_heard_of_analysis_of_variance <chr>,
## #   i_understand_when_to_run_an_analysis_of_variance_anova <chr>,
## #   i_know_how_to_interpret_the_results_from_an_anova <chr>,
## #   i_have_heard_of_a_chi_square_test <chr>,
## #   i_have_used_a_chi_square_test_before <chr>,
## #   i_know_how_to_interpret_the_results_of_a_chi_square_test <chr>,
## #   i_have_heard_of_cluster_analysis_before <chr>,
## #   i_have_used_cluster_analysis_before <chr>,
## #   i_know_how_to_interpret_the_results_of_a_cluster_analysis <chr>,
## #   i_have_heard_of_factor_analysis_either_exploratory_or_confirmatory <chr>,
## #   i_have_used_factor_analysis_either_exploratory_or_confirmatory <chr>,
## #   i_know_how_to_interpret_the_results_of_a_factor_analysis_either_exploratory_or_confirmatory <chr>,
## #   i_already_have_r_and_rstudio_downloaded_to_my_computer <chr>,
## #   i_have_used_r_before <chr>
\end{verbatim}

One other function that will we see more in the future is the \texttt{table()} function, which will create a table with the counts of the values for a variable. For example, if we wanted to quickly know how students answered the ``I have taken a quantitative research methods course before'' question, we can run the following:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(prior\_survey}\SpecialCharTok{$}\NormalTok{i\_have\_taken\_a\_quantitative\_research\_methods\_course\_before)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Neither agree nor disagree             Somewhat agree 
##                          2                          5 
##          Somewhat disagree             Strongly agree 
##                          5                          2 
##          Strongly disagree 
##                         10
\end{verbatim}

\hypertarget{plotting-data}{%
\section{Plotting data}\label{plotting-data}}

We will discuss plotting more next week, but here is a brief preview of what's to come\ldots{}

There are multiple ways to plot data. Focusing on using ggplot, here are two.

The first way passes the prior\_survey dataframe explicitly to ggplot

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ prior\_survey, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ i\_know\_what\_a\_type\_i\_error\_is)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-12-1.pdf}

The second way does this implicitly, using the pipe operator. Note that the results should be the same.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ i\_know\_what\_a\_type\_i\_error\_is)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-13-1.pdf}

If we wanted to get extra fancy, we could first convert the data from a wide format to a long format and then start plotting all the items together.

Converting to long format would produce something like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"survey\_item"}\NormalTok{, }\AttributeTok{value =} \StringTok{"survey\_response"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,176 x 2
##    survey_item survey_response
##    <chr>       <chr>          
##  1 student_id  1              
##  2 student_id  2              
##  3 student_id  3              
##  4 student_id  4              
##  5 student_id  5              
##  6 student_id  6              
##  7 student_id  7              
##  8 student_id  8              
##  9 student_id  9              
## 10 student_id  10             
## # ... with 1,166 more rows
\end{verbatim}

Then we can combine that with the \texttt{group\_by()} and \texttt{summarize()} functions and plot the results.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"survey\_item"}\NormalTok{, }\AttributeTok{value =} \StringTok{"survey\_response"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(survey\_item, survey\_response) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ survey\_response, }\AttributeTok{y =}\NormalTok{ survey\_item, }\AttributeTok{fill =}\NormalTok{ n)) }\SpecialCharTok{+}
  \FunctionTok{geom\_tile}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'survey_item' (override with `.groups` argument)
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-15-1.pdf}

This plot is okay for giving a general sense of what is going on in these plots but there are a bunch of other ways to go about doing this.

First, maybe we want to rename the response categories to a numerical scale. We can accomplish this with a \texttt{mutate()} and \texttt{case\_when()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey }\OtherTok{\textless{}{-}}\NormalTok{ prior\_survey }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"survey\_item"}\NormalTok{, }\AttributeTok{value =} \StringTok{"survey\_response"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{survey\_response\_num =} \FunctionTok{case\_when}\NormalTok{(survey\_response }\SpecialCharTok{==} \StringTok{"Strongly disagree"} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{,}
\NormalTok{                                         survey\_response }\SpecialCharTok{==} \StringTok{"Somewhat disagree"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
\NormalTok{                                         survey\_response }\SpecialCharTok{==} \StringTok{"Neither agree nor disagree"} \SpecialCharTok{\textasciitilde{}} \DecValTok{2}\NormalTok{,}
\NormalTok{                                         survey\_response }\SpecialCharTok{==} \StringTok{"Somewhat agree"} \SpecialCharTok{\textasciitilde{}} \DecValTok{3}\NormalTok{,}
\NormalTok{                                         survey\_response }\SpecialCharTok{==} \StringTok{"Strongly agree"} \SpecialCharTok{\textasciitilde{}} \DecValTok{4}\NormalTok{,}
\NormalTok{                                         )) }
\end{Highlighting}
\end{Shaded}

Then we plot the same data but with the numerical scale along the x-axis.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_survey }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(survey\_item, survey\_response\_num) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ survey\_response\_num, }\AttributeTok{y =}\NormalTok{ survey\_item, }\AttributeTok{fill =}\NormalTok{ n)) }\SpecialCharTok{+}
  \FunctionTok{geom\_tile}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'survey_item' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## Warning: Removed 3 rows containing missing values (geom_tile).
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-17-1.pdf}

\hypertarget{some-brief-stats}{%
\section{Some brief stats}\label{some-brief-stats}}

In this week's reading, there was also discussion about standard errors and the central limit theorem. These are fairly important theoretical concepts to grasp. To some extent they deal with the scenario where you go out and repeatedly sample from a population and calculate a statistic from each of those samples. The distributions \emph{of that statistic} is what we will call the sampling distribution (as opposed to the sample distribution, which would more accurately describe the distribution of the data that we get in any one sample that we draw from the population).

\hypertarget{central-limit-theorem-and-standard-error-demo--}{%
\subsection{Central Limit Theorem and Standard Error Demo ----}\label{central-limit-theorem-and-standard-error-demo--}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pop\_students }\OtherTok{\textless{}{-}} \DecValTok{10000}

\NormalTok{zoom\_min\_pop }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ pop\_students, }\AttributeTok{mean =} \DecValTok{600}\NormalTok{, }\AttributeTok{sd =} \DecValTok{100}\NormalTok{)}

\FunctionTok{hist}\NormalTok{(zoom\_min\_pop)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-18-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{zoom\_min\_sample }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ zoom\_min\_pop,}
                          \AttributeTok{size =} \DecValTok{200}\NormalTok{,}
                          \AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}


\FunctionTok{hist}\NormalTok{(zoom\_min\_sample)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-18-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(zoom\_min\_sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 603.3624
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(zoom\_min\_sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 102.4502
\end{verbatim}

As a brief aside, let's review the idea of a loop

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num\_reps }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{data\_vec }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, num\_reps) }\CommentTok{\# this creates an empty vector of size num\_reps with NA in each entry}

\CommentTok{\# this loops through the vector starting at position 1 and ending at the final position (num\_reps). For demonstration purposes, we replacing the NA in each entry with the number of that entry (i.e., the NA in the 20th entry is replaced with the number 20)}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{num\_reps)\{}
\NormalTok{  data\_vec[i] }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Okay, so that's how we create an empty vector and how we loop through its different entries. For this demo, we will also need to remenber how to generate random numbers from a norm distribution with a specified mean and standard deviation.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{5}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{) }\CommentTok{\# n is the number of random numbers we draw from this normal distribution}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 4.099294 3.411509 6.232366 5.549321 5.418897 4.410174 5.330722 6.588594
##  [9] 7.336503 3.075376
\end{verbatim}

Okay, so that's not bad. Now, that command will produce a vector with 10 random numbers. We can calculate the mean and standard deviation of those 10 numbers (which should be close to the values that we specified in \texttt{rnorm()} with the \texttt{mean()} and \texttt{sd()} functions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{5}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.288278
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{5}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.544623
\end{verbatim}

Next, let's act as if we are drawing a certain sample of size \texttt{samp\_size} of data points for \texttt{num\_reps} number of times. Keep in mind that, in practice, when we are collecting data ourselves in our own research, num\_reps will almost always be 1. We are just demonstrating the underlying assumptions for how we can calculate some of the statistics that we use.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num\_reps }\OtherTok{\textless{}{-}} \DecValTok{1000} \CommentTok{\# specify how many times to take a sample}
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{200} \CommentTok{\# specify the size of each sample}
\NormalTok{data\_vec }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, num\_reps) }\CommentTok{\# create an empty vector of size num\_reps with NA in each entry.}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{num\_reps)\{}
\NormalTok{  data\_vec[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{600}\NormalTok{, }\AttributeTok{sd =} \DecValTok{100}\NormalTok{)) }\CommentTok{\# store the mean of each of the num\_rep samples}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

With this, we have a vector \texttt{data\_vec} of size \texttt{num\_reps} with the mean of each of our samples that we drew. This vector contains our sampling distribution of our sample means. \textbf{NOTE}: The standard deviation of this sampling mean is what we are calling our \emph{standard error}.

We can plot a histogram of this sampling distribution and calculate the standard deviation of the sampling mean.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(data\_vec)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-23-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(data\_vec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6.876998
\end{verbatim}

On your own, try copying this code and changing the num\_reps and sample\_size variables to larger and smaller values. Focus on how the x-axis values in your histogram change when you change the num\_reps and samp\_size variables.

Hint: CLT will explain the normal distribution of the sampling mean (the shape you see in the histogram) while the Weak Law of Large Numbers will explain the concentration around the true mean as samp\_size increases (i.e., when we draw a larger sample size from the population, our sample mean gets closer to the population mean).

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Quick note on the rep() function: notice what happens when you specify "each" vs "times".}
\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{times =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1 2 1 2 1 2 1 2 1 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{each =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1 1 1 1 1 2 2 2 2 2
\end{verbatim}

\hypertarget{week-3-data-cleaning-organizing-describing-and-communicating}{%
\chapter{Week 3: Data Cleaning, Organizing, Describing, and Communicating}\label{week-3-data-cleaning-organizing-describing-and-communicating}}

This week we focus on different steps you will often take when you first start working with your data. These tend to fall under the umbrella of ``data processing'' and often need to happen before you can start doing any kind of analysis.

\hypertarget{visualizing-your-data}{%
\section{Visualizing your data}\label{visualizing-your-data}}

Once your data have been clearned, you are ready to start visualizing what you are working with. There is a huge range of what you can do with these plots. That's great! On the other hand, it can quickly start to feel overwhelming. To help get this under control and make it more manageable, it is convenient to think about the \emph{types} of data that you have. In particular, are your variables nominal, ordinal, interval, or ratio variables?

\hypertarget{one-continuous-variable-either-predictor-or-outcome-variable}{%
\subsection{One continuous variable (either predictor or outcome variable)}\label{one-continuous-variable-either-predictor-or-outcome-variable}}

When you have one continuous variable, a standard option is to plot a histogram. These are plots that show the frequency of each of the values that the variable takes. Oftentimes it is helpful to create bins of values so that any number that falls in the 0-4 range counts in one bin, numbers from 5-9 are in a second bin, and so on.

For this example, we will start by generating some data using \texttt{rnorm()}, which generates a random number (or in our case, \texttt{num} numbers) from a normal distribution with mean \texttt{mu} and standard deviation \texttt{stdev}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{stdev }\OtherTok{\textless{}{-}} \DecValTok{2}

\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ num, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ stdev)}
\end{Highlighting}
\end{Shaded}

With these data generated, we can then quickly plot the histogram with \texttt{hist()}. This will use base R graphics.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-25-1.pdf}

You can also do this using ggplot rather than base R graphics.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x\_col =}\NormalTok{ x)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ x\_df, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_col)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/ggplot-hist-1.pdf}

The histogram is a very standard plot, and you should consider it a go-to option in your toolkit. Alternatively, you can use geom\_density() instead of geom\_histogram() to get a smooth graph rather than one with discrete bins. We will use the same data that we generated before.

We will write this two ways to demnostrate how the pipe \texttt{\%\textgreater{}\%} operator works.

First way:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ x\_df, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_col)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-26-1.pdf}

Second way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_col)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-27-1.pdf}

Just for fun, look at what happens to the the plot if you increase the sample size

First, we will generate the data with a sample size of 5,000 rather than 50.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num }\OtherTok{\textless{}{-}} \DecValTok{5000}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{stdev }\OtherTok{\textless{}{-}} \DecValTok{2}

\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ num, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ stdev)}
\NormalTok{x\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x\_col =}\NormalTok{ x)}
\end{Highlighting}
\end{Shaded}

Then we will plot the histogram

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_col)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"x value"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \AttributeTok{title =} \StringTok{"Histogram of normal distribution with n = 5000, mu = 5, sd = 2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-29-1.pdf}

And, finally, we can make the density plot instead of the histogram, if that's our jam.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ x\_df, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x\_col)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-30-1.pdf}

\hypertarget{one-discrete-variable-either-predictor-or-outcome}{%
\subsection{One Discrete Variable (either predictor or outcome)}\label{one-discrete-variable-either-predictor-or-outcome}}

What if instead of a continuous (i.e., interval or ratio) variable we have a discrete variable such as a nominal (e.g., major, university) or ordinal (e.g., Likert scale item, level of education) variable? For that we can use something like \texttt{geom\_bar()} or \texttt{geom\_col()} to plot the counts of observations within each of those categories.

To demonstrate this, we first need some data to work with. We will use the pre-semester, prior knowledge survey that everyone took. I have combined this year's results with last year's results in order to increase the sample size. After reading in the data, I will also use the \texttt{clean\_names()} function from the \texttt{janitor} package.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# load in the data}
\NormalTok{survey\_df }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"ENGE\_5714\_2021\_pre\_survey.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   .default = col_character(),
##   student_id = col_double()
## )
\end{verbatim}

\begin{verbatim}
## See spec(...) for full column specifications.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_df }\OtherTok{\textless{}{-}}\NormalTok{ survey\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{clean\_names}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Next, we can go ahead and make a bar plot with the following code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ i\_have\_taken\_a\_quantitative\_research\_methods\_course\_before)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/geom-bar-1.pdf}

Notice that the ordering is not quite what we would want. It is alphabetical. Let's try to fix this.

Here is one way: we first specify the levels of that variable (i.e., the different values that it could take) and store that in the variable \texttt{q\_levels}. Then, we pass that to the \texttt{factor()} function, which will tell R that we want whichever variable is passed to \texttt{factor()} two things. First, it will say that we want to make that variable a factor variable with \texttt{levels\ =\ ...}. Second, we set \texttt{ordered\ =\ TRUE} to tell R that there is a specific ordering to that variable. This way, whenever there is something like a plot that we make, the ordering will persist in the labeling and R will not show the labels in alphabetical order.

Here is an example of that in action:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q\_levels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Strongly disagree"}\NormalTok{, }\StringTok{"Somewhat disagree"}\NormalTok{, }\StringTok{"Neither agree nor disagree"}\NormalTok{,}
              \StringTok{"Somewhat agree"}\NormalTok{, }\StringTok{"Strongly agree"}\NormalTok{)}



\NormalTok{survey\_df}\SpecialCharTok{$}\NormalTok{i\_have\_taken\_a\_quantitative\_research\_methods\_course\_before }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(survey\_df}\SpecialCharTok{$}\NormalTok{i\_have\_taken\_a\_quantitative\_research\_methods\_course\_before, }
                                                                               \AttributeTok{levels =}\NormalTok{ q\_levels,}
                                                                               \AttributeTok{ordered =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now try plotting these data. We will also add in a \texttt{coord\_flip()} to plot the categories along the y-axis. This is a common move to avoid text from the different levels overlapping with each other. Finally, we will also change the x, y, and title labels with \texttt{labs()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ i\_have\_taken\_a\_quantitative\_research\_methods\_course\_before)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"I have taken a quantitative research methods course before"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \AttributeTok{title =} \StringTok{"Reordered Example"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-32-1.pdf}

\hypertarget{joining-two-datasets}{%
\section{Joining two datasets}\label{joining-two-datasets}}

Let's imagine that we have a separate dataset that has information about the students who completed the pre-course prior knowledge survey.

First, we will load in that dataset

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_info\_df }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"survey\_student\_info.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   student_id = col_double(),
##   standing = col_character(),
##   college = col_character(),
##   required = col_character()
## )
\end{verbatim}

Next, let's join the two datasets based on the student id column, which is in each of the two dataframes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_df }\OtherTok{\textless{}{-}}\NormalTok{ survey\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{inner\_join}\NormalTok{(survey\_info\_df, }\AttributeTok{by =} \StringTok{"student\_id"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we should have both datasets joined into one and saved as survey\_df.

With this, we can make some nicer plots and do something like use facet\_grid() to look at students who are masters and doctoral students, for example.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ i\_have\_taken\_a\_quantitative\_research\_methods\_course\_before)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(standing }\SpecialCharTok{\textasciitilde{}}\NormalTok{.) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"I have taken a quantitative research methods course before"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \AttributeTok{title =} \StringTok{"Reordered Example"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-35-1.pdf}

The x axis looks a little crowded. What if we try \texttt{coord\_flip()}?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(standing }\SpecialCharTok{==} \StringTok{"doctoral"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ i\_have\_taken\_a\_quantitative\_research\_methods\_course\_before)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(standing }\SpecialCharTok{\textasciitilde{}}\NormalTok{.) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"I have taken a quantitative research methods course before"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
       \AttributeTok{title =} \StringTok{"Reordered Example"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-36-1.pdf}

That looks much better.

\hypertarget{a-quick-note-on-filters}{%
\subsubsection*{A quick note on filters}\label{a-quick-note-on-filters}}
\addcontentsline{toc}{subsubsection}{A quick note on filters}

If you want to look at only a subset of your data, you will want to use the \texttt{filter()} function. The general idea is that you can look at observations (rows) that match a certain criteria. For example, you may want to only look at students from a certain region or year or major. In our case, with the prior knowledge survey, let's say we only want to look at student who have to take the course (i.e., there is a ``yes'' for them for the \texttt{required} variable). We can do that with the first line. The second line just stores the result as a new dataframe called \texttt{filtered\_df}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(required }\SpecialCharTok{==} \StringTok{"yes"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 12 x 52
##    student_id i_have_taken_a_~ i_am_interested~ i_know_what_a_t~
##         <dbl> <ord>            <chr>            <chr>           
##  1          1 Somewhat disagr~ Somewhat agree   Strongly disagr~
##  2          2 Strongly disagr~ Neither agree n~ Somewhat agree  
##  3          4 Somewhat disagr~ Strongly agree   Strongly disagr~
##  4          8 Somewhat agree   Somewhat agree   Somewhat agree  
##  5          9 Strongly disagr~ Strongly agree   Somewhat agree  
##  6         11 Strongly disagr~ Strongly agree   Strongly disagr~
##  7         16 Strongly agree   Strongly agree   Somewhat agree  
##  8         17 Strongly disagr~ Strongly agree   Strongly disagr~
##  9         18 Somewhat disagr~ Somewhat agree   Somewhat disagr~
## 10         20 Strongly disagr~ Neither agree n~ Neither agree n~
## 11         22 Strongly disagr~ Strongly agree   Strongly disagr~
## 12         23 Somewhat agree   Strongly agree   Somewhat agree  
## # ... with 48 more variables: i_know_what_a_type_ii_error_is <chr>,
## #   i_know_what_a_statistical_confidence_level_is <chr>,
## #   i_know_what_a_p_value_is <chr>, i_know_what_p_hacking_means <chr>,
## #   i_know_what_statistical_power_means <chr>,
## #   i_have_heard_of_frequentist_statistics_before <chr>,
## #   i_have_heard_of_bayesian_statistics_before <chr>,
## #   i_have_heard_the_term_parametric_statistics_before <chr>,
## #   i_have_heard_the_term_non_parametric_statistics_before <chr>,
## #   i_know_what_a_histogram_is <chr>,
## #   i_know_what_a_probability_distribution_is <chr>,
## #   i_know_what_a_random_variable_is <chr>,
## #   i_know_what_a_probability_distribution_function_is <chr>,
## #   i_know_what_a_cumulative_distribution_function_is <chr>,
## #   i_know_what_the_expectation_of_a_random_variable_is <chr>,
## #   i_know_how_to_calculate_the_variance_of_a_random_variable <chr>,
## #   i_know_what_a_z_score_is <chr>,
## #   i_know_how_to_calculate_the_correlation_between_two_variables <chr>,
## #   i_know_how_to_interpret_the_correlation_coefficient_between_two_variables <chr>,
## #   i_have_heard_of_linear_regression <chr>,
## #   i_know_how_to_run_a_linear_regression_in_some_software_or_by_hand_if_im_feeling_wild <chr>,
## #   i_know_how_to_interpret_a_linear_regression <chr>,
## #   i_have_heard_of_multiple_regression <chr>,
## #   i_know_how_to_perform_a_multiple_regression <chr>,
## #   i_know_how_to_interpret_a_multiple_regression <chr>,
## #   i_have_heard_of_logistic_regression <chr>,
## #   i_understand_when_to_use_a_logistic_regression <chr>,
## #   i_know_how_to_interpret_the_results_of_a_logistic_regression <chr>,
## #   i_have_heard_of_t_tests <chr>, i_have_performed_a_t_test_before <chr>,
## #   i_know_how_to_interpret_the_results_of_a_t_test <chr>,
## #   i_have_heard_of_analysis_of_variance <chr>,
## #   i_understand_when_to_run_an_analysis_of_variance_anova <chr>,
## #   i_know_how_to_interpret_the_results_from_an_anova <chr>,
## #   i_have_heard_of_a_chi_square_test <chr>,
## #   i_have_used_a_chi_square_test_before <chr>,
## #   i_know_how_to_interpret_the_results_of_a_chi_square_test <chr>,
## #   i_have_heard_of_cluster_analysis_before <chr>,
## #   i_have_used_cluster_analysis_before <chr>,
## #   i_know_how_to_interpret_the_results_of_a_cluster_analysis <chr>,
## #   i_have_heard_of_factor_analysis_either_exploratory_or_confirmatory <chr>,
## #   i_have_used_factor_analysis_either_exploratory_or_confirmatory <chr>,
## #   i_know_how_to_interpret_the_results_of_a_factor_analysis_either_exploratory_or_confirmatory <chr>,
## #   i_already_have_r_and_rstudio_downloaded_to_my_computer <chr>,
## #   i_have_used_r_before <chr>, standing <chr>, college <chr>, required <chr>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filtered\_df }\OtherTok{\textless{}{-}}\NormalTok{ survey\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(required }\SpecialCharTok{==} \StringTok{"yes"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{a-little-more-about-plotting}{%
\subsubsection*{A little more about plotting}\label{a-little-more-about-plotting}}
\addcontentsline{toc}{subsubsection}{A little more about plotting}

We are going to shift gears again and look at a few different kinds of plots. The main thing to remember here is that you want to think about whether the variables you have are nominal, ordinal, or continuous (that includes interval and ratio).

\hypertarget{discrete-predictor-continuous-outcome}{%
\section{Discrete Predictor, Continuous Outcome}\label{discrete-predictor-continuous-outcome}}

So far we have looked at plots for one variable, but of course we want to have ways to plot multiple variables simultaneously. We will start with the scneario where where we want to plot a continuous variable against a discrete variable. This can arise when you want to plot something like an assessment score and you think it may differ across groups in some way (maybe you intentionally introduced a difference by exposing the two groups to different interventions, for example).

In these scenarios, a boxplot is a very standard way to go.

To demonstrate this, we will simulate a situation in which we want to look at differences on an assessment. We are specificially interested in differences between chemistry and chemical engineering students. Let's go ahead and create the data by creating two groups of 20 students each. The chemical engineering students will have scores generated from a normal distribution with \(\mu = 85\) and \(\sigma = 4\) (i.e., a mean of 85 and a standard deviation of 4). We will say the chemistry students have scores from a normal distribution with \(\mu = 78\) anad \(\sigma = 6\). This about what these distributions might look like in your head.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{group\_size }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{chem\_e\_scores }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ group\_size, }\AttributeTok{mean =} \DecValTok{85}\NormalTok{, }\AttributeTok{sd =} \DecValTok{4}\NormalTok{)}
\NormalTok{chem\_scores }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ group\_size, }\AttributeTok{mean =} \DecValTok{78}\NormalTok{, }\AttributeTok{sd =} \DecValTok{6}\NormalTok{)}


\NormalTok{data\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{discipline =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"ChemE"}\NormalTok{, }\StringTok{"Chemistry"}\NormalTok{), }\AttributeTok{each =}\NormalTok{ group\_size),}
  \AttributeTok{score =} \FunctionTok{c}\NormalTok{(chem\_e\_scores, chem\_scores)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

With these data, we can then create a boxplot using \texttt{geom\_boxplot()}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ discipline, }\AttributeTok{y =}\NormalTok{ score)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-38-1.pdf}

You can make a few modifications to possibly make this plot easier to read.

The first is to put the discrete category on the y axis instead of the x axis.

The second is to use geom\_jitter() in addition to geom\_boxplot() to show the individual points in each group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ score, }\AttributeTok{x =}\NormalTok{ discipline)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/box-and-dot-plot-1.pdf}

\hypertarget{continuous-predictor-and-continuous-outcome}{%
\section{Continuous predictor and continuous outcome}\label{continuous-predictor-and-continuous-outcome}}

First, let's re-do a lot of the steps in this week's script for reading in data and transforming it a little

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"Free Reduced Lunch by Schools and Grade Structures 2008{-}2017\_final.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   .default = col_character(),
##   div_num = col_double()
## )
\end{verbatim}

\begin{verbatim}
## See spec(...) for full column specifications.
\end{verbatim}

Check the structure of the data (this output is a bit long).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(mydata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [2,101 x 137] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ sch_id        : chr [1:2101] "001-0070" "001-0080" "001-0530" "001-0540" ...
##  $ div_num       : num [1:2101] 1 1 1 1 1 1 1 1 1 1 ...
##  $ div_name      : chr [1:2101] "Accomack County" "Accomack County" "Accomack County" "Accomack County" ...
##  $ school_num    : chr [1:2101] "0070<U+00A0>" "0080<U+00A0>" "0530<U+00A0>" "0540<U+00A0>" ...
##  $ school_name   : chr [1:2101] "NANDUA HIGH" "CHINCOTEAGUE ELEM" "TANGIER COMBINED" "ARCADIA HIGH" ...
##  $ school_name2  : chr [1:2101] NA NA NA NA ...
##  $ type0809      : chr [1:2101] "SCH-HIGH" "SCH-ELEM" "SCH-COMB" "SCH-HIGH" ...
##  $ lowgrade_2008 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2008  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2008  : chr [1:2101] "731" "263" "80" "638" ...
##  $ total_2008    : chr [1:2101] "731" "263" "80" "638" ...
##  $ snp_0809      : chr [1:2101] "659" "257" "80" "622" ...
##  $ free_elig_0809: chr [1:2101] "306" "95" "38" "289" ...
##  $ free_per_0809 : chr [1:2101] "46.43%" "36.96%" "47.50%" "46.46%" ...
##  $ red_elig_0809 : chr [1:2101] "64" "8" "0" "56" ...
##  $ red_per_0809  : chr [1:2101] "9.71%" "3.11%" "0.00%" "9.00%" ...
##  $ totalFRL_0809 : chr [1:2101] "370" "103" "38" "345" ...
##  $ totalper_0809 : chr [1:2101] "56.15%" "40.08%" "47.50%" "55.47%" ...
##  $ type0910      : chr [1:2101] "SCH-HIGH" "SCH-ELEM" "SCH-COMB" "SCH-HIGH" ...
##  $ lowgrade_2009 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2009  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2009  : chr [1:2101] "654" "266" "78" "634" ...
##  $ total_2009    : chr [1:2101] "654" "266" "78" "634" ...
##  $ snp_0910      : chr [1:2101] "655" "266" "78" "635" ...
##  $ free_elig_0910: chr [1:2101] "290" "99" "36" "286" ...
##  $ free_per_0910 : chr [1:2101] "44.27%" "37.22%" "46.15%" "45.04%" ...
##  $ red_elig_0910 : chr [1:2101] "37" "14" "0" "66" ...
##  $ red_per_0910  : chr [1:2101] "5.65%" "5.26%" "0.00%" "10.39%" ...
##  $ totalFRL_09010: chr [1:2101] "327" "113" "36" "352" ...
##  $ totalper_0910 : chr [1:2101] "49.92%" "42.48%" "46.15%" "55.43%" ...
##  $ type1011      : chr [1:2101] "SCH-HIGH" "SCH-ELEM" "SCH-COMB" "SCH-HIGH" ...
##  $ lowgrade_2010 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2010  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2010  : chr [1:2101] "603" "268" "74" "614" ...
##  $ total_2010    : chr [1:2101] "603" "268" "74" "614" ...
##  $ snp_1011      : chr [1:2101] "603" "277" "74" "606" ...
##  $ free_elig_1011: chr [1:2101] "285" "108" "32" "308" ...
##  $ free_per_1011 : chr [1:2101] "47.26%" "38.99%" "43.24%" "50.83%" ...
##  $ red_elig_1011 : chr [1:2101] "46" "8" "0" "50" ...
##  $ red_per_1011  : chr [1:2101] "7.63%" "2.89%" "0.00%" "8.25%" ...
##  $ totalFRL_1011 : chr [1:2101] "331" "116" "32" "358" ...
##  $ totalper_1011 : chr [1:2101] "54.89%" "41.88%" "43.24%" "59.08%" ...
##  $ type1112      : chr [1:2101] "SCH-HIGH" "SCH-ELEM" "SCH-COMB" "SCH-HIGH" ...
##  $ lowgrade_2011 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2011  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2011  : chr [1:2101] "593" "276" "73" "605" ...
##  $ total_2011    : chr [1:2101] "593" "276" "73" "605" ...
##  $ snp_1112      : chr [1:2101] "593" "281" "73" "611" ...
##  $ free_elig_1112: chr [1:2101] "289" "116" "31" "318" ...
##  $ free_per_1112 : chr [1:2101] "48.74%" "41.28%" "42.47%" "52.05%" ...
##  $ red_elig_1112 : chr [1:2101] "50" "14" "0" "44" ...
##  $ red_per_1112  : chr [1:2101] "8.43%" "4.98%" "0.00%" "7.20%" ...
##  $ totalFRL_1112 : chr [1:2101] "339" "130" "31" "362" ...
##  $ totalper_1112 : chr [1:2101] "57.17%" "46.26%" "42.47%" "59.25%" ...
##  $ type1213      : chr [1:2101] "SCH-HIGH" "SCH-ELEM" "SCH-COMB" "SCH-HIGH" ...
##  $ lowgrade_2012 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2012  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2012  : chr [1:2101] "637" "258" "68" "579" ...
##  $ total_2012    : chr [1:2101] "637" "258" "68" "579" ...
##  $ snp_1213      : chr [1:2101] "633" "259" "68" "579" ...
##  $ free_elig_1213: chr [1:2101] "324" "117" "21" "348" ...
##  $ free_per_1213 : chr [1:2101] "51.18%" "45.17%" "30.88%" "60.10%" ...
##  $ red_elig_1213 : chr [1:2101] "42" "20" "5" "33" ...
##  $ red_per_1213  : chr [1:2101] "6.64%" "7.72%" "7.35%" "5.70%" ...
##  $ totalFRL_1213 : chr [1:2101] "366" "137" "26" "381" ...
##  $ totalper_1213 : chr [1:2101] "57.82%" "52.90%" "38.24%" "65.80%" ...
##  $ type1314      : chr [1:2101] "SCH-HIGH" "SCH-ELEM" "SCH-COMB" "SCH-HIGH" ...
##  $ lowgrade_2013 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2013  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2013  : chr [1:2101] "670" "238" "66" "582" ...
##  $ total_2013    : chr [1:2101] "670" "238" "66" "582" ...
##  $ snp_1314      : chr [1:2101] "668" "239" "56" "589" ...
##  $ free_elig_1314: chr [1:2101] "346" "102" "12" "347" ...
##  $ free_per_1314 : chr [1:2101] "51.80%" "42.68%" "21.43%" "58.91%" ...
##  $ red_elig_1314 : chr [1:2101] "44" "19" "4" "54" ...
##  $ red_per_1314  : chr [1:2101] "6.59%" "7.95%" "7.14%" "9.17%" ...
##  $ totalFRL_1314 : chr [1:2101] "390" "121" "16" "401" ...
##  $ totalper_1314 : chr [1:2101] "58.38%" "50.63%" "28.57%" "68.08%" ...
##  $ type1415      : chr [1:2101] NA NA NA NA ...
##  $ lowgrade_2014 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2014  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2014  : chr [1:2101] "685" "251" "65" "581" ...
##  $ total_2014    : chr [1:2101] "685" "251" "65" "581" ...
##  $ snp_1415      : chr [1:2101] "672" "239" "61" "586" ...
##  $ free_elig_1415: chr [1:2101] "361" "93" "14" "351" ...
##  $ free_per_1415 : chr [1:2101] "53.72%" "38.91%" "22.95%" "59.90%" ...
##  $ red_elig_1415 : chr [1:2101] "40" "17" "4" "40" ...
##  $ red_per_1415  : chr [1:2101] "5.95%" "7.11%" "6.56%" "6.83%" ...
##  $ totalFRL_1415 : chr [1:2101] "401" "110" "18" "391" ...
##  $ totalper_1415 : chr [1:2101] "59.67%" "46.03%" "29.51%" "66.72%" ...
##  $ CEP_1516      : chr [1:2101] "#NULL!" "#NULL!" "#NULL!" "#NULL!" ...
##  $ type1516      : chr [1:2101] "SCH-HIGH" "SCH-ELEM" "SCH-COMB" "SCH-HIGH" ...
##  $ lowgrade_2015 : chr [1:2101] "9" "PK" "KG" "9" ...
##  $ higrade_2015  : chr [1:2101] "12" "5" "12" "12" ...
##  $ totalFT_2015  : chr [1:2101] "737" "259" "65" "621" ...
##  $ total_2015    : chr [1:2101] "737" "259" "65" "621" ...
##  $ snp_1516      : chr [1:2101] "728" "268" "67" "608" ...
##  $ free_elig_1516: chr [1:2101] "362" "109" "12" "339" ...
##  $ free_per_1516 : chr [1:2101] "49.73%" "40.67%" "17.91%" "55.76%" ...
##   [list output truncated]
##  - attr(*, "spec")=
##   .. cols(
##   ..   sch_id = col_character(),
##   ..   div_num = col_double(),
##   ..   div_name = col_character(),
##   ..   school_num = col_character(),
##   ..   school_name = col_character(),
##   ..   school_name2 = col_character(),
##   ..   type0809 = col_character(),
##   ..   lowgrade_2008 = col_character(),
##   ..   higrade_2008 = col_character(),
##   ..   totalFT_2008 = col_character(),
##   ..   total_2008 = col_character(),
##   ..   snp_0809 = col_character(),
##   ..   free_elig_0809 = col_character(),
##   ..   free_per_0809 = col_character(),
##   ..   red_elig_0809 = col_character(),
##   ..   red_per_0809 = col_character(),
##   ..   totalFRL_0809 = col_character(),
##   ..   totalper_0809 = col_character(),
##   ..   type0910 = col_character(),
##   ..   lowgrade_2009 = col_character(),
##   ..   higrade_2009 = col_character(),
##   ..   totalFT_2009 = col_character(),
##   ..   total_2009 = col_character(),
##   ..   snp_0910 = col_character(),
##   ..   free_elig_0910 = col_character(),
##   ..   free_per_0910 = col_character(),
##   ..   red_elig_0910 = col_character(),
##   ..   red_per_0910 = col_character(),
##   ..   totalFRL_09010 = col_character(),
##   ..   totalper_0910 = col_character(),
##   ..   type1011 = col_character(),
##   ..   lowgrade_2010 = col_character(),
##   ..   higrade_2010 = col_character(),
##   ..   totalFT_2010 = col_character(),
##   ..   total_2010 = col_character(),
##   ..   snp_1011 = col_character(),
##   ..   free_elig_1011 = col_character(),
##   ..   free_per_1011 = col_character(),
##   ..   red_elig_1011 = col_character(),
##   ..   red_per_1011 = col_character(),
##   ..   totalFRL_1011 = col_character(),
##   ..   totalper_1011 = col_character(),
##   ..   type1112 = col_character(),
##   ..   lowgrade_2011 = col_character(),
##   ..   higrade_2011 = col_character(),
##   ..   totalFT_2011 = col_character(),
##   ..   total_2011 = col_character(),
##   ..   snp_1112 = col_character(),
##   ..   free_elig_1112 = col_character(),
##   ..   free_per_1112 = col_character(),
##   ..   red_elig_1112 = col_character(),
##   ..   red_per_1112 = col_character(),
##   ..   totalFRL_1112 = col_character(),
##   ..   totalper_1112 = col_character(),
##   ..   type1213 = col_character(),
##   ..   lowgrade_2012 = col_character(),
##   ..   higrade_2012 = col_character(),
##   ..   totalFT_2012 = col_character(),
##   ..   total_2012 = col_character(),
##   ..   snp_1213 = col_character(),
##   ..   free_elig_1213 = col_character(),
##   ..   free_per_1213 = col_character(),
##   ..   red_elig_1213 = col_character(),
##   ..   red_per_1213 = col_character(),
##   ..   totalFRL_1213 = col_character(),
##   ..   totalper_1213 = col_character(),
##   ..   type1314 = col_character(),
##   ..   lowgrade_2013 = col_character(),
##   ..   higrade_2013 = col_character(),
##   ..   totalFT_2013 = col_character(),
##   ..   total_2013 = col_character(),
##   ..   snp_1314 = col_character(),
##   ..   free_elig_1314 = col_character(),
##   ..   free_per_1314 = col_character(),
##   ..   red_elig_1314 = col_character(),
##   ..   red_per_1314 = col_character(),
##   ..   totalFRL_1314 = col_character(),
##   ..   totalper_1314 = col_character(),
##   ..   type1415 = col_character(),
##   ..   lowgrade_2014 = col_character(),
##   ..   higrade_2014 = col_character(),
##   ..   totalFT_2014 = col_character(),
##   ..   total_2014 = col_character(),
##   ..   snp_1415 = col_character(),
##   ..   free_elig_1415 = col_character(),
##   ..   free_per_1415 = col_character(),
##   ..   red_elig_1415 = col_character(),
##   ..   red_per_1415 = col_character(),
##   ..   totalFRL_1415 = col_character(),
##   ..   totalper_1415 = col_character(),
##   ..   CEP_1516 = col_character(),
##   ..   type1516 = col_character(),
##   ..   lowgrade_2015 = col_character(),
##   ..   higrade_2015 = col_character(),
##   ..   totalFT_2015 = col_character(),
##   ..   total_2015 = col_character(),
##   ..   snp_1516 = col_character(),
##   ..   free_elig_1516 = col_character(),
##   ..   free_per_1516 = col_character(),
##   ..   red_elig_1516 = col_character(),
##   ..   red_Per_1516 = col_character(),
##   ..   totalFRL_1516 = col_character(),
##   ..   totalper_1516 = col_character(),
##   ..   CEP_1617 = col_character(),
##   ..   type1617 = col_character(),
##   ..   lowgrade_2016 = col_character(),
##   ..   higrade_2016 = col_character(),
##   ..   totalFT_2016 = col_character(),
##   ..   total_2016 = col_character(),
##   ..   snp_2016 = col_character(),
##   ..   free_elig_1617 = col_character(),
##   ..   free_per_1617 = col_character(),
##   ..   red_elig_1617 = col_character(),
##   ..   red_per_1617 = col_character(),
##   ..   totalFRL_1617 = col_character(),
##   ..   totalper_1617 = col_character(),
##   ..   CEP_1718 = col_character(),
##   ..   type1718 = col_character(),
##   ..   lowgrade_2017 = col_character(),
##   ..   higrade_2017 = col_character(),
##   ..   totalFT_2017 = col_character(),
##   ..   total_2017 = col_character(),
##   ..   snp_1718 = col_character(),
##   ..   free_elig_1718 = col_character(),
##   ..   free_per_1718 = col_character(),
##   ..   red_elig_1718 = col_character(),
##   ..   red_per_1718 = col_character(),
##   ..   totalFRL_1718 = col_character(),
##   ..   totalper_1718 = col_character(),
##   ..   stable = col_character(),
##   ..   new = col_character(),
##   ..   closed = col_character(),
##   ..   close_yr = col_character(),
##   ..   reuseid = col_character(),
##   ..   gradechg = col_character(),
##   ..   gradechg_yr = col_character(),
##   ..   grchgyr_2 = col_character()
##   .. )
\end{verbatim}

Or just check the structure of one specific variable.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(mydata}\SpecialCharTok{$}\NormalTok{total\_2017)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  chr [1:2101] "742" "236" "60" "624" "286" "485" "583" "550" "600" "514" ...
\end{verbatim}

\textbf{NOTE:} When you have a lot of variables, running this str() function is not a great idea - the output is a little too cumbersome

\hypertarget{mutating-variables}{%
\section{Mutating Variables}\label{mutating-variables}}

Note that almost all of the data reads in as a ``character'' data type which are just strings,
This can create issues.

We know that many of the columns are actually storing numbers or ``numeric'' values as R refers to them.
We need to fix this.

Let's tell R that these columns (at least the two we are going to use) are numeric.

We are going to see two interchangeable ways to do this.

First, we use the \$ operator which lets me specify a specific column within my data frame in combination with the as.numeric() function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata}\SpecialCharTok{$}\NormalTok{total\_2017}\OtherTok{\textless{}{-}}\FunctionTok{as.numeric}\NormalTok{(mydata}\SpecialCharTok{$}\NormalTok{total\_2017)}
\NormalTok{mydata}\SpecialCharTok{$}\NormalTok{totalFRL\_1718}\OtherTok{\textless{}{-}}\FunctionTok{as.numeric}\NormalTok{(mydata}\SpecialCharTok{$}\NormalTok{totalFRL\_1718)}
\end{Highlighting}
\end{Shaded}

Some columns have a percent symbol, which you will need to remove before coercing to numeric data type

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OtherTok{\textless{}{-}}\NormalTok{ mydata }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{totalper\_0809 =} \FunctionTok{str\_remove}\NormalTok{(totalper\_0809, }\StringTok{"\%"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Then we can change the column from character to numeric

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata}\SpecialCharTok{$}\NormalTok{totalper\_0809 }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mydata}\SpecialCharTok{$}\NormalTok{totalper\_0809)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: NAs introduced by coercion
\end{verbatim}

Check to make sure it converted the column type correctly using \texttt{str()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(mydata}\SpecialCharTok{$}\NormalTok{totalper\_0809)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  num [1:2101] 56.1 40.1 47.5 55.5 33.4 ...
\end{verbatim}

Second, alternatively, we can do this for a whole set of variables at once. We just need to specify a matching criteria.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newdf }\OtherTok{\textless{}{-}}\NormalTok{ mydata }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate\_at}\NormalTok{(}\FunctionTok{vars}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"total"}\NormalTok{)), as.numeric)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion

## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newdf }\OtherTok{\textless{}{-}}\NormalTok{ newdf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate\_at}\NormalTok{(}\FunctionTok{vars}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"totalFRL"}\NormalTok{)), as.numeric)}
\end{Highlighting}
\end{Shaded}

Check whether the old and new variables are stored differently (old as a character, new as a numeric variable)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(mydata}\SpecialCharTok{$}\NormalTok{total\_2008)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  chr [1:2101] "731" "263" "80" "638" "333" "536" "610" "490" "585" "450" ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(newdf}\SpecialCharTok{$}\NormalTok{total\_2008)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  num [1:2101] 731 263 80 638 333 536 610 490 585 450 ...
\end{verbatim}

\hypertarget{filtering-and-selecting}{%
\section{Filtering and Selecting}\label{filtering-and-selecting}}

A basic operation we do a lot is to filter the data so that we are working with a subset of all that we have.

We can do this with the filter() function, part of the dplyr package (in the tidyverse collection of packages).

Let's say we want to look at the schools with div\_num values less than 50.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newdf }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(div\_num }\SpecialCharTok{\textless{}} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 800 x 137
##    sch_id div_num div_name school_num school_name school_name2 type0809
##    <chr>    <dbl> <chr>    <chr>      <chr>       <chr>        <chr>   
##  1 001-0~       1 Accomac~ "0070\xa0" NANDUA HIGH <NA>         SCH-HIGH
##  2 001-0~       1 Accomac~ "0080\xa0" CHINCOTEAG~ <NA>         SCH-ELEM
##  3 001-0~       1 Accomac~ "0530\xa0" TANGIER CO~ <NA>         SCH-COMB
##  4 001-0~       1 Accomac~ "0540\xa0" ARCADIA HI~ <NA>         SCH-HIGH
##  5 001-0~       1 Accomac~ "0580\xa0" CHINCOTEAG~ <NA>         SCH-COMB
##  6 001-0~       1 Accomac~ "0590\xa0" PUNGOTEAGU~ <NA>         SCH-ELEM
##  7 001-0~       1 Accomac~ "0600\xa0" KEGOTANK E~ <NA>         SCH-ELEM
##  8 001-0~       1 Accomac~ "0701\xa0" ACCAWMACKE~ <NA>         SCH-ELEM
##  9 001-0~       1 Accomac~ "0702\xa0" METOMPKIN ~ <NA>         SCH-ELEM
## 10 001-0~       1 Accomac~ "0703\xa0" NANDUA MID~ <NA>         SCH-MID 
## # ... with 790 more rows, and 130 more variables: lowgrade_2008 <chr>,
## #   higrade_2008 <chr>, totalFT_2008 <dbl>, total_2008 <dbl>, snp_0809 <chr>,
## #   free_elig_0809 <chr>, free_per_0809 <chr>, red_elig_0809 <chr>,
## #   red_per_0809 <chr>, totalFRL_0809 <dbl>, totalper_0809 <dbl>,
## #   type0910 <chr>, lowgrade_2009 <chr>, higrade_2009 <chr>,
## #   totalFT_2009 <dbl>, total_2009 <dbl>, snp_0910 <chr>, free_elig_0910 <chr>,
## #   free_per_0910 <chr>, red_elig_0910 <chr>, red_per_0910 <chr>,
## #   totalFRL_09010 <dbl>, totalper_0910 <dbl>, type1011 <chr>,
## #   lowgrade_2010 <chr>, higrade_2010 <chr>, totalFT_2010 <dbl>,
## #   total_2010 <dbl>, snp_1011 <chr>, free_elig_1011 <chr>,
## #   free_per_1011 <chr>, red_elig_1011 <chr>, red_per_1011 <chr>,
## #   totalFRL_1011 <dbl>, totalper_1011 <dbl>, type1112 <chr>,
## #   lowgrade_2011 <chr>, higrade_2011 <chr>, totalFT_2011 <dbl>,
## #   total_2011 <dbl>, snp_1112 <chr>, free_elig_1112 <chr>,
## #   free_per_1112 <chr>, red_elig_1112 <chr>, red_per_1112 <chr>,
## #   totalFRL_1112 <dbl>, totalper_1112 <dbl>, type1213 <chr>,
## #   lowgrade_2012 <chr>, higrade_2012 <chr>, totalFT_2012 <dbl>,
## #   total_2012 <dbl>, snp_1213 <chr>, free_elig_1213 <chr>,
## #   free_per_1213 <chr>, red_elig_1213 <chr>, red_per_1213 <chr>,
## #   totalFRL_1213 <dbl>, totalper_1213 <dbl>, type1314 <chr>,
## #   lowgrade_2013 <chr>, higrade_2013 <chr>, totalFT_2013 <dbl>,
## #   total_2013 <dbl>, snp_1314 <chr>, free_elig_1314 <chr>,
## #   free_per_1314 <chr>, red_elig_1314 <chr>, red_per_1314 <chr>,
## #   totalFRL_1314 <dbl>, totalper_1314 <dbl>, type1415 <chr>,
## #   lowgrade_2014 <chr>, higrade_2014 <chr>, totalFT_2014 <dbl>,
## #   total_2014 <dbl>, snp_1415 <chr>, free_elig_1415 <chr>,
## #   free_per_1415 <chr>, red_elig_1415 <chr>, red_per_1415 <chr>,
## #   totalFRL_1415 <dbl>, totalper_1415 <dbl>, CEP_1516 <chr>, type1516 <chr>,
## #   lowgrade_2015 <chr>, higrade_2015 <chr>, totalFT_2015 <dbl>,
## #   total_2015 <dbl>, snp_1516 <chr>, free_elig_1516 <chr>,
## #   free_per_1516 <chr>, red_elig_1516 <chr>, red_Per_1516 <chr>,
## #   totalFRL_1516 <dbl>, totalper_1516 <dbl>, CEP_1617 <chr>, type1617 <chr>,
## #   lowgrade_2016 <chr>, higrade_2016 <chr>, ...
\end{verbatim}

Or, if we want to look at schools where the highest grade in 2008 was grade five, we can try:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newdf }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(higrade\_2008 }\SpecialCharTok{==} \StringTok{"5"}\NormalTok{) }\CommentTok{\# this returns a subsetted dataframe with 878 rows}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 878 x 137
##    sch_id div_num div_name school_num school_name school_name2 type0809
##    <chr>    <dbl> <chr>    <chr>      <chr>       <chr>        <chr>   
##  1 001-0~       1 Accomac~ "0080\xa0" CHINCOTEAG~ <NA>         SCH-ELEM
##  2 001-0~       1 Accomac~ "0590\xa0" PUNGOTEAGU~ <NA>         SCH-ELEM
##  3 001-0~       1 Accomac~ "0600\xa0" KEGOTANK E~ <NA>         SCH-ELEM
##  4 001-0~       1 Accomac~ "0701\xa0" ACCAWMACKE~ <NA>         SCH-ELEM
##  5 001-0~       1 Accomac~ "0702\xa0" METOMPKIN ~ <NA>         SCH-ELEM
##  6 002-0~       2 Albemar~ "0010\xa0" HOLLYMEAD ~ <NA>         SCH-ELEM
##  7 002-0~       2 Albemar~ "0030\xa0" SCOTTSVILL~ <NA>         SCH-ELEM
##  8 002-0~       2 Albemar~ "0040\xa0" MARY CARR ~ <NA>         SCH-ELEM
##  9 002-0~       2 Albemar~ "0100\xa0" BROADUS WO~ <NA>         SCH-ELEM
## 10 002-0~       2 Albemar~ "0150\xa0" PAUL H CAL~ <NA>         SCH-ELEM
## # ... with 868 more rows, and 130 more variables: lowgrade_2008 <chr>,
## #   higrade_2008 <chr>, totalFT_2008 <dbl>, total_2008 <dbl>, snp_0809 <chr>,
## #   free_elig_0809 <chr>, free_per_0809 <chr>, red_elig_0809 <chr>,
## #   red_per_0809 <chr>, totalFRL_0809 <dbl>, totalper_0809 <dbl>,
## #   type0910 <chr>, lowgrade_2009 <chr>, higrade_2009 <chr>,
## #   totalFT_2009 <dbl>, total_2009 <dbl>, snp_0910 <chr>, free_elig_0910 <chr>,
## #   free_per_0910 <chr>, red_elig_0910 <chr>, red_per_0910 <chr>,
## #   totalFRL_09010 <dbl>, totalper_0910 <dbl>, type1011 <chr>,
## #   lowgrade_2010 <chr>, higrade_2010 <chr>, totalFT_2010 <dbl>,
## #   total_2010 <dbl>, snp_1011 <chr>, free_elig_1011 <chr>,
## #   free_per_1011 <chr>, red_elig_1011 <chr>, red_per_1011 <chr>,
## #   totalFRL_1011 <dbl>, totalper_1011 <dbl>, type1112 <chr>,
## #   lowgrade_2011 <chr>, higrade_2011 <chr>, totalFT_2011 <dbl>,
## #   total_2011 <dbl>, snp_1112 <chr>, free_elig_1112 <chr>,
## #   free_per_1112 <chr>, red_elig_1112 <chr>, red_per_1112 <chr>,
## #   totalFRL_1112 <dbl>, totalper_1112 <dbl>, type1213 <chr>,
## #   lowgrade_2012 <chr>, higrade_2012 <chr>, totalFT_2012 <dbl>,
## #   total_2012 <dbl>, snp_1213 <chr>, free_elig_1213 <chr>,
## #   free_per_1213 <chr>, red_elig_1213 <chr>, red_per_1213 <chr>,
## #   totalFRL_1213 <dbl>, totalper_1213 <dbl>, type1314 <chr>,
## #   lowgrade_2013 <chr>, higrade_2013 <chr>, totalFT_2013 <dbl>,
## #   total_2013 <dbl>, snp_1314 <chr>, free_elig_1314 <chr>,
## #   free_per_1314 <chr>, red_elig_1314 <chr>, red_per_1314 <chr>,
## #   totalFRL_1314 <dbl>, totalper_1314 <dbl>, type1415 <chr>,
## #   lowgrade_2014 <chr>, higrade_2014 <chr>, totalFT_2014 <dbl>,
## #   total_2014 <dbl>, snp_1415 <chr>, free_elig_1415 <chr>,
## #   free_per_1415 <chr>, red_elig_1415 <chr>, red_per_1415 <chr>,
## #   totalFRL_1415 <dbl>, totalper_1415 <dbl>, CEP_1516 <chr>, type1516 <chr>,
## #   lowgrade_2015 <chr>, higrade_2015 <chr>, totalFT_2015 <dbl>,
## #   total_2015 <dbl>, snp_1516 <chr>, free_elig_1516 <chr>,
## #   free_per_1516 <chr>, red_elig_1516 <chr>, red_Per_1516 <chr>,
## #   totalFRL_1516 <dbl>, totalper_1516 <dbl>, CEP_1617 <chr>, type1617 <chr>,
## #   lowgrade_2016 <chr>, higrade_2016 <chr>, ...
\end{verbatim}

Note that we had to set it equal to the character value ``5'' rather than the numeric value 5. Why?

If we wanted to filter on numeric values instead, we would want to do something like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newdf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{higrade\_2008 =} \FunctionTok{as.numeric}\NormalTok{(higrade\_2008)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(higrade\_2008 }\SpecialCharTok{==} \DecValTok{5}\NormalTok{) }\CommentTok{\# again, this returns a subsetted dataframe with 878 rows}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in mask$eval_all_mutate(dots[[i]]): NAs introduced by coercion
\end{verbatim}

\begin{verbatim}
## # A tibble: 878 x 137
##    sch_id div_num div_name school_num school_name school_name2 type0809
##    <chr>    <dbl> <chr>    <chr>      <chr>       <chr>        <chr>   
##  1 001-0~       1 Accomac~ "0080\xa0" CHINCOTEAG~ <NA>         SCH-ELEM
##  2 001-0~       1 Accomac~ "0590\xa0" PUNGOTEAGU~ <NA>         SCH-ELEM
##  3 001-0~       1 Accomac~ "0600\xa0" KEGOTANK E~ <NA>         SCH-ELEM
##  4 001-0~       1 Accomac~ "0701\xa0" ACCAWMACKE~ <NA>         SCH-ELEM
##  5 001-0~       1 Accomac~ "0702\xa0" METOMPKIN ~ <NA>         SCH-ELEM
##  6 002-0~       2 Albemar~ "0010\xa0" HOLLYMEAD ~ <NA>         SCH-ELEM
##  7 002-0~       2 Albemar~ "0030\xa0" SCOTTSVILL~ <NA>         SCH-ELEM
##  8 002-0~       2 Albemar~ "0040\xa0" MARY CARR ~ <NA>         SCH-ELEM
##  9 002-0~       2 Albemar~ "0100\xa0" BROADUS WO~ <NA>         SCH-ELEM
## 10 002-0~       2 Albemar~ "0150\xa0" PAUL H CAL~ <NA>         SCH-ELEM
## # ... with 868 more rows, and 130 more variables: lowgrade_2008 <chr>,
## #   higrade_2008 <dbl>, totalFT_2008 <dbl>, total_2008 <dbl>, snp_0809 <chr>,
## #   free_elig_0809 <chr>, free_per_0809 <chr>, red_elig_0809 <chr>,
## #   red_per_0809 <chr>, totalFRL_0809 <dbl>, totalper_0809 <dbl>,
## #   type0910 <chr>, lowgrade_2009 <chr>, higrade_2009 <chr>,
## #   totalFT_2009 <dbl>, total_2009 <dbl>, snp_0910 <chr>, free_elig_0910 <chr>,
## #   free_per_0910 <chr>, red_elig_0910 <chr>, red_per_0910 <chr>,
## #   totalFRL_09010 <dbl>, totalper_0910 <dbl>, type1011 <chr>,
## #   lowgrade_2010 <chr>, higrade_2010 <chr>, totalFT_2010 <dbl>,
## #   total_2010 <dbl>, snp_1011 <chr>, free_elig_1011 <chr>,
## #   free_per_1011 <chr>, red_elig_1011 <chr>, red_per_1011 <chr>,
## #   totalFRL_1011 <dbl>, totalper_1011 <dbl>, type1112 <chr>,
## #   lowgrade_2011 <chr>, higrade_2011 <chr>, totalFT_2011 <dbl>,
## #   total_2011 <dbl>, snp_1112 <chr>, free_elig_1112 <chr>,
## #   free_per_1112 <chr>, red_elig_1112 <chr>, red_per_1112 <chr>,
## #   totalFRL_1112 <dbl>, totalper_1112 <dbl>, type1213 <chr>,
## #   lowgrade_2012 <chr>, higrade_2012 <chr>, totalFT_2012 <dbl>,
## #   total_2012 <dbl>, snp_1213 <chr>, free_elig_1213 <chr>,
## #   free_per_1213 <chr>, red_elig_1213 <chr>, red_per_1213 <chr>,
## #   totalFRL_1213 <dbl>, totalper_1213 <dbl>, type1314 <chr>,
## #   lowgrade_2013 <chr>, higrade_2013 <chr>, totalFT_2013 <dbl>,
## #   total_2013 <dbl>, snp_1314 <chr>, free_elig_1314 <chr>,
## #   free_per_1314 <chr>, red_elig_1314 <chr>, red_per_1314 <chr>,
## #   totalFRL_1314 <dbl>, totalper_1314 <dbl>, type1415 <chr>,
## #   lowgrade_2014 <chr>, higrade_2014 <chr>, totalFT_2014 <dbl>,
## #   total_2014 <dbl>, snp_1415 <chr>, free_elig_1415 <chr>,
## #   free_per_1415 <chr>, red_elig_1415 <chr>, red_per_1415 <chr>,
## #   totalFRL_1415 <dbl>, totalper_1415 <dbl>, CEP_1516 <chr>, type1516 <chr>,
## #   lowgrade_2015 <chr>, higrade_2015 <chr>, totalFT_2015 <dbl>,
## #   total_2015 <dbl>, snp_1516 <chr>, free_elig_1516 <chr>,
## #   free_per_1516 <chr>, red_elig_1516 <chr>, red_Per_1516 <chr>,
## #   totalFRL_1516 <dbl>, totalper_1516 <dbl>, CEP_1617 <chr>, type1617 <chr>,
## #   lowgrade_2016 <chr>, higrade_2016 <chr>, ...
\end{verbatim}

\hypertarget{grouping-and-summarizing}{%
\section{Grouping and Summarizing}\label{grouping-and-summarizing}}

Let's shift gears to a different combination of operations\ldots{}

Let's go ahead and try using tidyverse to narrow to what we want.
Imagine we want to see the county level aggregate numbers for FRL in the 2017-2018 school year.

We will start out with our entire data frame and then use pipes (the \%\textgreater\% operator) to work from there.
The final result will be stored in our new data frame that we are creating, called county\_level\_aggregate.

First, select will pick columns
Next, group\_by and summarize work together to get us our aggregate totals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{county\_level\_aggregate }\OtherTok{\textless{}{-}}\NormalTok{ newdf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(div\_name, total\_2017, totalFRL\_1718) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(div\_name) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{totalstudents =} \FunctionTok{sum}\NormalTok{(total\_2017), }
            \AttributeTok{totalFRL =} \FunctionTok{sum}\NormalTok{(totalFRL\_1718))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

Now, we can compute percentages if we like and we can specify a new column by referring to. One that doesn't exist yet but will after we run this code. We will do this two interchangeable ways.

First, the old school way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{county\_level\_aggregate}\SpecialCharTok{$}\NormalTok{percent\_FRL }\OtherTok{\textless{}{-}}\NormalTok{ county\_level\_aggregate}\SpecialCharTok{$}\NormalTok{totalFRL}\SpecialCharTok{/}\NormalTok{county\_level\_aggregate}\SpecialCharTok{$}\NormalTok{totalstudents}\SpecialCharTok{*}\DecValTok{100}
\end{Highlighting}
\end{Shaded}

Second, the tidyverse way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{county\_level\_aggregate }\OtherTok{\textless{}{-}}\NormalTok{ county\_level\_aggregate }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{percent\_frl =}\NormalTok{ totalFRL }\SpecialCharTok{/}\NormalTok{ totalstudents }\SpecialCharTok{*} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Just for fun, let's see how this could have been incorporated into our summarize call

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{county\_level\_percents }\OtherTok{\textless{}{-}}\NormalTok{ newdf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(div\_name, total\_2017, totalFRL\_1718) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(div\_name) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{percentFRL=}\FunctionTok{sum}\NormalTok{(totalFRL\_1718)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(total\_2017) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

Something is going to look weird with this plot

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newdf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(totalFRL\_0809, totalFT\_2008)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"FRL 2008"}\NormalTok{, }\AttributeTok{x =} \StringTok{"totalFRL\_0809"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 236 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-55-1.pdf}

Let's see if we can fix it

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newdf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(totalFRL\_0809)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(totalFRL\_0809, totalFT\_2008)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"FRL 2008"}\NormalTok{, }
       \AttributeTok{x =} \StringTok{"totalFRL\_0809"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1000}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 324 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-56-1.pdf}

\hypertarget{week-4-assumptions-and-correlations}{%
\chapter{Week 4: Assumptions and Correlations}\label{week-4-assumptions-and-correlations}}

This week we will be discussing Chapters 5 and 6 from DSUR. These notes will pull out some of the important pieces from each chapter.

\hypertarget{assumptions}{%
\section{Assumptions}\label{assumptions}}

These assumptions that we are making are helpful when determining whether we should be using parametric vs non-parametric statistical tests. What does ``parametric'' mean here? It means that the data are from a parameterized distribution (i.e., parameters characterize the distribution that the data come from). An example of a parameterized distribution that we have already seen is the normal distribution. The two parameters for the normal distribution are \(\mu\) for the mean and \(\sigma\) for the standard deviation. We have seen this altogether with this kind of notation to denote that \(x_i\) is from a normal distribution:

\(x_i \sim \mathcal{N} (\mu, \,\sigma^{2})\)

\hypertarget{normally-distributed-data}{%
\subsection{Normally distributed data}\label{normally-distributed-data}}

This assumption is about the normality of the sampling distribution. The big idea here is that we tend to operate under the belief that if our \emph{sampled} data are normally distributed then the underlying \emph{sampling distribution} is also normally distributed. Also, keep in mind that this becomes less of a concern as our sample size increases (thank, Central Limit Theorem!).

There are several tests for normality that we will discuss, which include either (a) calculations or (b) visual examination. We will discuss both.

\hypertarget{visual-check-of-normality}{%
\subsubsection{Visual check of normality}\label{visual-check-of-normality}}

You can accomplish this with a histogram (e.g., \texttt{hist()} or \texttt{geom\_histogram()} or a q-q plot \texttt{qplot()} (which stands for quantile-quantile).

\hypertarget{homogeneity-of-variance}{%
\subsection{Homogeneity of variance}\label{homogeneity-of-variance}}

Here, you want to know whether the variance of a variable is the same across different groups. For example, if you are looking at test scores in chemistry and chemical engineering students, you want to know if the variances (spread) of the test scores in the chemistry group and the chemical engineering group are close to each other.

\hypertarget{interval-data}{%
\subsection{Interval data}\label{interval-data}}

This might be a little redundant given that we want normally distributed data, but you want at least interval data (ratio data are also fine, but in practice very few things we work with actually qualify as ratio variables). If you have ordinal or nominal variables, you might be in trouble with this assumption\ldots{}

\hypertarget{independence}{%
\subsection{Independence}\label{independence}}

This assumption is about the observations not being related to each other or affecting each other in some way. In practice, this can also be a little tricky. For example, if you are sampling students from different classrooms, depending on the variables you are measuring, you might actually have reason to believe that students in one classroom are more related to each other than students in a different classroom. In practice, you can handle this with a multi-level model (aka hierarchical model), but that is beyond the scope of this class.

\hypertarget{correlation}{%
\section{Correlation}\label{correlation}}

\hypertarget{covariance}{%
\subsection{Covariance}\label{covariance}}

First, start with the observation that variance is calculated with:
\(Variance(s^2) = \frac{\sum(x_i - \overline{x})^2}{N - 1} = \frac{\sum(x_i - \overline{x})(x_i - \overline{x})}{N - 1}\)

But now let's say that we want to know how, for each observation we have, how does the value of \(x\) vary with the value of \(y\) on average. For example, when the value of \(x\) increases, does the value of \(y\) also increase? This could happen when \(x\) represents the number of hours of sleep you get each night and \(y\) is your average grade on an exam you take the next day. The opposite could arise when \(x\) increases but we expect \(y\) to go down. An example of this might be when \(x\) is the number of hilarious jokes that a teacher tells in class and \(y\) is the number of students who fall asleep in class. As the number of jokes increases, we might expect/hope that it keeps students' attention and keeps them from dozing. This generally process of considering how one variable changes when another variable changes is where the notion of covariance comes in.

In practice, what we really want to know is: when \(x_i\) is above its average value in a sample (\(\overline{x}\)), how does \(y_i\) change? Does it also tend to be above the sample average for \(y\) (\(\overline{y}\))? This is expressed in the general formular for covariance:

\(cov(x,y) = \frac{\sum(x_i - \overline{x})(y_i - \overline{y})}{N - 1}\)

While covariance can be a helpful value to work with in many settings, for most of what we do in this class, we will be using correlation coefficients instead of covariance. This is because covariance is an unnormalized value, which can make comparisons across different ranges of values difficult.

\hypertarget{correlation-coefficient}{%
\subsection{Correlation coefficient}\label{correlation-coefficient}}

In order to standardize the covariance to a value the is easier to work with across ranges of values, we use the correlatoin coefficient. There are several version of this, depending on the type of data you are working with. The most basic version is the Pearson correlation coefficient. It is calculated by dividing the covariance by the standard deviations of your two variables of interest:

\(r = \frac{cov_{xy}}{s_xs_y} = \frac{\sum(x_i - \overline{x})(y_i - \overline{y})}{(N-1)s_xs_y}\)

This is a \emph{bivariate} correlation coefficient because it is looking at the correlation between \emph{two variables}. There are also partial correlation coefficients, which look at the correlation between two variables whil controlling for other variables.

We can calculate the correlatoin between two variables using the \texttt{cor()} or \texttt{cor.test()} functions, which are part of base R.

\hypertarget{another-worked-example-for-cleaning-and-prelim-analysis}{%
\section{Another worked example for cleaning and prelim analysis}\label{another-worked-example-for-cleaning-and-prelim-analysis}}

This script takes an incomplete subset of senior data from a .csv file, cleans it,
computes factor scores, and prepares it for analysis.

If you have not already done so, make sure that you have run \texttt{library(tidyverse)} and \texttt{library(psych)} since we will be using functions from both of those packages.

\hypertarget{loading-in-data}{%
\subsection{Loading in data}\label{loading-in-data}}

First, as usual, load in your data. We will use the file \texttt{seniorsurvey.csv} for this demo.

\texttt{file\_path\ \textless{}-\ "YOUR\ PATH\ HERE"}
\texttt{setwd(file\_path)} use this command to change the working directory to the folder where you have your file
\texttt{list.files()} run this to make sure that your file is in your current working directory

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{seniorSurvey\_df }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"seniorsurvey.csv"}\NormalTok{) }\CommentTok{\# replace text in the parentheses with your file name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   .default = col_double()
## )
\end{verbatim}

\begin{verbatim}
## See spec(...) for full column specifications.
\end{verbatim}

\hypertarget{data-prep-and-cleaning}{%
\subsection{Data prep and cleaning}\label{data-prep-and-cleaning}}

After loading, it is always nice to just see how things loaded in. Functions like str() and describe() from the psych package are nice for this. For example, if we use describe(), we can see the following (we deleted some variables):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{describe}\NormalTok{(seniorSurvey\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                                   vars    n  mean    sd median
## What is your PRIMARY MAJOR?                          1 1849 31.79 20.43     29
## Internship, field experience, co-op, or practicum    2 1121  1.00  0.00      1
## ParticipateServiceL                                  3  489  1.00  0.00      1
## ParticipateCService                                  4 1296  1.00  0.00      1
## ParticipateStudyAbroadSemester                       5  142  1.00  0.00      1
## SJ1                                                  6 1733  2.32  1.03      2
## SJ2                                                  7 1732  2.08  0.96      2
## SJ3                                                  8 1731  2.77  0.88      3
## SJ4                                                  9 1726  2.27  1.01      2
## SJ5                                                 10 1728  3.27  0.92      3
## SJ6                                                 11 1719  3.50  0.83      4
## SJ7                                                 12 1719  4.01  0.79      4
## SJ8                                                 13 1719  4.15  0.83      4
## DA1                                                 14 1719  2.23  0.93      2
## DA2                                                 15 1719  2.86  0.95      3
## DA3                                                 16 1720  1.97  0.81      2
## DA4                                                 17 1721  4.20  0.72      4
## DA5                                                 18 1721  4.06  0.81      4
## LocalRole                                           19 1453  3.49  0.94      4
## LocalFinance                                        20 1453  3.22  0.90      3
## LocalTime                                           21 1453  3.58  0.89      4
## GlobalRole                                          22 1446  3.57  0.99      4
## GlobalFinance                                       23 1449  3.19  1.00      3
## GlobalTime                                          24 1449  3.42  0.98      3
## Your gender?                                        25 1678  1.49  0.50      1
##                                                   trimmed   mad min max range
## What is your PRIMARY MAJOR?                         31.25 28.17   1  70    69
## Internship, field experience, co-op, or practicum    1.00  0.00   1   1     0
## ParticipateServiceL                                  1.00  0.00   1   1     0
## ParticipateCService                                  1.00  0.00   1   1     0
## ParticipateStudyAbroadSemester                       1.00  0.00   1   1     0
## SJ1                                                  2.25  1.48   1   5     4
## SJ2                                                  1.98  1.48   1   5     4
## SJ3                                                  2.79  1.48   1   5     4
## SJ4                                                  2.20  1.48   1   5     4
## SJ5                                                  3.27  1.48   1   5     4
## SJ6                                                  3.54  1.48   1   5     4
## SJ7                                                  4.07  0.00   1   5     4
## SJ8                                                  4.23  1.48   1   5     4
## DA1                                                  2.15  1.48   1   5     4
## DA2                                                  2.89  1.48   1   5     4
## DA3                                                  1.90  0.00   1   5     4
## DA4                                                  4.27  1.48   1   5     4
## DA5                                                  4.11  1.48   1   5     4
## LocalRole                                            3.51  1.48   1   5     4
## LocalFinance                                         3.23  1.48   1   5     4
## LocalTime                                            3.63  1.48   1   5     4
## GlobalRole                                           3.62  1.48   1   5     4
## GlobalFinance                                        3.18  1.48   1   5     4
## GlobalTime                                           3.44  1.48   1   5     4
## Your gender?                                         1.49  0.00   1   2     1
##                                                    skew kurtosis   se
## What is your PRIMARY MAJOR?                        0.18    -1.33 0.48
## Internship, field experience, co-op, or practicum   NaN      NaN 0.00
## ParticipateServiceL                                 NaN      NaN 0.00
## ParticipateCService                                 NaN      NaN 0.00
## ParticipateStudyAbroadSemester                      NaN      NaN 0.00
## SJ1                                                0.46    -0.51 0.02
## SJ2                                                0.64    -0.16 0.02
## SJ3                                               -0.03    -0.14 0.02
## SJ4                                                0.52    -0.40 0.02
## SJ5                                               -0.19    -0.03 0.02
## SJ6                                               -0.40     0.15 0.02
## SJ7                                               -0.75     1.05 0.02
## SJ8                                               -0.86     0.69 0.02
## DA1                                                0.57    -0.11 0.02
## DA2                                               -0.09    -0.41 0.02
## DA3                                                0.70     0.31 0.02
## DA4                                               -0.66     0.54 0.02
## DA5                                               -0.59     0.16 0.02
## LocalRole                                         -0.44    -0.33 0.02
## LocalFinance                                      -0.19    -0.27 0.02
## LocalTime                                         -0.59     0.22 0.02
## GlobalRole                                        -0.47    -0.30 0.03
## GlobalFinance                                     -0.11    -0.33 0.03
## GlobalTime                                        -0.35    -0.17 0.03
## Your gender?                                       0.03    -2.00 0.01
\end{verbatim}

Upon examining this, we can notice a few things:
Primary Major variable is all messed up. We won't fix it here, but basically there is a numeric code needed (e.g., 13 = underwater basket weaving)

Columns 3 and 5 have lots of missing values (note the small N's) -- this means that this was asked via checkbox so (1) is true and missing is not missing but False

SJ1-8 and DA1-5 all look essentially ok -- about the same N (some survey fatigue or skips) but all values in range (1-5)

Now, we know that SJ and DA are scales from the literature and we want to compute scale scores for those. Typically for attitude scales like these we just report means across the items. So, we will use the ``psych'' package to use a built in function to help us with this. If you have not used psych yet, be sure it is installed using the command install.packages(``psych'') -- you need only do this once and then in subsequent uses you only need \texttt{library(psych)} to tell R to look in that package for the functions you will be using.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(psych)}
\end{Highlighting}
\end{Shaded}

Subset out only the SJ and DA items in their own dataframe and then use tools in the psych package to compute scale means

The first method to do this - use numbering of the columns:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{seniorSurveyScales\_df }\OtherTok{\textless{}{-}}\NormalTok{ seniorSurvey\_df[}\DecValTok{6}\SpecialCharTok{:}\DecValTok{18}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

A second method to do this - use select() from dplyr

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{seniorSurveyScales\_df }\OtherTok{\textless{}{-}}\NormalTok{ seniorSurvey\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(SJ1}\SpecialCharTok{:}\NormalTok{DA5)}
\end{Highlighting}
\end{Shaded}

Use the make.keys() function from psych package to key-in how the scales are built (mapping items to scales, use - for reverse scored items)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_keys }\OtherTok{\textless{}{-}} \FunctionTok{make.keys}\NormalTok{(seniorSurveyScales\_df, }\FunctionTok{list}\NormalTok{(}\AttributeTok{SJCa=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{4}\NormalTok{),}\AttributeTok{SJCh=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{),}\AttributeTok{DA=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{9}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{11}\NormalTok{,}\DecValTok{12}\NormalTok{,}\DecValTok{13}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

Use scoreItems function to score each respondent on the three scales of interest SJCa, SJCh, and DA -- the default here in scoreItems is to takes the mean of the items (not additive though that is sometimes used) and also, it imputes missing values instead of dropping cases the scoreItems function calculates many things. At this stage, all we really want are the scores, so we include a line to only extract that info.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_scales }\OtherTok{\textless{}{-}} \FunctionTok{scoreItems}\NormalTok{(my\_keys, seniorSurveyScales\_df) }
\NormalTok{my\_scores }\OtherTok{\textless{}{-}}\NormalTok{ my\_scales}\SpecialCharTok{$}\NormalTok{scores}
\end{Highlighting}
\end{Shaded}

Now, if you view the first few rows of the my.scores vector using the header -- head() command -- it looks like we expect:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(my\_scores)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      SJCa     SJCh  DA
## [1,] 2.75 3.000000 3.2
## [2,] 3.75 3.333333 4.2
## [3,] 3.00 3.000000 3.0
## [4,] 2.25 4.333333 3.6
## [5,] 3.00 3.333333 3.4
## [6,] 4.50 4.333333 3.4
\end{verbatim}

Now, let's build a clean dataframe to prep for analysis - by clean in this case I mean that we have replaced item scores from the scales with their means and also that we have fixed the NAs that don't belong (for participation variables, in this dataset, the NAs should be 0s)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(seniorSurvey\_df[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{],my\_scores, seniorSurvey\_df[}\DecValTok{19}\SpecialCharTok{:}\DecValTok{25}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

This is an old school method to replace NAs in specific columns

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df}\SpecialCharTok{$}\NormalTok{ParticipateServiceL[}\FunctionTok{is.na}\NormalTok{(my\_df}\SpecialCharTok{$}\NormalTok{ParticipateServiceL)] }\OtherTok{\textless{}{-}} \DecValTok{0} 
\NormalTok{my\_df}\SpecialCharTok{$}\NormalTok{ParticipateCService[}\FunctionTok{is.na}\NormalTok{(my\_df}\SpecialCharTok{$}\NormalTok{ParticipateCService)] }\OtherTok{\textless{}{-}} \DecValTok{0} 
\NormalTok{my\_df}\SpecialCharTok{$}\NormalTok{ParticipateStudyAbroadSemester[}\FunctionTok{is.na}\NormalTok{(my\_df}\SpecialCharTok{$}\NormalTok{ParticipateStudyAbroadSemester)] }\OtherTok{\textless{}{-}} \DecValTok{0} 
\end{Highlighting}
\end{Shaded}

my\_df\(ParticipateInternCoop...[is.na(mydf\)ParticipateInternCoop\ldots){]} \textless- 0 ------- this variable read in cumbersomely named and I don't care about it right now so I'll skip

Here is An alternative method to replace NAs in specific columns:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df }\OtherTok{\textless{}{-}}\NormalTok{ my\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{replace\_na}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{ParticipateCService =} \DecValTok{0}\NormalTok{, }\AttributeTok{ParticipateStudyAbroadSemester =} \DecValTok{0}\NormalTok{, }\AttributeTok{ParticipateServiceL =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{preliminary-analysis}{%
\subsection{Preliminary analysis}\label{preliminary-analysis}}

At this point, we are ready for some analysis

Let's investigate correlations. What seems most obvious would just be to run cor() but, as we found out in class, this can cause us to run full speed ahead without considering assumptions

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_correlations }\OtherTok{\textless{}{-}}\NormalTok{ my\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(SJCa,SJCh,DA) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{cor}\NormalTok{()}
\FunctionTok{print}\NormalTok{(my\_correlations)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           SJCa      SJCh        DA
## SJCa 1.0000000 0.2590211 0.3342276
## SJCh 0.2590211 1.0000000 0.2310703
## DA   0.3342276 0.2310703 1.0000000
\end{verbatim}

Ok, so, it is important that we note that this ran correlations but R doesn't know that this was sample data and therefore that we are interested instatistical significance (or not) of these results AND that our data may need another method (e.g., non-parametric). cor() does have a way to run spearman instead.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_spearman\_correlations }\OtherTok{\textless{}{-}}\NormalTok{ my\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(SJCa,SJCh,DA) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{cor}\NormalTok{(}\AttributeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\FunctionTok{print}\NormalTok{(my\_spearman\_correlations)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           SJCa      SJCh        DA
## SJCa 1.0000000 0.2727828 0.3148168
## SJCh 0.2727828 1.0000000 0.2340174
## DA   0.3148168 0.2340174 1.0000000
\end{verbatim}

If we need p values though, we need to change to something else -- corr.test

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_results }\OtherTok{\textless{}{-}} \FunctionTok{corr.test}\NormalTok{(my\_df}\SpecialCharTok{$}\NormalTok{SJCa,my\_df}\SpecialCharTok{$}\NormalTok{DA)}
\end{Highlighting}
\end{Shaded}

Then we can pull out results from this list or print it. Let's do both.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(my\_results,}\AttributeTok{short=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:corr.test(x = my_df$SJCa, y = my_df$DA)
## Correlation matrix 
## [1] 0.33
## Sample Size 
## [1] 1852
## Probability values  adjusted for multiple tests. 
## [1] 0
## 
##  Confidence intervals based upon normal theory.  To get bootstrapped values, try cor.ci
##       raw.lower raw.r raw.upper raw.p lower.adj upper.adj
## NA-NA      0.29  0.33      0.37     0      0.29      0.37
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_results}\SpecialCharTok{$}\NormalTok{r }\CommentTok{\# correlation coefficient}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3342276
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_results}\SpecialCharTok{$}\NormalTok{p }\CommentTok{\# p{-}value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.433637e-49
\end{verbatim}

Visually, we should be able to see this on a scatterplot. We are going to use qplot which stands for quickplot from within ggplot. It is useful and quicker for simple plotting than building up ggplot (though from the same package) we need to jitter my points (take geom=``jitter'' out if you want to see why)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qplot}\NormalTok{(SJCa,DA,}\AttributeTok{data=}\NormalTok{my\_df,}\AttributeTok{geom=}\StringTok{"jitter"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-72-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qqnorm}\NormalTok{(my\_df}\SpecialCharTok{$}\NormalTok{SJCa, }\AttributeTok{frame =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{qqline}\NormalTok{(my\_df}\SpecialCharTok{$}\NormalTok{SJCa, }\AttributeTok{col =} \StringTok{"steelblue"}\NormalTok{, }\AttributeTok{lwd =} \FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-72-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ SJCa)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-72-3.pdf}

Other functions we used today in class were describe() and also the q-q plot creation to investigate normality assumption copying syntax from the Field, Miles, \& Field book

\hypertarget{week-5-simple-regression}{%
\chapter{Week 5: Simple Regression}\label{week-5-simple-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{require}\NormalTok{(tidyverse)}
\FunctionTok{require}\NormalTok{(psych)}
\FunctionTok{require}\NormalTok{(kableExtra)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: kableExtra
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'kableExtra'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:dplyr':
## 
##     group_rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

This week we will start learning about linear regression. In particular, we focus on simple regression. These kinds of models involve one predictor variable and one continuous outcome variable. Next week we will move to models with multiple regression, which involves - you guessed it - multiple predictor variables.

\hypertarget{general-modeling-philosophy}{%
\section{General Modeling Philosophy}\label{general-modeling-philosophy}}

The general approach is to model the outcome variable as a function of some predictor(s) plus an error term. Mathematically, this looks like:

\(outcome_i = model + error_i\)

where the \(i\) subscript refers to the \(i^{th}\) person in the sample.

\hypertarget{review-of-the-normal-distribution-and-standardizing-variables}{%
\subsubsection{Review of the normal distribution and standardizing variables}\label{review-of-the-normal-distribution-and-standardizing-variables}}

Just to review, let's think about normally distributed variables and the notion of centering and standardizing.

First, we will generate some data by drawing \texttt{n} random numbers from a normal distribution with a mean and standard deviation that we will specify.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{sd }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}

\NormalTok{random\_x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{mean =}\NormalTok{ mean, }\AttributeTok{sd =}\NormalTok{ sd)}
\end{Highlighting}
\end{Shaded}

We can then visualize those numbers

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(random\_x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-74-1.pdf}

Now if we subtract the mean and plot the histogram, notice how the values have all basically shifted to the left along the x-axis.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_mean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(random\_x)}

\NormalTok{centered\_x }\OtherTok{\textless{}{-}}\NormalTok{ random\_x }\SpecialCharTok{{-}}\NormalTok{ sample\_mean}

\FunctionTok{hist}\NormalTok{(centered\_x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-75-1.pdf}

Finally, we can divide by the sample standard deviation, which should have the effect of either stretching or squishing the values along the x-axis (without changing their mean). Pay attention again to the values along the x-axis.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_sd }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(random\_x)}

\NormalTok{standardized\_x }\OtherTok{\textless{}{-}}\NormalTok{ centered\_x }\SpecialCharTok{/}\NormalTok{ sample\_sd}

\FunctionTok{hist}\NormalTok{(standardized\_x)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-76-1.pdf}

This final plot should remind you have the standard normal plot (with mean 0 and standard deviation 1). This is noted as \(x \sim \mathcal{N}(0, 1)\) and is read as ``x is distributed according to a normal distribution with a mean of 0 and variance of 1''.

\hypertarget{data-generation-demo---one-set-sample-size}{%
\section{Data generation demo - one set sample size}\label{data-generation-demo---one-set-sample-size}}

The following is a demo from class, found in the week\_5\_demo.R file

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#store the sample size that we want to use}
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# uniformly sample X values (values for our predictor variable) from 0 to 20 }
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{30}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{) }\CommentTok{\# this gives samp\_size number of random numbers}
\end{Highlighting}
\end{Shaded}

Store the noise values for our different test models

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd\_min }\OtherTok{\textless{}{-}} \DecValTok{2} \CommentTok{\# low noise}
\NormalTok{sd\_med }\OtherTok{\textless{}{-}} \DecValTok{6} \CommentTok{\# medium noise}
\NormalTok{sd\_max }\OtherTok{\textless{}{-}} \DecValTok{12} \CommentTok{\# high noise}
\end{Highlighting}
\end{Shaded}

Generate the outcome variable values under different amounts of noise (the rnorm() function is what is generating noise here)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_noise\_sd\_none }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\CommentTok{\# this is the true relationship without any noise}
\NormalTok{y\_noise\_sd\_min }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_min), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\NormalTok{y\_noise\_sd\_med }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_med), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\NormalTok{y\_noise\_sd\_max }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_max), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Typical step 1: visualize! Let's plot each of these x values vs y

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_none)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy006-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_min)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy006-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_med)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy006-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_max)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy006-4.pdf}

Let's put all of these vectors together into a data frame to make it easier to analyze later on
Note, this is not a vital step for conducting the simple regression

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\StringTok{"x"} \OtherTok{=}\NormalTok{ x, }
                  \StringTok{"y\_noise\_sd\_none"}\OtherTok{=}\NormalTok{y\_noise\_sd\_none, }
                  \StringTok{"y\_noise\_sd\_min"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_min,}
                  \StringTok{"y\_noise\_sd\_med"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_med,}
                  \StringTok{"y\_noise\_sd\_max"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_max)}
\end{Highlighting}
\end{Shaded}

Check out what demo\_df looks like

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(demo\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##       x y_noise_sd_none y_noise_sd_min y_noise_sd_med y_noise_sd_max
##   <dbl>           <dbl>          <dbl>          <dbl>          <dbl>
## 1   8.5            20             18.9           11.7           36.1
## 2  11.9            26.8           26.6           26.7           29.5
## 3  14.3            31.6           31.4           23.8           43.9
## 4   4.9            12.8           15.9            9.3           28.6
## 5  15.7            34.4           33.9           32             25.8
## 6   9.7            22.4           18.8           30.7           24.2
\end{verbatim}

Order by increasing x value

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

Check out what the arrange() function did

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(demo\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##       x y_noise_sd_none y_noise_sd_min y_noise_sd_med y_noise_sd_max
##   <dbl>           <dbl>          <dbl>          <dbl>          <dbl>
## 1   0.1             3.2           4.9            3.1           15.6 
## 2   0.2             3.4           7.6            5.2           23.3 
## 3   0.4             3.8           4              4.1           -1.8 
## 4   0.8             4.6           4.00           1.70           2.60
## 5   0.9             4.8           6.4            4.2           -4.1 
## 6   1.6             6.2           8.7            2.7           -2.90
\end{verbatim}

Let's make this a long df so that we can plot multiple standard deviation values together

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\StringTok{"y\_noise"}\NormalTok{),}
               \AttributeTok{names\_to =} \StringTok{"y\_col"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"y\_val"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Again, check on what this did

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(demo\_df\_long)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##       x y_col           y_val
##   <dbl> <chr>           <dbl>
## 1   0.1 y_noise_sd_none   3.2
## 2   0.1 y_noise_sd_min    4.9
## 3   0.1 y_noise_sd_med    3.1
## 4   0.1 y_noise_sd_max   15.6
## 5   0.2 y_noise_sd_none   3.4
## 6   0.2 y_noise_sd_min    7.6
\end{verbatim}

Let's add in a column to note whether the value is from the min, med, max, or zero sd (noise) model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sd\_val =} \FunctionTok{case\_when}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_none"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_min"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_min,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_med"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_med,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_max"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_max))}
\end{Highlighting}
\end{Shaded}

Use facet\_grid to separate the plots out by

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y\_val)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(.}\SpecialCharTok{\textasciitilde{}}\NormalTok{y\_col)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy014-1.pdf}

You can also automatically add in a line with the geom\_smooth() function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y\_val)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{facet\_grid}\NormalTok{(.}\SpecialCharTok{\textasciitilde{}}\NormalTok{y\_col)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/remedy015-1.pdf}

Now we can create a linear model for the data with minimum noise with the following command:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_min }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_min }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\end{Highlighting}
\end{Shaded}

\ldots and we can look at the summary of the model with:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(fit\_demo\_min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_min ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.6315 -1.4674  0.0561  1.4041  5.0728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   3.5564     0.4064   8.751 6.19e-14 ***
## x             1.9931     0.0250  79.726  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.053 on 98 degrees of freedom
## Multiple R-squared:  0.9848, Adjusted R-squared:  0.9847 
## F-statistic:  6356 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

We can also look at model results with the glance() function from the broom package

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{broom}\SpecialCharTok{::}\FunctionTok{glance}\NormalTok{(fit\_demo\_min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1     0.985         0.985  2.05     6356. 6.25e-91     1  -213.  432.  439.
## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

We can create models for the med and max sd values as well and take a look at those with the summary() function once again

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_med }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_med }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_med)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_med ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.7657  -3.8200   0.1044   3.8614  12.4352 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  1.26899    1.03129    1.23    0.221    
## x            2.11389    0.06344   33.32   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.209 on 98 degrees of freedom
## Multiple R-squared:  0.9189, Adjusted R-squared:  0.9181 
## F-statistic:  1110 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_max }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_max }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_max)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_max ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -26.1504  -7.7075  -0.2646   7.7050  26.6308 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   4.1472     2.1243   1.952   0.0538 .  
## x             1.8455     0.1307  14.123   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 10.73 on 98 degrees of freedom
## Multiple R-squared:  0.6706, Adjusted R-squared:  0.6672 
## F-statistic: 199.5 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

Notice the increase in the standard error of the coefficient estimates as the noise in y values went up

From a programming perspective, this was not very efficient because I just copied, pasted, and corrected these values.
There is a better way to do this using lists (see below)

Let's do some fancy stuff to make multiple models at once rather than having to write new lines for each model
*Some of these ideas are taken from the R4DS book chapter 25

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{nest}\NormalTok{(}\AttributeTok{data =} \SpecialCharTok{{-}}\NormalTok{sd\_val)}


\NormalTok{linear\_model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df) \{}
  \FunctionTok{lm}\NormalTok{(y\_val }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{\}}


\NormalTok{models }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(test\_nest}\SpecialCharTok{$}\NormalTok{data, linear\_model)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{2}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.6315 -1.4674  0.0561  1.4041  5.0728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   3.5564     0.4064   8.751 6.19e-14 ***
## x             1.9931     0.0250  79.726  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.053 on 98 degrees of freedom
## Multiple R-squared:  0.9848, Adjusted R-squared:  0.9847 
## F-statistic:  6356 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{3}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.7657  -3.8200   0.1044   3.8614  12.4352 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  1.26899    1.03129    1.23    0.221    
## x            2.11389    0.06344   33.32   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.209 on 98 degrees of freedom
## Multiple R-squared:  0.9189, Adjusted R-squared:  0.9181 
## F-statistic:  1110 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{4}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -26.1504  -7.7075  -0.2646   7.7050  26.6308 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   4.1472     2.1243   1.952   0.0538 .  
## x             1.8455     0.1307  14.123   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 10.73 on 98 degrees of freedom
## Multiple R-squared:  0.6706, Adjusted R-squared:  0.6672 
## F-statistic: 199.5 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

We can also store the models as new columns in the nested dataframe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ test\_nest }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \FunctionTok{map}\NormalTok{(data, linear\_model))}
\end{Highlighting}
\end{Shaded}

Finally, we can unnest the models to make it easier to compare them with each other in a data frame

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ test\_nest }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{glance =} \FunctionTok{map}\NormalTok{(model, broom}\SpecialCharTok{::}\NormalTok{glance)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{unnest}\NormalTok{(glance)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in summary.lm(x): essentially perfect fit: summary may be unreliable

## Warning in summary.lm(x): essentially perfect fit: summary may be unreliable
\end{verbatim}

\hypertarget{data-generation-demo---one-set-sample-size-1}{%
\section{Data generation demo - one set sample size;}\label{data-generation-demo---one-set-sample-size-1}}

The change from the past demo is that we are now sampling from integer values rather than continuous for the predictor

Store the sample size that we want to use

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{200}
\end{Highlighting}
\end{Shaded}

Instead of sampling uniformly from 0 to 20, this is to sample integers from 40 to 100 uniformly.
We take ``samp\_size'' number of samples. Replace = TRUE means we can get the same x value multiple times

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{60}\SpecialCharTok{:}\DecValTok{100}\NormalTok{), }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

As before, store the noise values for our different test models

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd\_min }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{sd\_med }\OtherTok{\textless{}{-}} \DecValTok{6}
\NormalTok{sd\_max }\OtherTok{\textless{}{-}} \DecValTok{12}

\NormalTok{y\_noise\_sd\_none }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x}
\NormalTok{y\_noise\_sd\_min }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_min), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\NormalTok{y\_noise\_sd\_med }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_med), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\NormalTok{y\_noise\_sd\_max }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_max), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Typical step 1: visualize! Let's plot each of these x values vs y

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_none)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy030-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_min)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy030-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_med)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy030-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_max)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy030-4.pdf}

Let's put all of these vectors together into a data frame to make it easier to analyze later on.
Note, this is not a vital step for conducting the simple regression

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\StringTok{"x"} \OtherTok{=}\NormalTok{ x, }
                  \StringTok{"y\_noise\_sd\_none"}\OtherTok{=}\NormalTok{y\_noise\_sd\_none, }
                  \StringTok{"y\_noise\_sd\_min"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_min,}
                  \StringTok{"y\_noise\_sd\_med"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_med,}
                  \StringTok{"y\_noise\_sd\_max"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_max)}
\end{Highlighting}
\end{Shaded}

Order by increasing x value

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

Let's make this a long df so that we can plot multiple standard deviation values together

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\StringTok{"y\_noise"}\NormalTok{),}
               \AttributeTok{names\_to =} \StringTok{"y\_col"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"y\_val"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sd\_val =} \FunctionTok{case\_when}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_none"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_min"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_min,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_med"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_med,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_max"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_max))}
\end{Highlighting}
\end{Shaded}

And visualize the data, faceting by different noise

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y\_val)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(.}\SpecialCharTok{\textasciitilde{}}\NormalTok{y\_col)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/remedy035-1.pdf}

And add in a line with \texttt{geom\_smooth(method\ =\ \textquotesingle{}lm\textquotesingle{})}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y\_val)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{facet\_grid}\NormalTok{(.}\SpecialCharTok{\textasciitilde{}}\NormalTok{y\_col)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/remedy036-1.pdf}

Create a linear model and look at the summary.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_min }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_min }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_min ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3835 -1.5211  0.0379  1.3254  6.7636 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  2.21905    0.99404   2.232   0.0267 *  
## x            2.01019    0.01229 163.530   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.104 on 198 degrees of freedom
## Multiple R-squared:  0.9927, Adjusted R-squared:  0.9926 
## F-statistic: 2.674e+04 on 1 and 198 DF,  p-value: < 2.2e-16
\end{verbatim}

We can also look at model results with the glance() function from the broom package

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{broom}\SpecialCharTok{::}\FunctionTok{glance}\NormalTok{(fit\_demo\_min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>     <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1     0.993         0.993  2.10    26742. 3.27e-213     1  -432.  869.  879.
## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

We can create models for the med and max sd values as well and take a look at those with the summary() function once again.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_med }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_med }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_med)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_med ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.4632  -4.6878  -0.4005   4.6437  17.4622 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -1.24876    2.87289  -0.435    0.664    
## x            2.04508    0.03553  57.564   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.08 on 198 degrees of freedom
## Multiple R-squared:  0.9436, Adjusted R-squared:  0.9433 
## F-statistic:  3314 on 1 and 198 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_max }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_max }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_max)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_max ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -39.867  -6.497   0.018   7.027  39.951 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 10.16895    5.87444   1.731    0.085 .  
## x            1.90820    0.07264  26.268   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 12.43 on 198 degrees of freedom
## Multiple R-squared:  0.777,  Adjusted R-squared:  0.7759 
## F-statistic:   690 on 1 and 198 DF,  p-value: < 2.2e-16
\end{verbatim}

Notice the increase in the standard error of the coefficient estimates as the noise in y values went up

From a programming perspective, this was not very efficient because I just copied, pasted, and corrected these values.
There is a better way to do this using lists (see below)

Let's do some fancy stuff to make multiple models at once rather than having to write new lines for each model
*Some of these ideas are taken from the R4DS book chapter 25

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{nest}\NormalTok{(}\AttributeTok{data =} \SpecialCharTok{{-}}\NormalTok{sd\_val)}


\NormalTok{linear\_model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df) \{}
  \FunctionTok{lm}\NormalTok{(y\_val }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{\}}


\NormalTok{models }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(test\_nest}\SpecialCharTok{$}\NormalTok{data, linear\_model)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{2}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3835 -1.5211  0.0379  1.3254  6.7636 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  2.21905    0.99404   2.232   0.0267 *  
## x            2.01019    0.01229 163.530   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.104 on 198 degrees of freedom
## Multiple R-squared:  0.9927, Adjusted R-squared:  0.9926 
## F-statistic: 2.674e+04 on 1 and 198 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{3}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.4632  -4.6878  -0.4005   4.6437  17.4622 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -1.24876    2.87289  -0.435    0.664    
## x            2.04508    0.03553  57.564   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.08 on 198 degrees of freedom
## Multiple R-squared:  0.9436, Adjusted R-squared:  0.9433 
## F-statistic:  3314 on 1 and 198 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{4}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -39.867  -6.497   0.018   7.027  39.951 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 10.16895    5.87444   1.731    0.085 .  
## x            1.90820    0.07264  26.268   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 12.43 on 198 degrees of freedom
## Multiple R-squared:  0.777,  Adjusted R-squared:  0.7759 
## F-statistic:   690 on 1 and 198 DF,  p-value: < 2.2e-16
\end{verbatim}

We can also store the models as new columns in the nested dataframe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ test\_nest }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \FunctionTok{map}\NormalTok{(data, linear\_model))}
\end{Highlighting}
\end{Shaded}

Finally, we can unnest the models to make it easier to compare them with each other in a data frame

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ test\_nest }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{glance =} \FunctionTok{map}\NormalTok{(model, broom}\SpecialCharTok{::}\NormalTok{glance)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{unnest}\NormalTok{(glance)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-generation-with-three-different-sample-sizes}{%
\section{Data generation with three different sample sizes}\label{data-generation-with-three-different-sample-sizes}}

Let's run the same demo but now have three different sample sizes - 10, 50, and 500

First, store the sample sizes we want to use

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_sizes }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next, create a bookkeping column for ourselves to keep track of which sample size the future values will come from

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size\_col }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{50}\NormalTok{, }\DecValTok{500}\NormalTok{), }\AttributeTok{times =}\NormalTok{ samp\_sizes)}
\end{Highlighting}
\end{Shaded}

Calculate the total number of values we will need from the three samples combined

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tot\_samp\_size }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(samp\_sizes)}
\end{Highlighting}
\end{Shaded}

Sample uniformly from 0 to 20

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{runif}\NormalTok{(}\AttributeTok{n =}\NormalTok{ tot\_samp\_size, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{20}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Store the standard deviations for the min, med, and max models

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd\_min }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{sd\_med }\OtherTok{\textless{}{-}} \DecValTok{6}
\NormalTok{sd\_max }\OtherTok{\textless{}{-}} \DecValTok{12}
\end{Highlighting}
\end{Shaded}

Calculate the y values for the different scenarios where there is no noise up to max noise

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_noise\_sd\_none }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x}
\NormalTok{y\_noise\_sd\_min }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ tot\_samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_min), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\NormalTok{y\_noise\_sd\_med }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ tot\_samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_med), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\NormalTok{y\_noise\_sd\_max }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ tot\_samp\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd\_max), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Typical step 1: visualize! Let's plot each of these x values vs y

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_none)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-80-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_min)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-80-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_med)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-80-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y\_noise\_sd\_max)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-80-4.pdf}
Can we calculate the correlations between x and these different y values? (pro tip: yes)

Let's put all of these vectors together into a data frame to make it easier to analyze later on
Note, this is not a vital step for conducting the simple regression

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\StringTok{"n"} \OtherTok{=}\NormalTok{ samp\_size\_col,}
                  \StringTok{"x"} \OtherTok{=}\NormalTok{ x, }
                  \StringTok{"y\_noise\_sd\_none"}\OtherTok{=}\NormalTok{y\_noise\_sd\_none, }
                  \StringTok{"y\_noise\_sd\_min"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_min,}
                  \StringTok{"y\_noise\_sd\_med"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_med,}
                  \StringTok{"y\_noise\_sd\_max"} \OtherTok{=}\NormalTok{ y\_noise\_sd\_max)}
\end{Highlighting}
\end{Shaded}

Order by increasing x value

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(n, x)}
\end{Highlighting}
\end{Shaded}

Let's make this a long df so that we can plot multiple standard deviation values together

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\StringTok{"y\_noise"}\NormalTok{),}
               \AttributeTok{names\_to =} \StringTok{"y\_col"}\NormalTok{,}
               \AttributeTok{values\_to =} \StringTok{"y\_val"}
\NormalTok{  )}

\NormalTok{demo\_df\_long }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sd\_val =} \FunctionTok{case\_when}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_none"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_min"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_min,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_med"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_med,}
                            \FunctionTok{str\_detect}\NormalTok{(y\_col, }\StringTok{"sd\_max"}\NormalTok{) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sd\_max))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y\_val)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(n}\SpecialCharTok{\textasciitilde{}}\NormalTok{y\_col)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-84-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y\_val)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{facet\_grid}\NormalTok{(n}\SpecialCharTok{\textasciitilde{}}\NormalTok{y\_col)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-85-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_min }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_min }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_min ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3503 -1.2768 -0.0035  1.2450  6.9759 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  3.14043    0.15889   19.77   <2e-16 ***
## x            1.98512    0.01397  142.12   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.91 on 558 degrees of freedom
## Multiple R-squared:  0.9731, Adjusted R-squared:  0.9731 
## F-statistic: 2.02e+04 on 1 and 558 DF,  p-value: < 2.2e-16
\end{verbatim}

We can also look at model results with the glance() function from the broom package

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{broom}\SpecialCharTok{::}\FunctionTok{glance}\NormalTok{(fit\_demo\_min)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1     0.973         0.973  1.91    20198.       0     1 -1156. 2318. 2331.
## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

We can create models for the med and max sd values as well and take a look at those with the summary() function once again

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_med }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_med }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_med)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_med ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.1057  -4.0478   0.1628   3.9796  19.6085 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  3.91276    0.48368    8.09 3.75e-15 ***
## x            1.92913    0.04252   45.37  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.814 on 558 degrees of freedom
## Multiple R-squared:  0.7867, Adjusted R-squared:  0.7863 
## F-statistic:  2058 on 1 and 558 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_demo\_max }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_noise\_sd\_max }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{summary}\NormalTok{(fit\_demo\_max)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_noise_sd_max ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -32.189  -7.761   0.154   7.975  40.250 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  2.83362    0.96027   2.951   0.0033 ** 
## x            1.97258    0.08442  23.366   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 11.54 on 558 degrees of freedom
## Multiple R-squared:  0.4946, Adjusted R-squared:  0.4937 
## F-statistic:   546 on 1 and 558 DF,  p-value: < 2.2e-16
\end{verbatim}

Notice the increase in the standard error of the coefficient estimates as the noise in y values went up

From a programming perspective, this was not very efficient because I just copied, pasted, and corrected these values.
There is a better way to do this using lists (see below)

Let's do some fancy stuff to make multiple models at once rather than having to write new lines for each model
*Some of these ideas are taken from the R4DS book chapter 25

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ demo\_df\_long }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{nest}\NormalTok{(}\AttributeTok{data =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(sd\_val, n))}


\NormalTok{linear\_model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df) \{}
  \FunctionTok{lm}\NormalTok{(y\_val }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{\}}


\NormalTok{models }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(test\_nest}\SpecialCharTok{$}\NormalTok{data, linear\_model)}

\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{2}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6922 -1.3073 -0.6152  1.0899  4.3290 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   5.7397     2.4885   2.307     0.05 *  
## x             1.8425     0.1831  10.063  8.1e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.276 on 8 degrees of freedom
## Multiple R-squared:  0.9268, Adjusted R-squared:  0.9176 
## F-statistic: 101.3 on 1 and 8 DF,  p-value: 8.102e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{3}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.0241 -3.7944 -0.5031  2.5688  6.4852 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)   
## (Intercept)   7.7300     4.9571   1.559  0.15753   
## x             1.7955     0.3647   4.923  0.00116 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.534 on 8 degrees of freedom
## Multiple R-squared:  0.7518, Adjusted R-squared:  0.7208 
## F-statistic: 24.23 on 1 and 8 DF,  p-value: 0.00116
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(models[[}\DecValTok{4}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y_val ~ x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -17.317  -6.780  -1.251   9.328  15.416 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)  
## (Intercept)    2.155     12.626   0.171   0.8687  
## x              2.047      0.929   2.204   0.0587 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 11.55 on 8 degrees of freedom
## Multiple R-squared:  0.3777, Adjusted R-squared:    0.3 
## F-statistic: 4.856 on 1 and 8 DF,  p-value: 0.05865
\end{verbatim}

We can also store the models as new columns in the nested dataframe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ test\_nest }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \FunctionTok{map}\NormalTok{(data, linear\_model))}
\end{Highlighting}
\end{Shaded}

Finally, we can unnest the models to make it easier to compare them with each other in a data frame

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest }\OtherTok{\textless{}{-}}\NormalTok{ test\_nest }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{glance =} \FunctionTok{map}\NormalTok{(model, broom}\SpecialCharTok{::}\NormalTok{glance)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{unnest}\NormalTok{(glance)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in summary.lm(x): essentially perfect fit: summary may be unreliable

## Warning in summary.lm(x): essentially perfect fit: summary may be unreliable

## Warning in summary.lm(x): essentially perfect fit: summary may be unreliable

## Warning in summary.lm(x): essentially perfect fit: summary may be unreliable
\end{verbatim}

And look at the different models by just calling the data frame

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nest}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 12 x 16
##        n sd_val data  model r.squared adj.r.squared    sigma statistic   p.value
##    <dbl>  <dbl> <lis> <lis>     <dbl>         <dbl>    <dbl>     <dbl>     <dbl>
##  1    10      0 <tib~ <lm>      1             1     2.80e-15   7.90e31 2.87e-125
##  2    10      2 <tib~ <lm>      0.927         0.918 2.28e+ 0   1.01e 2 8.10e-  6
##  3    10      6 <tib~ <lm>      0.752         0.721 4.53e+ 0   2.42e 1 1.16e-  3
##  4    10     12 <tib~ <lm>      0.378         0.300 1.15e+ 1   4.86e 0 5.87e-  2
##  5    50      0 <tib~ <lm>      1             1     4.48e-15   3.00e32 0.       
##  6    50      2 <tib~ <lm>      0.965         0.965 2.08e+ 0   1.34e 3 9.56e- 37
##  7    50      6 <tib~ <lm>      0.754         0.749 6.31e+ 0   1.47e 2 3.07e- 16
##  8    50     12 <tib~ <lm>      0.521         0.511 1.04e+ 1   5.22e 1 3.34e-  9
##  9   500      0 <tib~ <lm>      1             1     2.95e-14   7.79e31 0.       
## 10   500      2 <tib~ <lm>      0.974         0.974 1.89e+ 0   1.87e 4 0.       
## 11   500      6 <tib~ <lm>      0.790         0.790 5.78e+ 0   1.87e 3 7.39e-171
## 12   500     12 <tib~ <lm>      0.492         0.491 1.17e+ 1   4.83e 2 2.51e- 75
## # ... with 7 more variables: df <dbl>, logLik <dbl>, AIC <dbl>, BIC <dbl>,
## #   deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

\hypertarget{week-6-regression-ii}{%
\chapter{Week 6: Regression II}\label{week-6-regression-ii}}

This week we will be discussing multiple regression. We will use the child aggression data set as a running example for this.

\hypertarget{explore-the-child-aggression-data-set}{%
\section{Explore the child aggression data set}\label{explore-the-child-aggression-data-set}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"ChildAggression.dat"}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Method 1 for quickly getting summary statistics for the data you have, using the built-in summary() function

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(ca\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Aggression          Television       Computer_Games      
##  Min.   :-1.295608   Min.   :-1.46012   Min.   :-1.1538345  
##  1st Qu.:-0.174279   1st Qu.:-0.18206   1st Qu.:-0.1687007  
##  Median :-0.005548   Median :-0.01247   Median :-0.0001997  
##  Mean   :-0.005011   Mean   :-0.02758   Mean   : 0.0103812  
##  3rd Qu.: 0.149611   3rd Qu.: 0.14983   3rd Qu.: 0.1881810  
##  Max.   : 1.178823   Max.   : 0.98162   Max.   : 1.6175039  
##  Sibling_Aggression       Diet          Parenting_Style   
##  Min.   :-1.433127   Min.   :-1.28490   Min.   :-4.46041  
##  1st Qu.:-0.156414   1st Qu.:-0.16136   1st Qu.:-0.58008  
##  Median : 0.008459   Median : 0.00934   Median : 0.02736  
##  Mean   : 0.008275   Mean   : 0.01162   Mean   : 0.00000  
##  3rd Qu.: 0.185136   3rd Qu.: 0.18708   3rd Qu.: 0.51784  
##  Max.   : 1.103671   Max.   : 1.22383   Max.   : 3.99326
\end{verbatim}

Method 2, using the describe() function from the psych package

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{describe}\NormalTok{(ca\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    vars   n  mean   sd median trimmed  mad   min  max range
## Aggression            1 666 -0.01 0.32  -0.01   -0.01 0.24 -1.30 1.18  2.47
## Television            2 666 -0.03 0.31  -0.01   -0.02 0.25 -1.46 0.98  2.44
## Computer_Games        3 666  0.01 0.34   0.00    0.00 0.27 -1.15 1.62  2.77
## Sibling_Aggression    4 666  0.01 0.33   0.01    0.01 0.26 -1.43 1.10  2.54
## Diet                  5 666  0.01 0.34   0.01    0.01 0.26 -1.28 1.22  2.51
## Parenting_Style       6 666  0.00 1.00   0.03    0.01 0.82 -4.46 3.99  8.45
##                     skew kurtosis   se
## Aggression         -0.02     1.61 0.01
## Television         -0.36     1.34 0.01
## Computer_Games      0.25     1.60 0.01
## Sibling_Aggression -0.17     1.40 0.01
## Diet               -0.12     1.51 0.01
## Parenting_Style    -0.22     1.67 0.04
\end{verbatim}

Spot check: where do the ``se'' values come from?

Now that we have seen some of the numbers, let's try to visualize some of these data. Let's try to visualize the data while we're at it

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Aggression)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-98-1.pdf}

We could do this for each of our variables or we could try something a little fancier by using the pivot\_longer() function to make a longer dataframe and plot everything at once

First, create the long dataframe. After running this command, it's a good idea to view the new data frame to make sure this did what you intended

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df\_long }\OtherTok{\textless{}{-}}\NormalTok{ ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =}\NormalTok{ Aggression}\SpecialCharTok{:}\NormalTok{Parenting\_Style, }\AttributeTok{names\_to =} \StringTok{"variable\_name"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"variable\_value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

After making sure everything looks in order, run the same plot command with the addition of a facet.

Note that the fill = variable\_name tells R to color the plot with different colors by variable\_name and the theme(\ldots) tells R to get rid of the legend that automatically shows up

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ variable\_value, }\AttributeTok{fill =}\NormalTok{ variable\_name)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(variable\_name }\SpecialCharTok{\textasciitilde{}}\NormalTok{.) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-100-1.pdf}

From this we should be able to see that everything is normally distributed and appears to be standardized

Let's try a different kind of visualization: the empirical cumulative distribution function (eCDF) (sounds fancy, but it's not bad)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ variable\_value)) }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{geom =} \StringTok{"point"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(variable\_name }\SpecialCharTok{\textasciitilde{}}\NormalTok{.) }
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-101-1.pdf}

It looks like a bunch of distorted s shapes. In order to understand what is going on here, we should take a brief detour into the world of cumulative distribution functions (CDFs), eCDFs, and eventually QQ plots. This detour is at the end of the markdown file.

Now we can try a third way of visualizing our data - QQ plots!

As before, we can plot each variable with separate calls or plot them all together with the long data frame

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample=}\NormalTok{Aggression)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-102-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample=}\NormalTok{variable\_value)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(variable\_name }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-103-1.pdf}

\hypertarget{multiple-regression}{%
\section{Multiple regression}\label{multiple-regression}}

Let's create a model of child aggression as a function of parenting style and sibling aggression

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_fam }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Aggression }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Parenting\_Style }\SpecialCharTok{+}\NormalTok{ Sibling\_Aggression, }\AttributeTok{data =}\NormalTok{ ca\_df)}
\end{Highlighting}
\end{Shaded}

Run the summary on the model

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(model\_fam)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Aggression ~ Parenting_Style + Sibling_Aggression, 
##     data = ca_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.09755 -0.17180  0.00092  0.15405  1.23037 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(>|t|)    
## (Intercept)        -0.005784   0.012065  -0.479    0.632    
## Parenting_Style     0.061984   0.012257   5.057 5.51e-07 ***
## Sibling_Aggression  0.093409   0.037505   2.491    0.013 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3113 on 663 degrees of freedom
## Multiple R-squared:  0.05325,    Adjusted R-squared:  0.05039 
## F-statistic: 18.64 on 2 and 663 DF,  p-value: 1.325e-08
\end{verbatim}

This will be helpful later when we want to plot the residuals of the model.

Let's create another model of child aggression as a function of computer games and television.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_screens }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Aggression }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Computer\_Games }\SpecialCharTok{+}\NormalTok{ Television, }\AttributeTok{data =}\NormalTok{ ca\_df)}

\FunctionTok{summary}\NormalTok{(model\_screens)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Aggression ~ Computer_Games + Television, data = ca_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.05234 -0.15191 -0.00512  0.15156  1.24062 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(>|t|)    
## (Intercept)    -0.002879   0.012132  -0.237 0.812526    
## Computer_Games  0.153874   0.035845   4.293 2.03e-05 ***
## Television      0.135263   0.039546   3.420 0.000664 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3115 on 663 degrees of freedom
## Multiple R-squared:  0.05149,    Adjusted R-squared:  0.04862 
## F-statistic: 17.99 on 2 and 663 DF,  p-value: 2.455e-08
\end{verbatim}

Now let's see what the full model looks like with all five predictors

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_all }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Aggression }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Parenting\_Style }\SpecialCharTok{+}\NormalTok{ Sibling\_Aggression }\SpecialCharTok{+}\NormalTok{ Diet }\SpecialCharTok{+}\NormalTok{ Computer\_Games }\SpecialCharTok{+}\NormalTok{ Television, }
                \AttributeTok{data =}\NormalTok{ ca\_df)}
\FunctionTok{summary}\NormalTok{(model\_all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Aggression ~ Parenting_Style + Sibling_Aggression + 
##     Diet + Computer_Games + Television, data = ca_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.12629 -0.15253 -0.00421  0.15222  1.17669 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(>|t|)    
## (Intercept)        -0.004988   0.011983  -0.416 0.677350    
## Parenting_Style     0.056648   0.014557   3.891 0.000110 ***
## Sibling_Aggression  0.081684   0.038780   2.106 0.035550 *  
## Diet               -0.109054   0.038076  -2.864 0.004315 ** 
## Computer_Games      0.142161   0.036920   3.851 0.000129 ***
## Television          0.032916   0.046057   0.715 0.475059    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3071 on 660 degrees of freedom
## Multiple R-squared:  0.08258,    Adjusted R-squared:  0.07563 
## F-statistic: 11.88 on 5 and 660 DF,  p-value: 5.025e-11
\end{verbatim}

We can get the output from the summary() function but as a tibble instead:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(model\_all, }\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 7
##   term               estimate std.error statistic  p.value conf.low conf.high
##   <chr>                 <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>
## 1 (Intercept)        -0.00499    0.0120    -0.416 0.677    -0.0285     0.0185
## 2 Parenting_Style     0.0566     0.0146     3.89  0.000110  0.0281     0.0852
## 3 Sibling_Aggression  0.0817     0.0388     2.11  0.0355    0.00554    0.158 
## 4 Diet               -0.109      0.0381    -2.86  0.00432  -0.184     -0.0343
## 5 Computer_Games      0.142      0.0369     3.85  0.000129  0.0697     0.215 
## 6 Television          0.0329     0.0461     0.715 0.475    -0.0575     0.123
\end{verbatim}

We can also get summary statistics like the R\^{}2, F-statistics, and AIC from the glance() function in the Broom package

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{broom}\SpecialCharTok{::}\FunctionTok{glance}\NormalTok{(model\_all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1    0.0826        0.0756 0.307      11.9 5.02e-11     5  -156.  325.  357.
## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

Let's stop here to interpret what the model output is telling us(specifically, the coefficient estimates, the standard errors, the p values, and the R\^{}2 values).

Notice the Television p value and standard errors (especially how the estimate is so close to zero, and its 95\% confidence interval crosses 0)

We can also have R handle factors automatically in a regression model for us.

First, we will generate a new factor for the child aggression data - the handedness of the child (left vs right).

This code generates a random handedness for each of the 666 students and assigns it to a new column in ca\_df

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{handed\_levels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"left"}\NormalTok{, }\StringTok{"right"}\NormalTok{)}
\NormalTok{handed\_vector }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(handed\_levels, }\AttributeTok{size =} \FunctionTok{nrow}\NormalTok{(ca\_df), }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{))}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{Handedness }\OtherTok{\textless{}{-}}\NormalTok{ handed\_vector}
\end{Highlighting}
\end{Shaded}

Check to make sure we have all the predictor names correct to add into the linear model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(ca\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Aggression"         "Television"         "Computer_Games"    
## [4] "Sibling_Aggression" "Diet"               "Parenting_Style"   
## [7] "Handedness"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_all\_3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Aggression }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Parenting\_Style }\SpecialCharTok{+}\NormalTok{ Sibling\_Aggression }\SpecialCharTok{+}\NormalTok{ Television }\SpecialCharTok{+}\NormalTok{ Computer\_Games }\SpecialCharTok{+}\NormalTok{ Diet }\SpecialCharTok{+}\NormalTok{ Handedness, }\AttributeTok{data =}\NormalTok{ ca\_df)}
\end{Highlighting}
\end{Shaded}

Check the model summary and notice how the Handedness predictor variable was handled.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(model\_all\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Aggression ~ Parenting_Style + Sibling_Aggression + 
##     Television + Computer_Games + Diet + Handedness, data = ca_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.12485 -0.15230 -0.00332  0.15254  1.17596 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(>|t|)    
## (Intercept)        -0.006228   0.019320  -0.322 0.747302    
## Parenting_Style     0.056528   0.014642   3.861 0.000124 ***
## Sibling_Aggression  0.081905   0.038903   2.105 0.035636 *  
## Television          0.033078   0.046134   0.717 0.473636    
## Computer_Games      0.142117   0.036951   3.846 0.000132 ***
## Diet               -0.109070   0.038106  -2.862 0.004339 ** 
## Handednessright     0.002019   0.024671   0.082 0.934809    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3073 on 659 degrees of freedom
## Multiple R-squared:  0.08259,    Adjusted R-squared:  0.07424 
## F-statistic: 9.888 on 6 and 659 DF,  p-value: 1.847e-10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(Aggression }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data=}\NormalTok{ca\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Aggression ~ ., data = ca_df)
## 
## Coefficients:
##        (Intercept)          Television      Computer_Games  Sibling_Aggression  
##          -0.006228            0.033078            0.142117            0.081905  
##               Diet     Parenting_Style     Handednessright  
##          -0.109070            0.056528            0.002019
\end{verbatim}

\hypertarget{assumption-testing}{%
\subsection{Assumption testing}\label{assumption-testing}}

Note: A lot of the things we are doing here can be accomplished with the augment() function in the broom package

Check for correlation between adjacent residual terms using Durbin-Watson test

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dwt}\NormalTok{(model\_all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  lag Autocorrelation D-W Statistic p-value
##    1      0.04218005      1.912808   0.282
##  Alternative hypothesis: rho != 0
\end{verbatim}

Check for multicollinearity.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{car}\SpecialCharTok{::}\FunctionTok{vif}\NormalTok{(model\_all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Parenting_Style Sibling_Aggression               Diet     Computer_Games 
##           1.494296           1.132618           1.160466           1.122719 
##         Television 
##           1.435525
\end{verbatim}

Now let's go back and check for influential cases following the procedure Field does in the textbook.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{residuals }\OtherTok{\textless{}{-}} \FunctionTok{resid}\NormalTok{(model\_all) }\CommentTok{\# notice how this is the same as looking at View(model\_all) and then residuals or model\_all$residuals}
\CommentTok{\#model\_all$residuals}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{standardized.residuals }\OtherTok{\textless{}{-}} \FunctionTok{rstandard}\NormalTok{(model\_all)}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{studentized.residuals }\OtherTok{\textless{}{-}} \FunctionTok{rstudent}\NormalTok{(model\_all)}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{cooks.distance }\OtherTok{\textless{}{-}} \FunctionTok{cooks.distance}\NormalTok{(model\_all)}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{dfbeta }\OtherTok{\textless{}{-}} \FunctionTok{dfbeta}\NormalTok{(model\_all)}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{dffit }\OtherTok{\textless{}{-}} \FunctionTok{dffits}\NormalTok{(model\_all)}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{leverage }\OtherTok{\textless{}{-}} \FunctionTok{hatvalues}\NormalTok{(model\_all)}
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{covariance.ratios }\OtherTok{\textless{}{-}} \FunctionTok{covratio}\NormalTok{(model\_all)}
\end{Highlighting}
\end{Shaded}

Now that we have all of the extra model fit statistics calculated, we can add a new olumn using a different method than what he does in the textbook (but this accomplishes the same task).

We are using a combination of mutate() and case\_when() instead of the traditional logical test subsetting that we see in the bookon pp.~289-290

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\OtherTok{\textless{}{-}}\NormalTok{ ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{large.residual =} \FunctionTok{case\_when}\NormalTok{(standardized.residuals }\SpecialCharTok{\textgreater{}} \DecValTok{2} \SpecialCharTok{|}\NormalTok{ standardized.residuals }\SpecialCharTok{\textless{}} \SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{\textasciitilde{}} \ConstantTok{TRUE}\NormalTok{,}
                                    \FunctionTok{abs}\NormalTok{(standardized.residuals) }\SpecialCharTok{\textless{}=} \DecValTok{2} \SpecialCharTok{\textasciitilde{}} \ConstantTok{FALSE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now let's just look at the observations where there was a large residual (absolute value \textgreater{} 2)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(large.residual }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Aggression  Television Computer_Games Sibling_Aggression       Diet
## 1  0.7711534 -0.03287184     0.70991822        0.576836667 -0.0229903
## 2 -0.9309839 -0.14695730     0.58503832        0.143914123  0.1341567
## 3  0.8437696 -0.53337187     0.62674291        0.006193792 -0.0542531
## 4 -0.8604237 -0.32734996    -0.10228524        0.088454410  0.3403472
## 5  0.7374707  0.05104538     0.06804261        0.742478946  0.3607529
## 6  0.6158280 -0.17945254    -0.14381635        0.337002793 -0.5992525
##   Parenting_Style Handedness  residuals standardized.residuals
## 1      -1.2481665       left  0.6973813               2.289855
## 2      -1.0470961       left -0.9421375              -3.081966
## 3       0.2386578      right  0.7572738               2.484122
## 4      -0.6988965       left -0.7606374              -2.483667
## 5       0.9243197       left  0.6574374               2.152417
## 6      -1.0334894      right  0.6128345               2.006389
##   studentized.residuals cooks.distance dfbeta.(Intercept)
## 1              2.297263    0.014610960       0.0010048327
## 2             -3.102033    0.014474124      -0.0013336489
## 3              2.493925    0.015185553       0.0008375093
## 4             -2.493465    0.005595170      -0.0010247662
## 5              2.158374    0.008347004       0.0008799517
## 6              2.011011    0.007252602       0.0009296294
##   dfbeta.Parenting_Style dfbeta.Sibling_Aggression   dfbeta.Diet
## 1          -0.0022102310              0.0053377408 -0.0015602060
## 2           0.0022877988             -0.0008058492 -0.0011872151
## 3           0.0016068696              0.0002508274 -0.0028943101
## 4           0.0006636867             -0.0011984511 -0.0042173119
## 5           0.0008756410              0.0069052922  0.0014075292
## 6          -0.0005401040              0.0047888699 -0.0054530647
##   dfbeta.Computer_Games dfbeta.Television      dffit    leverage
## 1          0.0067966200      0.0013345865  0.2970419 0.016444209
## 2         -0.0079629954     -0.0003344591 -0.2966131 0.009060145
## 3          0.0072143563     -0.0098994502  0.3030411 0.014550253
## 4          0.0015183740      0.0029152017 -0.1839467 0.005412783
## 5         -0.0015476206     -0.0021915865  0.2244095 0.010694476
## 6         -0.0004611714     -0.0010521222  0.2090845 0.010694131
##   covariance.ratios large.residual
## 1         0.9780649           TRUE
## 2         0.9335336           TRUE
## 3         0.9679182           TRUE
## 4         0.9590456           TRUE
## 5         0.9778335           TRUE
## 6         0.9832825           TRUE
\end{verbatim}

There's a problem here because we don't preserve observation numbers. In general, it might be a good idea to give each observation an ID with something like

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(ca\_df)[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 666
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\OtherTok{\textless{}{-}}\NormalTok{ ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ID =} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{dim}\NormalTok{(ca\_df)[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

In the tidyverse, there is an even simpler way to do this with the rowid\_to\_column() function!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\OtherTok{\textless{}{-}}\NormalTok{ ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{rowid\_to\_column}\NormalTok{(}\AttributeTok{var =} \StringTok{"participant\_id"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we can run the filter again and see which observations have large residuals

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(large.residual }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{view}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Plot the residuals against the fitted values

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df}\SpecialCharTok{$}\NormalTok{fitted }\OtherTok{\textless{}{-}}\NormalTok{ model\_all}\SpecialCharTok{$}\NormalTok{fitted.values}
\end{Highlighting}
\end{Shaded}

First, plot the distribution of the residuals by themselves

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{histogram }\OtherTok{\textless{}{-}}\NormalTok{ ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ studentized.residuals)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ ..density..)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Studentized Residuals"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Density"}\NormalTok{)}
\NormalTok{histogram}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-123-1.pdf}

Now let's add a normal density on top of that for comparison

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{histogram }\SpecialCharTok{+} \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dnorm, }
                          \AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(ca\_df}\SpecialCharTok{$}\NormalTok{studentized.residuals, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{), }
                                      \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(ca\_df}\SpecialCharTok{$}\NormalTok{studentized.residuals, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)), }
                          \AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-124-1.pdf}

Second, plot the residuals against the fitted values to make sure there are no systematic patterns

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fitted, }\AttributeTok{y =}\NormalTok{ studentized.residuals)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Fitted Residual"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Studentized Residual"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-125-1.pdf}

We can also skip all the fancy code from the book and use the plot() function on the model.

R knows that this means we want to plot four fit plots

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)) }\CommentTok{\# this changes the arrangement for the plots to show two rows and two columns of plots}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(model\_all)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-127-1.pdf} \includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-127-2.pdf} \includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-127-3.pdf} \includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-127-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)) }\CommentTok{\# this changes the plotting arrangement back to the default of one plot at a time}
\end{Highlighting}
\end{Shaded}

Note that we could also create a model that uses all our covariates as predictors with the following call

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_all\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Aggression }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data=}\NormalTok{ca\_df)}
\end{Highlighting}
\end{Shaded}

Inspect the results to make sure it is giving the same results as before

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(model\_all\_2)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-129-1.pdf} \includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-129-2.pdf} \includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-129-3.pdf} \includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-129-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(model\_all\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Aggression ~ ., data = ca_df)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -3.216e-15 -4.010e-17 -2.600e-18  4.070e-17  8.607e-15 
## 
## Coefficients: (2 not defined because of singularities)
##                            Estimate Std. Error    t value Pr(>|t|)    
## (Intercept)              -4.988e-03  2.150e-15 -2.320e+12  < 2e-16 ***
## participant_id            3.761e-19  8.163e-20  4.607e+00 4.93e-06 ***
## Television                3.292e-02  6.086e-17  5.409e+14  < 2e-16 ***
## Computer_Games            1.422e-01  4.883e-17  2.911e+15  < 2e-16 ***
## Sibling_Aggression        8.168e-02  5.123e-17  1.594e+15  < 2e-16 ***
## Diet                     -1.091e-01  5.053e-17 -2.158e+15  < 2e-16 ***
## Parenting_Style           5.665e-02  1.934e-17  2.929e+15  < 2e-16 ***
## Handednessright           2.481e-17  3.228e-17  7.690e-01    0.442    
## residuals                 1.000e+00  4.111e-12  2.432e+11  < 2e-16 ***
## standardized.residuals    8.540e-13  2.457e-12  3.480e-01    0.728    
## studentized.residuals    -1.487e-16  5.938e-15 -2.500e-02    0.980    
## cooks.distance            5.031e-15  5.584e-15  9.010e-01    0.368    
## dfbeta(Intercept)        -8.887e-10  2.593e-09 -3.430e-01    0.732    
## dfbetaParenting_Style     3.083e-14  2.986e-14  1.033e+00    0.302    
## dfbetaSibling_Aggression -7.369e-12  2.146e-11 -3.430e-01    0.731    
## dfbetaDiet               -1.032e-11  3.013e-11 -3.430e-01    0.732    
## dfbetaComputer_Games     -9.233e-12  2.692e-11 -3.430e-01    0.732    
## dfbetaTelevision          2.452e-11  7.150e-11  3.430e-01    0.732    
## dffit                    -2.383e-15  5.561e-15 -4.280e-01    0.668    
## leverage                 -3.056e-15  3.512e-15 -8.700e-01    0.384    
## covariance.ratios         1.874e-16  2.140e-15  8.800e-02    0.930    
## large.residualTRUE       -1.521e-16  1.215e-16 -1.251e+00    0.211    
## ID                               NA         NA         NA       NA    
## fitted                           NA         NA         NA       NA    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.985e-16 on 644 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 2.034e+31 on 21 and 644 DF,  p-value: < 2.2e-16
\end{verbatim}

Check how augment() works and which parts of the above it replicates

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{augmented\_model\_all }\OtherTok{\textless{}{-}} \FunctionTok{augment}\NormalTok{(model\_all)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ca\_df\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ variable\_value, }\AttributeTok{fill =}\NormalTok{ variable\_name)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-131-1.pdf}

\hypertarget{detour-cumulative-distribution-function-cdf-empirical-cdf-and-qq-plot-discussion}{%
\subsection{Detour: Cumulative Distribution Function (CDF), empirical CDF, and QQ Plot Discussion}\label{detour-cumulative-distribution-function-cdf-empirical-cdf-and-qq-plot-discussion}}

Our goal here is to visualize the cumulative distribution function for a normal distribution as a stepping stone toward undestanding QQ plots. We will use plots of the empirical cumulative distribution function (eCDF)

As a way to visualize our data. Although we have not discussed eCDFs before, they are another tool you can use to visualize the distribution of quantitative data.

We will also look at the effect of sample size on the kinds of plots that we may make when visualizing the distribution of data.

First, let's generate some data to help us see what these concepts are all about.

\textbf{Note} that We are generating data to make things easier on ourselves - we know the underlying data-generating process. So that lets us form an expectation of what \emph{should} happen. These kinds of toy examples can be helpful for building an intuition about these concepts that we can then use in our own work.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_1 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{25}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{), }\AttributeTok{samp\_size =} \FunctionTok{rep}\NormalTok{(}\AttributeTok{x =} \DecValTok{25}\NormalTok{, }\AttributeTok{times =} \DecValTok{25}\NormalTok{))}
\NormalTok{df\_2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{50}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{), }\AttributeTok{samp\_size =} \FunctionTok{rep}\NormalTok{(}\AttributeTok{x =} \DecValTok{50}\NormalTok{, }\AttributeTok{times =} \DecValTok{50}\NormalTok{))}
\NormalTok{df\_3 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{100}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{), }\AttributeTok{samp\_size =} \FunctionTok{rep}\NormalTok{(}\AttributeTok{x =} \DecValTok{100}\NormalTok{, }\AttributeTok{times =} \DecValTok{100}\NormalTok{))}
\NormalTok{df\_4 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{200}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{), }\AttributeTok{samp\_size =} \FunctionTok{rep}\NormalTok{(}\AttributeTok{x =} \DecValTok{200}\NormalTok{, }\AttributeTok{times =} \DecValTok{200}\NormalTok{))}
\NormalTok{df\_5 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{500}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{), }\AttributeTok{samp\_size =} \FunctionTok{rep}\NormalTok{(}\AttributeTok{x =} \DecValTok{500}\NormalTok{, }\AttributeTok{times =} \DecValTok{500}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Combine the generated data together into one data frame to make it easy to plot everything in one ggplot call.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_df }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(df\_1, df\_2, df\_3, df\_4, df\_5)}
\end{Highlighting}
\end{Shaded}

Look at the empirical CDFs

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{geom =} \StringTok{"point"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(samp\_size}\SpecialCharTok{\textasciitilde{}}\NormalTok{.)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-134-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(samp\_size}\SpecialCharTok{\textasciitilde{}}\NormalTok{.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-135-1.pdf}

In class, this should lead to a discussion about how to find quantiles now let's try to look at some QQ plots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_1 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample=}\NormalTok{x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-136-1.pdf}

Let's try to wrap our heads around what is going on by looking at sorted versions of df\_1 values

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(df\_1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##       x samp_size
##   <dbl>     <dbl>
## 1  -2.1        25
## 2  -1.5        25
## 3  -1          25
## 4  -1          25
## 5  -1          25
## 6  -0.9        25
\end{verbatim}

Let's also look at the other end of the dataframe. We can do this either using arrange(desc(x)) or tail instead of head
Confirm that they're basically two ways of accomplishing the same objective.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(df\_1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(x)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##       x samp_size
##   <dbl>     <dbl>
## 1   2          25
## 2   1.6        25
## 3   1.4        25
## 4   1.3        25
## 5   1.1        25
## 6   0.5        25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(df\_1 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##       x samp_size
##   <dbl>     <dbl>
## 1   0.5        25
## 2   1.1        25
## 3   1.3        25
## 4   1.4        25
## 5   1.6        25
## 6   2          25
\end{verbatim}

End detour

\hypertarget{generating-data-for-student-happiness-exercise.}{%
\subsection{Generating data for student happiness exercise.}\label{generating-data-for-student-happiness-exercise.}}

We are going to student happiness scores on a scale from 0 to 100 as a function of their time spent outdoors, time spent on Zoom, class standing, and department.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pop\_size }\OtherTok{\textless{}{-}} \DecValTok{5000}
\NormalTok{sample\_size }\OtherTok{\textless{}{-}} \DecValTok{200}


\NormalTok{pop\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{standing =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"undergrad"}\NormalTok{, }\StringTok{"masters"}\NormalTok{, }\StringTok{"phd"}\NormalTok{), }
                 \AttributeTok{times =} \FunctionTok{c}\NormalTok{(pop\_size}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, pop\_size}\SpecialCharTok{/}\DecValTok{4}\NormalTok{, pop\_size}\SpecialCharTok{/}\DecValTok{4}\NormalTok{)))}

\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{discipline }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"mechanical"}\NormalTok{, }\StringTok{"civil"}\NormalTok{, }\StringTok{"electrical"}\NormalTok{), }
                         \AttributeTok{length.out =}\NormalTok{ pop\_size)}

\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{min\_outdoors }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\AttributeTok{n =}\NormalTok{ pop\_size, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{300}\NormalTok{), }\DecValTok{0}\NormalTok{)}

\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{min\_zoom }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\AttributeTok{n =}\NormalTok{ pop\_size, }\AttributeTok{min =} \DecValTok{0}\NormalTok{, }\AttributeTok{max =} \DecValTok{400}\NormalTok{), }\DecValTok{0}\NormalTok{)}

\NormalTok{pop\_df }\OtherTok{\textless{}{-}}\NormalTok{ pop\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{undergrad =} \FunctionTok{case\_when}\NormalTok{(standing }\SpecialCharTok{==} \StringTok{"undergrad"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
                           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{),}
         \AttributeTok{masters =} \FunctionTok{case\_when}\NormalTok{(standing }\SpecialCharTok{==} \StringTok{"masters"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
                           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{),}
         \AttributeTok{phd =} \FunctionTok{case\_when}\NormalTok{(standing }\SpecialCharTok{==} \StringTok{"phd"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
                           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{),}
         \AttributeTok{civil =} \FunctionTok{case\_when}\NormalTok{(discipline }\SpecialCharTok{==} \StringTok{"civil"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
                           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{),}
         \AttributeTok{mechanical =} \FunctionTok{case\_when}\NormalTok{(discipline }\SpecialCharTok{==} \StringTok{"mechanical"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
                           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{),}
         \AttributeTok{electrical =} \FunctionTok{case\_when}\NormalTok{(discipline }\SpecialCharTok{==} \StringTok{"electrical"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
                           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

With the predictors generated, we can now generate the happiness scores.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#pop\_df \textless{}{-} pop\_df \%\textgreater{}\% }
\CommentTok{\#  mutate(happiness = 50 + {-}.2*(min\_zoom+runif(n = 1, min = 10, max = 30)) + .1 * min\_outdoors + 4*civil {-}.3 * mechanical)}

\NormalTok{b\_0 }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{b\_out }\OtherTok{\textless{}{-}} \FloatTok{0.03}
\NormalTok{b\_zoom }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FloatTok{0.05}
\NormalTok{b\_civ }\OtherTok{\textless{}{-}} \DecValTok{6}
\NormalTok{b\_mech }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{b\_ele }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{3}
\NormalTok{b\_under }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{b\_masters }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{2}
\NormalTok{b\_phd }\OtherTok{\textless{}{-}} \DecValTok{10}

\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{happiness }\OtherTok{\textless{}{-}}\NormalTok{ b\_0 }\SpecialCharTok{+}\NormalTok{ b\_out}\SpecialCharTok{*}\NormalTok{(pop\_df}\SpecialCharTok{$}\NormalTok{min\_outdoors }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(pop\_size, }\DecValTok{0}\NormalTok{, }\DecValTok{40}\NormalTok{)) }\SpecialCharTok{+}
\NormalTok{  b\_zoom}\SpecialCharTok{*}\NormalTok{(pop\_df}\SpecialCharTok{$}\NormalTok{min\_zoom }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(pop\_size, }\DecValTok{0}\NormalTok{, }\DecValTok{40}\NormalTok{)) }\SpecialCharTok{+} 
\NormalTok{  b\_civ}\SpecialCharTok{*}\NormalTok{(pop\_df}\SpecialCharTok{$}\NormalTok{civil }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(pop\_size, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{)) }\SpecialCharTok{+} 
\NormalTok{  b\_mech}\SpecialCharTok{*}\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{mechanical }\SpecialCharTok{+}
\NormalTok{  b\_ele}\SpecialCharTok{*}\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{electrical }\SpecialCharTok{+}\NormalTok{ b\_under }\SpecialCharTok{*}\NormalTok{ pop\_df}\SpecialCharTok{$}\NormalTok{undergrad }\SpecialCharTok{+} 
\NormalTok{  b\_masters}\SpecialCharTok{*}\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{masters }\SpecialCharTok{+}
\NormalTok{  b\_phd}\SpecialCharTok{*}\NormalTok{pop\_df}\SpecialCharTok{$}\NormalTok{phd }\SpecialCharTok{+} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ pop\_size, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{10}\NormalTok{), }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We will save the full population dataset. That is what we will start with in class.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pop\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{write\_csv}\NormalTok{(}\StringTok{"student\_happiness.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we create a sample of students by sampling from the population dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df }\OtherTok{\textless{}{-}} \FunctionTok{sample\_n}\NormalTok{(pop\_df, }\AttributeTok{size =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

On the modeling side, we can first start with a very simple model with only one predictor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{happiness\_zoom }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(happiness }\SpecialCharTok{\textasciitilde{}}\NormalTok{ min\_zoom, }\AttributeTok{data =}\NormalTok{ samp\_df)}
\FunctionTok{summary}\NormalTok{(happiness\_zoom)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = happiness ~ min_zoom, data = samp_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -42.871  -9.296  -0.308  10.089  41.709 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 63.584166   2.248145   28.28  < 2e-16 ***
## min_zoom    -0.065520   0.009677   -6.77 1.42e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 15.08 on 198 degrees of freedom
## Multiple R-squared:  0.188,  Adjusted R-squared:  0.1839 
## F-statistic: 45.84 on 1 and 198 DF,  p-value: 1.425e-10
\end{verbatim}

Next, we can look at what happens with a more complex model with multiple predictors. Pay attention to how the \(R^2\) value changes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{happiness\_all }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(happiness }\SpecialCharTok{\textasciitilde{}}\NormalTok{ min\_outdoors }\SpecialCharTok{+}\NormalTok{ min\_zoom }\SpecialCharTok{+}\NormalTok{ civil }\SpecialCharTok{+}\NormalTok{ mechanical }\SpecialCharTok{+}\NormalTok{ electrical }\SpecialCharTok{+}\NormalTok{ undergrad }\SpecialCharTok{+}\NormalTok{ masters }\SpecialCharTok{+}\NormalTok{ phd, }\AttributeTok{data =}\NormalTok{ samp\_df)}
\FunctionTok{summary}\NormalTok{(happiness\_all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = happiness ~ min_outdoors + min_zoom + civil + mechanical + 
##     electrical + undergrad + masters + phd, data = samp_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -45.992 -10.389  -0.302   8.511  37.301 
## 
## Coefficients: (2 not defined because of singularities)
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  62.94592    3.76431  16.722  < 2e-16 ***
## min_outdoors  0.02556    0.01241   2.060  0.04076 *  
## min_zoom     -0.06954    0.00964  -7.214 1.21e-11 ***
## civil         4.66774    2.57563   1.812  0.07150 .  
## mechanical    0.96157    2.66793   0.360  0.71893    
## electrical         NA         NA      NA       NA    
## undergrad    -4.60262    2.61826  -1.758  0.08035 .  
## masters      -7.79982    2.96814  -2.628  0.00928 ** 
## phd                NA         NA      NA       NA    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 14.76 on 193 degrees of freedom
## Multiple R-squared:  0.2418, Adjusted R-squared:  0.2183 
## F-statistic: 10.26 on 6 and 193 DF,  p-value: 7.479e-10
\end{verbatim}

An alternative way of writing the full model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{happiness\_all }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(happiness }\SpecialCharTok{\textasciitilde{}}\NormalTok{ min\_outdoors }\SpecialCharTok{+}\NormalTok{ min\_zoom }\SpecialCharTok{+}\NormalTok{ discipline }\SpecialCharTok{+}\NormalTok{ standing, }\AttributeTok{data =}\NormalTok{ samp\_df)}
\FunctionTok{summary}\NormalTok{(happiness\_all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = happiness ~ min_outdoors + min_zoom + discipline + 
##     standing, data = samp_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -45.992 -10.389  -0.302   8.511  37.301 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(>|t|)    
## (Intercept)          59.81384    3.61923  16.527  < 2e-16 ***
## min_outdoors          0.02556    0.01241   2.060  0.04076 *  
## min_zoom             -0.06954    0.00964  -7.214 1.21e-11 ***
## disciplineelectrical -4.66774    2.57563  -1.812  0.07150 .  
## disciplinemechanical -3.70617    2.51991  -1.471  0.14299    
## standingphd           7.79982    2.96814   2.628  0.00928 ** 
## standingundergrad     3.19720    2.53864   1.259  0.20940    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 14.76 on 193 degrees of freedom
## Multiple R-squared:  0.2418, Adjusted R-squared:  0.2183 
## F-statistic: 10.26 on 6 and 193 DF,  p-value: 7.479e-10
\end{verbatim}

\hypertarget{week-7-logistic-regression}{%
\chapter{Week 7: Logistic Regression}\label{week-7-logistic-regression}}

To study how to run a logistic regression model in R, we are going to create simulate some data.

NOTE: Simulating data is a good way to get a sense of how the model works since you already know the data-generate process that you are trying to characterize with the model. This means you already know the ``ground truth''. In practice, we do not have this luxury when we run our studies - it is this ``ground truth'' that we're looking for.
Nonetheless, it can be helpful to remove one piece of uncertainty when learning the technical aspects by using data that are already characterized because you made them.

We will proceed through several rounds of data generation to see how the model may vary.

\hypertarget{round-1---no-systematic-variation-in-outcomes}{%
\section{Round 1 - No systematic variation in outcomes}\label{round-1---no-systematic-variation-in-outcomes}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{disciplines }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"civil"}\NormalTok{, }\StringTok{"mechanical"}\NormalTok{, }\StringTok{"electrical"}\NormalTok{, }\StringTok{"systems"}\NormalTok{)}
\NormalTok{disciplines\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.35}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}


\NormalTok{know\_engineer }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"immediate\_fam"}\NormalTok{, }\StringTok{"distant\_fam"}\NormalTok{, }\StringTok{"friend"}\NormalTok{, }\StringTok{"none"}\NormalTok{)}
\NormalTok{know\_engineer\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}


\NormalTok{persistence }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"yes"}\NormalTok{, }\StringTok{"no"}\NormalTok{)}
\NormalTok{persistence\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.8}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we will generate the actual sample of 500 students

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{500}

\NormalTok{disc\_samp }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ disciplines, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ disciplines\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{know\_samp }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ know\_engineer, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ know\_engineer\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{pers\_samp }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ persistence, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ persistence\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}


\NormalTok{samp\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{discipline =}\NormalTok{ disc\_samp,}
                  \AttributeTok{know\_eng =}\NormalTok{ know\_samp,}
                  \AttributeTok{persist =}\NormalTok{ pers\_samp,}
                  \AttributeTok{gpa =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{3}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.3}\NormalTok{), }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis

First, add in a new binary column for the persistence variable (coding ``yes'' as 1 and ``no'' as 0)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df }\OtherTok{\textless{}{-}}\NormalTok{ samp\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{persist\_bin =} \FunctionTok{case\_when}\NormalTok{(persist }\SpecialCharTok{==} \StringTok{"yes"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
\NormalTok{                                 persist }\SpecialCharTok{==} \StringTok{"no"} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Second, get a sense of the distributions of some of the variables in our model

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(samp\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [500 x 5] (S3: tbl_df/tbl/data.frame)
##  $ discipline : chr [1:500] "mechanical" "electrical" "civil" "electrical" ...
##  $ know_eng   : chr [1:500] "friend" "friend" "distant_fam" "none" ...
##  $ persist    : chr [1:500] "yes" "yes" "yes" "no" ...
##  $ gpa        : num [1:500] 3.1 3.37 3.32 2.97 3.26 3.46 3.16 3.18 3.06 3.41 ...
##  $ persist_bin: num [1:500] 1 1 1 0 1 0 1 1 1 1 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(samp\_df}\SpecialCharTok{$}\NormalTok{persist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  no yes 
##  85 415
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{describe}\NormalTok{(samp\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in describe(samp_df): NAs introduced by coercion

## Warning in describe(samp_df): NAs introduced by coercion

## Warning in describe(samp_df): NAs introduced by coercion
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf
\end{verbatim}

\begin{verbatim}
##             vars   n mean   sd median trimmed  mad  min  max range  skew
## discipline*    1 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## know_eng*      2 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## persist*       3 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## gpa            4 500 3.02 0.31   3.02    3.02 0.31 2.02 4.09  2.07 -0.05
## persist_bin    5 500 0.83 0.38   1.00    0.91 0.00 0.00 1.00  1.00 -1.75
##             kurtosis   se
## discipline*       NA   NA
## know_eng*         NA   NA
## persist*          NA   NA
## gpa             0.21 0.01
## persist_bin     1.07 0.02
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(samp\_df}\SpecialCharTok{$}\NormalTok{discipline)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      civil electrical mechanical    systems 
##        128        176        147         49
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{xtabs}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ discipline }\SpecialCharTok{+}\NormalTok{ persist\_bin, }\AttributeTok{data =}\NormalTok{ samp\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             persist_bin
## discipline     0   1
##   civil       23 105
##   electrical  29 147
##   mechanical  23 124
##   systems     10  39
\end{verbatim}

Third, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(persist\_bin }\SpecialCharTok{\textasciitilde{}}\NormalTok{ discipline }\SpecialCharTok{+}\NormalTok{ know\_eng }\SpecialCharTok{+}\NormalTok{ gpa, }\AttributeTok{data =}\NormalTok{ samp\_df, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{())}
\FunctionTok{summary}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1661   0.4728   0.6094   0.6462   0.8378  
## 
## Coefficients:
##                        Estimate Std. Error z value Pr(>|z|)  
## (Intercept)            0.802358   1.174157   0.683   0.4944  
## disciplineelectrical   0.110177   0.309131   0.356   0.7215  
## disciplinemechanical   0.158249   0.325697   0.486   0.6271  
## disciplinesystems     -0.101610   0.426971  -0.238   0.8119  
## know_engfriend         0.571152   0.329111   1.735   0.0827 .
## know_engimmediate_fam  0.004592   0.313112   0.015   0.9883  
## know_engnone          -0.345766   0.366554  -0.943   0.3455  
## gpa                    0.206253   0.383967   0.537   0.5912  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 455.89  on 499  degrees of freedom
## Residual deviance: 449.32  on 492  degrees of freedom
## AIC: 465.32
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tidy}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 5
##   term                  estimate std.error statistic p.value
##   <chr>                    <dbl>     <dbl>     <dbl>   <dbl>
## 1 (Intercept)            0.802       1.17     0.683   0.494 
## 2 disciplineelectrical   0.110       0.309    0.356   0.722 
## 3 disciplinemechanical   0.158       0.326    0.486   0.627 
## 4 disciplinesystems     -0.102       0.427   -0.238   0.812 
## 5 know_engfriend         0.571       0.329    1.74    0.0827
## 6 know_engimmediate_fam  0.00459     0.313    0.0147  0.988 
## 7 know_engnone          -0.346       0.367   -0.943   0.346 
## 8 gpa                    0.206       0.384    0.537   0.591
\end{verbatim}

Since we generated the data without any relationships between the predictors and the binary outcome, we do not expect any of the predictor variables to be statistically significant. Sometimes there will be a significant predictor, but that emphasizes the idea p values are not necessarily the most reliable indicator of importance.

\hypertarget{round-2---systematic-varation-in-outcomes-as-a-function-of-discipline}{%
\section{Round 2 - Systematic varation in outcomes as a function of discipline}\label{round-2---systematic-varation-in-outcomes-as-a-function-of-discipline}}

Now, to introduce some systematic variation, we will change the probabilities of persistence (the outcome variable we are modeling) as a function of major but not as a function of the other two predictors

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{disciplines }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"civil"}\NormalTok{, }\StringTok{"mechanical"}\NormalTok{, }\StringTok{"electrical"}\NormalTok{, }\StringTok{"systems"}\NormalTok{)}
\NormalTok{disciplines\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.35}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}


\NormalTok{know\_engineer }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"immediate\_fam"}\NormalTok{, }\StringTok{"distant\_fam"}\NormalTok{, }\StringTok{"friend"}\NormalTok{, }\StringTok{"none"}\NormalTok{)}
\NormalTok{know\_engineer\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We generate the actual data here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{5000}

\NormalTok{disc\_samp\_2 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ disciplines, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ disciplines\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{know\_samp\_2 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ know\_engineer, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ know\_engineer\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#pers\_samp\_2 \textless{}{-} sample(x = persistence, size = samp\_size, prob = persistence\_prob, replace = TRUE)}
\end{Highlighting}
\end{Shaded}

Now we will combine our data into one dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{discipline =}\NormalTok{ disc\_samp\_2,}
                  \AttributeTok{know\_eng =}\NormalTok{ know\_samp\_2,}
                  \AttributeTok{gpa =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{3}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.3}\NormalTok{), }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now we want to have some different outcomes whose probabilities vary by discipline. We'll create a new column called persist\_prob that describes the probability of persisting from year one to year two (e.g., 0.6 means there is a 0.6 prob of a student persisting)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_2 }\OtherTok{\textless{}{-}}\NormalTok{ samp\_df\_2 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{persist\_prob =} \FunctionTok{case\_when}\NormalTok{(discipline }\SpecialCharTok{==} \StringTok{"civil"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.6}\NormalTok{,}
\NormalTok{                             discipline }\SpecialCharTok{==} \StringTok{"mechanical"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.7}\NormalTok{,}
\NormalTok{                             discipline }\SpecialCharTok{==} \StringTok{"electrical"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.8}\NormalTok{,}
\NormalTok{                             discipline }\SpecialCharTok{==} \StringTok{"systems"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We will create a vector that samples depending on the value of the persistence probability at that index. That value varies depending on the discipline for that student at that index value in the vector.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{persist\_outcome }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ samp\_df\_2}\SpecialCharTok{$}\NormalTok{persist\_prob, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ .x))}
\end{Highlighting}
\end{Shaded}

Now we add that persistence outcome column to our dataframe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_2}\SpecialCharTok{$}\NormalTok{persist\_bin }\OtherTok{\textless{}{-}}\NormalTok{ persist\_outcome}
\end{Highlighting}
\end{Shaded}

Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(samp\_df\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [5,000 x 5] (S3: tbl_df/tbl/data.frame)
##  $ discipline  : chr [1:5000] "systems" "civil" "electrical" "civil" ...
##  $ know_eng    : chr [1:5000] "friend" "distant_fam" "immediate_fam" "distant_fam" ...
##  $ gpa         : num [1:5000] 2.51 3.41 3.11 3.43 2.78 2.95 3.28 2.94 2.9 2.67 ...
##  $ persist_prob: num [1:5000] 0.9 0.6 0.8 0.6 0.8 0.7 0.7 0.6 0.7 0.7 ...
##  $ persist_bin : num [1:5000] 1 0 1 0 0 1 1 1 0 1 ...
\end{verbatim}

Let's check on the distribution of persistence by major. xtabs() is a function that creates a contingency table (more on that in 2 weeks)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{xtabs}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ persist\_bin }\SpecialCharTok{+}\NormalTok{ discipline, }\AttributeTok{data=}\NormalTok{samp\_df\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            discipline
## persist_bin civil electrical mechanical systems
##           0   486        353        497      40
##           1   745       1399       1001     479
\end{verbatim}

Or we can use \texttt{describe()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{describe}\NormalTok{(samp\_df\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in describe(samp_df_2): NAs introduced by coercion

## Warning in describe(samp_df_2): NAs introduced by coercion
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf
\end{verbatim}

\begin{verbatim}
##              vars    n mean   sd median trimmed  mad  min  max range  skew
## discipline*     1 5000  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## know_eng*       2 5000  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## gpa             3 5000 3.00 0.30    3.0    3.00 0.30 1.65 4.11  2.46 -0.01
## persist_prob    4 5000 0.73 0.10    0.7    0.73 0.15 0.60 0.90  0.30  0.06
## persist_bin     5 5000 0.72 0.45    1.0    0.78 0.00 0.00 1.00  1.00 -1.01
##              kurtosis   se
## discipline*        NA   NA
## know_eng*          NA   NA
## gpa              0.23 0.00
## persist_prob    -1.02 0.00
## persist_bin     -0.99 0.01
\end{verbatim}

Or even use \texttt{table()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(samp\_df\_2}\SpecialCharTok{$}\NormalTok{discipline)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      civil electrical mechanical    systems 
##       1231       1752       1498        519
\end{verbatim}

Now, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_2 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(persist\_bin }\SpecialCharTok{\textasciitilde{}}\NormalTok{ discipline }\SpecialCharTok{+}\NormalTok{ know\_eng }\SpecialCharTok{+}\NormalTok{ gpa, }\AttributeTok{data =}\NormalTok{ samp\_df\_2, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

And examine the model output with either \texttt{summary()}\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(model\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df_2)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3096  -1.3462   0.6673   0.8955   1.0749  
## 
## Coefficients:
##                         Estimate Std. Error z value Pr(>|z|)    
## (Intercept)            0.8906195  0.3302760   2.697 0.007005 ** 
## disciplineelectrical   0.9502611  0.0834057  11.393  < 2e-16 ***
## disciplinemechanical   0.2710469  0.0801181   3.383 0.000717 ***
## disciplinesystems      2.0517523  0.1746544  11.748  < 2e-16 ***
## know_engfriend         0.0005848  0.0785944   0.007 0.994064    
## know_engimmediate_fam -0.0946710  0.0890747  -1.063 0.287860    
## know_engnone          -0.0657999  0.1150084  -0.572 0.567233    
## gpa                   -0.1454997  0.1070743  -1.359 0.174189    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 5883.6  on 4999  degrees of freedom
## Residual deviance: 5594.5  on 4992  degrees of freedom
## AIC: 5610.5
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\ldots or \texttt{tidy()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tidy}\NormalTok{(model\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 5
##   term                   estimate std.error statistic  p.value
##   <chr>                     <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)            0.891       0.330    2.70    7.01e- 3
## 2 disciplineelectrical   0.950       0.0834  11.4     4.52e-30
## 3 disciplinemechanical   0.271       0.0801   3.38    7.17e- 4
## 4 disciplinesystems      2.05        0.175   11.7     7.27e-32
## 5 know_engfriend         0.000585    0.0786   0.00744 9.94e- 1
## 6 know_engimmediate_fam -0.0947      0.0891  -1.06    2.88e- 1
## 7 know_engnone          -0.0658      0.115   -0.572   5.67e- 1
## 8 gpa                   -0.145       0.107   -1.36    1.74e- 1
\end{verbatim}

\hypertarget{round-3---systematic-varation-in-outcomes-as-a-function-of-discipline-and-gpa}{%
\section{Round 3 - Systematic varation in outcomes as a function of discipline and gpa}\label{round-3---systematic-varation-in-outcomes-as-a-function-of-discipline-and-gpa}}

Now, to introduce some systematic variation, we will change the probabilities of persistence (the outcome variable we are modeling) as a function of major and gpa but not as a function of knowing an engineer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{disciplines }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"civil"}\NormalTok{, }\StringTok{"mechanical"}\NormalTok{, }\StringTok{"electrical"}\NormalTok{, }\StringTok{"systems"}\NormalTok{)}
\NormalTok{disciplines\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.35}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}

\NormalTok{know\_engineer }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"immediate\_fam"}\NormalTok{, }\StringTok{"distant\_fam"}\NormalTok{, }\StringTok{"friend"}\NormalTok{, }\StringTok{"none"}\NormalTok{)}
\NormalTok{know\_engineer\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Simulate the dataf or disciplines, knowing an engineer, and the persistence outcome

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{500}

\NormalTok{disc\_samp\_3 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ disciplines, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ disciplines\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{know\_samp\_3 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ know\_engineer, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ know\_engineer\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{pers\_samp\_3 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ persistence, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ persistence\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

And combine all the generated data into one dataframe with \texttt{tibble()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_3 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{discipline =}\NormalTok{ disc\_samp\_3,}
                  \AttributeTok{know\_eng =}\NormalTok{ know\_samp\_3,}
                  \AttributeTok{persist =}\NormalTok{ pers\_samp\_3)}
\end{Highlighting}
\end{Shaded}

Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting out analysis

To run the logistic regression, we need our outcome coded as 0/1, not no/yes to address this, we add in a new binary column for the persistence variable (coding ``yes'' as 1 and ``no'' as 0)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_3 }\OtherTok{\textless{}{-}}\NormalTok{ samp\_df\_3 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{persist\_bin =} \FunctionTok{case\_when}\NormalTok{(persist }\SpecialCharTok{==} \StringTok{"yes"} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
\NormalTok{                                 persist }\SpecialCharTok{==} \StringTok{"no"} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now, since we want to look at the potential effect of gpa on persistence, we create a bookkeeping column for gpa\_mean for students who do and do not persist to year two.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_3 }\OtherTok{\textless{}{-}}\NormalTok{ samp\_df\_3 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gpa\_mean =} \FunctionTok{case\_when}\NormalTok{(persist }\SpecialCharTok{==} \StringTok{"yes"} \SpecialCharTok{\textasciitilde{}} \FloatTok{3.4}\NormalTok{,}
\NormalTok{                              persist }\SpecialCharTok{==} \StringTok{"no"} \SpecialCharTok{\textasciitilde{}} \FloatTok{3.0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Simulate the gpa data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gpa\_vec }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ samp\_df\_3}\SpecialCharTok{$}\NormalTok{gpa\_mean, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ .x, }\AttributeTok{sd =}\NormalTok{ .}\DecValTok{2}\NormalTok{)), }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Add the simulated data back to our data frame

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_3}\SpecialCharTok{$}\NormalTok{gpa }\OtherTok{\textless{}{-}}\NormalTok{ gpa\_vec}
\end{Highlighting}
\end{Shaded}

Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis

Check the structure of the dataframe to make sure it looks as expected

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(samp\_df\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [500 x 6] (S3: tbl_df/tbl/data.frame)
##  $ discipline : chr [1:500] "mechanical" "civil" "mechanical" "mechanical" ...
##  $ know_eng   : chr [1:500] "distant_fam" "immediate_fam" "distant_fam" "friend" ...
##  $ persist    : chr [1:500] "yes" "no" "yes" "yes" ...
##  $ persist_bin: num [1:500] 1 0 1 1 1 1 1 1 1 0 ...
##  $ gpa_mean   : num [1:500] 3.4 3 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3 ...
##  $ gpa        : num [1:500] 3.39 2.98 3.52 3.47 3.15 3.02 3.59 3.61 3.34 2.9 ...
\end{verbatim}

Let's check on the distribution of persistence by major. xtabs() is a function that creates a contingency table (more on that in 2 weeks)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{xtabs}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ persist\_bin }\SpecialCharTok{+}\NormalTok{ discipline, }\AttributeTok{data=}\NormalTok{samp\_df\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            discipline
## persist_bin civil electrical mechanical systems
##           0    31         24         34       5
##           1    90        120        145      51
\end{verbatim}

\ldots or with \texttt{describe()}\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{describe}\NormalTok{(samp\_df\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in describe(samp_df_3): NAs introduced by coercion

## Warning in describe(samp_df_3): NAs introduced by coercion

## Warning in describe(samp_df_3): NAs introduced by coercion
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf
\end{verbatim}

\begin{verbatim}
##             vars   n mean   sd median trimmed  mad  min  max range  skew
## discipline*    1 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## know_eng*      2 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## persist*       3 500  NaN   NA     NA     NaN   NA  Inf -Inf  -Inf    NA
## persist_bin    4 500 0.81 0.39   1.00    0.89 0.00 0.00 1.00  1.00 -1.59
## gpa_mean       5 500 3.32 0.16   3.40    3.36 0.00 3.00 3.40  0.40 -1.59
## gpa            6 500 3.32 0.25   3.33    3.33 0.24 2.61 4.06  1.45 -0.26
##             kurtosis   se
## discipline*       NA   NA
## know_eng*         NA   NA
## persist*          NA   NA
## persist_bin     0.54 0.02
## gpa_mean        0.54 0.01
## gpa             0.01 0.01
\end{verbatim}

\ldots or with \texttt{table()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(samp\_df\_3}\SpecialCharTok{$}\NormalTok{discipline)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      civil electrical mechanical    systems 
##        121        144        179         56
\end{verbatim}

Check the distribution of the gpa values by discipline, just to make sure

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_3 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gpa, }\AttributeTok{fill =}\NormalTok{ discipline)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-176-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# be sure to put alpha before position}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_3 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gpa, }\AttributeTok{fill =}\NormalTok{ persist)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-177-1.pdf}

Now, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_3 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(persist\_bin }\SpecialCharTok{\textasciitilde{}}\NormalTok{ discipline }\SpecialCharTok{+}\NormalTok{ know\_eng }\SpecialCharTok{+}\NormalTok{ gpa, }\AttributeTok{data =}\NormalTok{ samp\_df\_3, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

And examine the results with \texttt{summary()} or \texttt{tidy()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(model\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df_3)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.71674   0.05747   0.18177   0.41143   2.22106  
## 
## Coefficients:
##                         Estimate Std. Error z value Pr(>|z|)    
## (Intercept)           -32.297462   3.419792  -9.444   <2e-16 ***
## disciplineelectrical    0.007722   0.439815   0.018    0.986    
## disciplinemechanical    0.110320   0.403782   0.273    0.785    
## disciplinesystems       1.075912   0.656979   1.638    0.101    
## know_engfriend          0.320038   0.399080   0.802    0.423    
## know_engimmediate_fam  -0.021159   0.428994  -0.049    0.961    
## know_engnone            0.332457   0.583245   0.570    0.569    
## gpa                    10.458703   1.083815   9.650   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 483.31  on 499  degrees of freedom
## Residual deviance: 258.80  on 492  degrees of freedom
## AIC: 274.8
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tidy}\NormalTok{(model\_3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 5
##   term                   estimate std.error statistic  p.value
##   <chr>                     <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)           -32.3         3.42    -9.44   3.58e-21
## 2 disciplineelectrical    0.00772     0.440    0.0176 9.86e- 1
## 3 disciplinemechanical    0.110       0.404    0.273  7.85e- 1
## 4 disciplinesystems       1.08        0.657    1.64   1.01e- 1
## 5 know_engfriend          0.320       0.399    0.802  4.23e- 1
## 6 know_engimmediate_fam  -0.0212      0.429   -0.0493 9.61e- 1
## 7 know_engnone            0.332       0.583    0.570  5.69e- 1
## 8 gpa                    10.5         1.08     9.65   4.92e-22
\end{verbatim}

\hypertarget{round-4---gpa-and-persistence-vary-by-discipline}{%
\section{Round 4 - GPA and persistence vary by discipline}\label{round-4---gpa-and-persistence-vary-by-discipline}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{disciplines }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"civil"}\NormalTok{, }\StringTok{"mechanical"}\NormalTok{, }\StringTok{"electrical"}\NormalTok{, }\StringTok{"systems"}\NormalTok{)}
\NormalTok{disciplines\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.35}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}

\NormalTok{know\_engineer }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"immediate\_fam"}\NormalTok{, }\StringTok{"distant\_fam"}\NormalTok{, }\StringTok{"friend"}\NormalTok{, }\StringTok{"none"}\NormalTok{)}
\NormalTok{know\_engineer\_prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Simulate the data for disciplines, knowing an engineer, and the persistence outcome

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{500}

\NormalTok{student\_id }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(samp\_size)}
\NormalTok{disc\_samp\_4 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ disciplines, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ disciplines\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{know\_samp\_4 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ know\_engineer, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ know\_engineer\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{pers\_samp\_4 }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ persistence, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{prob =}\NormalTok{ persistence\_prob, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Combine these all together in \texttt{tibble()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_4 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{sid =}\NormalTok{ student\_id,}
                    \AttributeTok{discipline =}\NormalTok{ disc\_samp\_4,}
                    \AttributeTok{know\_eng =}\NormalTok{ know\_samp\_4)}
\end{Highlighting}
\end{Shaded}

Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting out analysis

Start the data analysis for logistic regression here

Now, since we want to look at the potential effect of gpa on persistence, we create a bookkeeping column for gpa\_mean for students who do and do not persist to year two.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_4 }\OtherTok{\textless{}{-}}\NormalTok{ samp\_df\_4 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gpa\_mean =} \FunctionTok{case\_when}\NormalTok{(discipline }\SpecialCharTok{==} \StringTok{"civil"} \SpecialCharTok{\textasciitilde{}} \FloatTok{3.0}\NormalTok{,}
\NormalTok{                              discipline }\SpecialCharTok{==} \StringTok{"electrical"} \SpecialCharTok{\textasciitilde{}} \FloatTok{3.15}\NormalTok{,}
\NormalTok{                              discipline }\SpecialCharTok{==} \StringTok{"mechanical"} \SpecialCharTok{\textasciitilde{}} \FloatTok{3.3}\NormalTok{,}
\NormalTok{                              discipline }\SpecialCharTok{==} \StringTok{"systems"} \SpecialCharTok{\textasciitilde{}} \FloatTok{3.45}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Simulate the gpa data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gpa\_vec }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ samp\_df\_4}\SpecialCharTok{$}\NormalTok{gpa\_mean, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ .x, }\AttributeTok{sd =}\NormalTok{ .}\DecValTok{1}\NormalTok{)), }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Add the simulated data back to our data frame

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_4}\SpecialCharTok{$}\NormalTok{gpa }\OtherTok{\textless{}{-}}\NormalTok{ gpa\_vec}
\end{Highlighting}
\end{Shaded}

We will create a vector that samples depending on the value of the persistence probability at that index.

That value varies depending on the discipline for that student at that index value in the vector.

Now we want to have some different outcomes whose probabilities vary by discipline. We'll create a new column called.

persist\_prob that describes the probability of persisting from year one to year two (e.g., 0.6 means there is a 0.6 prob of a student persisting)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_4 }\OtherTok{\textless{}{-}}\NormalTok{ samp\_df\_4 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{persist\_prob =} \FunctionTok{case\_when}\NormalTok{(discipline }\SpecialCharTok{==} \StringTok{"civil"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.6}\NormalTok{,}
\NormalTok{                                  discipline }\SpecialCharTok{==} \StringTok{"mechanical"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.7}\NormalTok{,}
\NormalTok{                                  discipline }\SpecialCharTok{==} \StringTok{"electrical"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.8}\NormalTok{,}
\NormalTok{                                  discipline }\SpecialCharTok{==} \StringTok{"systems"} \SpecialCharTok{\textasciitilde{}} \FloatTok{0.9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{persist\_outcome }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ samp\_df\_4}\SpecialCharTok{$}\NormalTok{persist\_prob, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ .x))}
\end{Highlighting}
\end{Shaded}

Now we add that persistence outcome column to our dataframe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_4}\SpecialCharTok{$}\NormalTok{persist\_bin }\OtherTok{\textless{}{-}}\NormalTok{ persist\_outcome}
\end{Highlighting}
\end{Shaded}

Up to now, we have simulated the data collection process. This is the point where we would typically be cleaning the data and starting our analysis

Check the structure of the dataframe to make sure it looks as expected.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(samp\_df\_4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [500 x 7] (S3: tbl_df/tbl/data.frame)
##  $ sid         : int [1:500] 1 2 3 4 5 6 7 8 9 10 ...
##  $ discipline  : chr [1:500] "civil" "mechanical" "electrical" "systems" ...
##  $ know_eng    : chr [1:500] "friend" "distant_fam" "distant_fam" "friend" ...
##  $ gpa_mean    : num [1:500] 3 3.3 3.15 3.45 3 3 3.15 3.45 3.15 3.3 ...
##  $ gpa         : num [1:500] 3.04 3.17 3 3.51 3.17 3.04 3.38 3.6 3.1 3.14 ...
##  $ persist_prob: num [1:500] 0.6 0.7 0.8 0.9 0.6 0.6 0.8 0.9 0.8 0.7 ...
##  $ persist_bin : num [1:500] 0 1 1 1 1 0 1 1 1 0 ...
\end{verbatim}

Let's check on the distribution of persistence by major. xtabs() is a function that creates a contingency table (more on that in 2 weeks).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{xtabs}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ persist\_bin }\SpecialCharTok{+}\NormalTok{ discipline, }\AttributeTok{data=}\NormalTok{samp\_df\_4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            discipline
## persist_bin civil electrical mechanical systems
##           0    46         33         47       3
##           1    64        145        118      44
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{describe}\NormalTok{(samp\_df\_4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in describe(samp_df_4): NAs introduced by coercion

## Warning in describe(samp_df_4): NAs introduced by coercion
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf
\end{verbatim}

\begin{verbatim}
## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf

## Warning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf
\end{verbatim}

\begin{verbatim}
##              vars   n   mean     sd median trimmed    mad  min    max  range
## sid             1 500 250.50 144.48 250.50  250.50 185.32 1.00 500.00 499.00
## discipline*     2 500    NaN     NA     NA     NaN     NA  Inf   -Inf   -Inf
## know_eng*       3 500    NaN     NA     NA     NaN     NA  Inf   -Inf   -Inf
## gpa_mean        4 500   3.19   0.14   3.15    3.19   0.22 3.00   3.45   0.45
## gpa             5 500   3.20   0.18   3.20    3.20   0.19 2.74   3.61   0.87
## persist_prob    6 500   0.73   0.09   0.70    0.73   0.15 0.60   0.90   0.30
## persist_bin     7 500   0.74   0.44   1.00    0.80   0.00 0.00   1.00   1.00
##               skew kurtosis   se
## sid           0.00    -1.21 6.46
## discipline*     NA       NA   NA
## know_eng*       NA       NA   NA
## gpa_mean      0.11    -0.87 0.01
## gpa           0.01    -0.46 0.01
## persist_prob  0.04    -0.92 0.00
## persist_bin  -1.10    -0.79 0.02
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(samp\_df\_4}\SpecialCharTok{$}\NormalTok{discipline)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      civil electrical mechanical    systems 
##        110        178        165         47
\end{verbatim}

Check the distribution of the gpa values by discipline, just to make sure.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_4 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gpa, }\AttributeTok{fill =}\NormalTok{ discipline)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-193-1.pdf}

\begin{itemize}
\tightlist
\item
  be sure to put alpha before position
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df\_4 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gpa, }\AttributeTok{fill =} \FunctionTok{as\_factor}\NormalTok{(persist\_bin))) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-194-1.pdf}

Now, model the outcome (persistence) as a function of three predictor variables (discipline, knowing an engineering, and gpa)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_4 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(persist\_bin }\SpecialCharTok{\textasciitilde{}}\NormalTok{ discipline }\SpecialCharTok{+}\NormalTok{ know\_eng }\SpecialCharTok{+}\NormalTok{ gpa, }\AttributeTok{data =}\NormalTok{ samp\_df\_4, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{())}
\FunctionTok{summary}\NormalTok{(model\_4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = persist_bin ~ discipline + know_eng + gpa, family = binomial(), 
##     data = samp_df_4)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4476  -1.2197   0.6448   0.8259   1.1700  
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(>|z|)    
## (Intercept)            -0.5614     2.9799  -0.188 0.850568    
## disciplineelectrical    1.0919     0.3176   3.438 0.000586 ***
## disciplinemechanical    0.5202     0.4033   1.290 0.197078    
## disciplinesystems       2.2443     0.7931   2.830 0.004660 ** 
## know_engfriend         -0.2586     0.2568  -1.007 0.313871    
## know_engimmediate_fam  -0.4132     0.2885  -1.432 0.152023    
## know_engnone           -0.1745     0.3881  -0.450 0.653007    
## gpa                     0.3543     0.9955   0.356 0.721925    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 570.95  on 499  degrees of freedom
## Residual deviance: 537.38  on 492  degrees of freedom
## AIC: 553.38
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tidy}\NormalTok{(model\_4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 5
##   term                  estimate std.error statistic  p.value
##   <chr>                    <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)             -0.561     2.98     -0.188 0.851   
## 2 disciplineelectrical     1.09      0.318     3.44  0.000586
## 3 disciplinemechanical     0.520     0.403     1.29  0.197   
## 4 disciplinesystems        2.24      0.793     2.83  0.00466 
## 5 know_engfriend          -0.259     0.257    -1.01  0.314   
## 6 know_engimmediate_fam   -0.413     0.288    -1.43  0.152   
## 7 know_engnone            -0.175     0.388    -0.450 0.653   
## 8 gpa                      0.354     0.996     0.356 0.722
\end{verbatim}

\hypertarget{interlude-looking-at-poisson-distribution}{%
\subsection{Interlude looking at poisson distribution}\label{interlude-looking-at-poisson-distribution}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10000}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}


\NormalTok{x\_samp\_5 }\OtherTok{\textless{}{-}} \FunctionTok{rpois}\NormalTok{(n, }\AttributeTok{lambda =} \DecValTok{5}\NormalTok{)}
\FunctionTok{hist}\NormalTok{(x\_samp\_5)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-196-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_samp\_10 }\OtherTok{\textless{}{-}} \FunctionTok{rpois}\NormalTok{(n, }\AttributeTok{lambda =} \DecValTok{10}\NormalTok{)}
\FunctionTok{hist}\NormalTok{(x\_samp\_10)}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-197-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{param\_vect }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{), }\AttributeTok{each =}\NormalTok{ n)}
\NormalTok{samp\_vect }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ param\_vect, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{rpois}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{ .x))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{param\_val =}\NormalTok{ param\_vect,}
                  \AttributeTok{sample\_val =}\NormalTok{ samp\_vect)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sample\_val)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(param\_val }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-200-1.pdf}

\hypertarget{week-8-comparing-two-means-t-tests}{%
\chapter{Week 8: Comparing two means (t-tests)}\label{week-8-comparing-two-means-t-tests}}

This week we focus on comparing two means. This can be the means of an outcome variable collected in two discrete groups (e.g., first-year and second-year students) or the same group across two time points (e.g., pre-test and post-test).

The following contains a number of demos to illustrate how and when we would use t-tests.

\hypertarget{demo-1---comparing-salary-data-for-chemical-engineering-and-environmental-engineering}{%
\section{Demo 1 - Comparing salary data for chemical engineering and environmental engineering}\label{demo-1---comparing-salary-data-for-chemical-engineering-and-environmental-engineering}}

First, let's generate some data so that we know the underlying data-generating process that we use statistical tests to characterize.

We'll have a sample of 100 participants.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{student\_id }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(N)}

\NormalTok{group\_size }\OtherTok{\textless{}{-}}\NormalTok{ N}\SpecialCharTok{/}\DecValTok{2}

\NormalTok{chem\_eng\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{id =} \FunctionTok{seq}\NormalTok{(group\_size),}
                      \AttributeTok{salary =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ group\_size, }\AttributeTok{mean =} \DecValTok{75000}\NormalTok{, }\AttributeTok{sd =} \DecValTok{3000}\NormalTok{), }\DecValTok{2}\NormalTok{),}
                      \AttributeTok{discipline =} \StringTok{"chemical"}\NormalTok{)}
\NormalTok{chem\_eng\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{ salary)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-202-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{env\_eng\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{id =} \FunctionTok{seq}\NormalTok{(group\_size),}
                      \AttributeTok{salary =} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ group\_size, }\AttributeTok{mean =} \DecValTok{65000}\NormalTok{, }\AttributeTok{sd =} \DecValTok{4000}\NormalTok{), }\DecValTok{2}\NormalTok{),}
                      \AttributeTok{discipline =} \StringTok{"environmental"}\NormalTok{)}
\NormalTok{env\_eng\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{ salary)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-202-2.pdf}

Combine the two disciplinary dataframes together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{salary\_comb\_long }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(chem\_eng\_df, env\_eng\_df)}



\NormalTok{salary\_comb\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ salary, }\AttributeTok{fill =}\NormalTok{ discipline)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-203-1.pdf}

Independent samples t-test using the long format approach (NB: the long format is a good practice - it keeps the grouping variable in one column and the continuous outcome variable in a separate column).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{salary\_test }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ discipline, }\AttributeTok{data =}\NormalTok{ salary\_comb\_long, }\AttributeTok{paired =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{salary\_test}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  salary by discipline
## t = 14.982, df = 95.279, p-value < 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   9159.492 11957.530
## sample estimates:
##      mean in group chemical mean in group environmental 
##                    75218.01                    64659.50
\end{verbatim}

Use the \texttt{tidy()} function from the broom package to generate a tibble with the output of the \texttt{t.test()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tidy}\NormalTok{(salary\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 10
##   estimate estimate1 estimate2 statistic  p.value parameter conf.low conf.high
##      <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>    <dbl>     <dbl>
## 1   10559.    75218.    64659.      15.0 8.65e-27      95.3    9159.    11958.
## # ... with 2 more variables: method <chr>, alternative <chr>
\end{verbatim}

Remember that a t-test is similar to a linear regression model with a binary predictor variable and continuous outcome variable.

In this case, the model is something like \(salary_i = \beta_0 + \beta_1 * discipline_i\)

Notice how the value of the t-statistic (t value in the linear model summary table) is close to the t value calculated with the t-test!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{salary\_lm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(salary }\SpecialCharTok{\textasciitilde{}}\NormalTok{ discipline, }\AttributeTok{data =}\NormalTok{ salary\_comb\_long)}
\FunctionTok{summary}\NormalTok{(salary\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = salary ~ discipline, data = salary_comb_long)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9496.0 -2100.7   239.4  2288.4  9202.1 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(>|t|)    
## (Intercept)              75218.0      498.3  150.94   <2e-16 ***
## disciplineenvironmental -10558.5      704.7  -14.98   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3524 on 98 degrees of freedom
## Multiple R-squared:  0.6961, Adjusted R-squared:  0.693 
## F-statistic: 224.5 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

Calculate the effect size of discipline on salary.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(t }\OtherTok{\textless{}{-}}\NormalTok{ salary\_test}\SpecialCharTok{$}\NormalTok{statistic[[}\DecValTok{1}\NormalTok{]]) }\CommentTok{\# wrapping this in parentheses prints out the value of t at the same time that it stores the value of t}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 14.98229
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(df }\OtherTok{\textless{}{-}}\NormalTok{ salary\_test}\SpecialCharTok{$}\NormalTok{parameter[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 95.27933
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(r }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(t}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{/}\NormalTok{(t}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ df)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8378649
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(r,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.838
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7020177
\end{verbatim}

We now have the results of an independent samples t-test and the effect size.

Think about what would happen if we changed the sample size or if we changed the underlying distributions that we used to generate the salary data.

We can also run the t-test using a wide format approach

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{salary\_comb\_wide }\OtherTok{\textless{}{-}}\NormalTok{ salary\_comb\_long }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ discipline, }\AttributeTok{values\_from =}\NormalTok{ salary)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{salary\_test\_2 }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(salary\_comb\_wide}\SpecialCharTok{$}\NormalTok{chemical, salary\_comb\_wide}\SpecialCharTok{$}\NormalTok{environmental, }\AttributeTok{paired =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{salary\_test\_2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  salary_comb_wide$chemical and salary_comb_wide$environmental
## t = 14.982, df = 95.279, p-value < 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   9159.492 11957.530
## sample estimates:
## mean of x mean of y 
##  75218.01  64659.50
\end{verbatim}

\hypertarget{demo-2---student-sat-scores}{%
\section{Demo 2 - Student SAT scores}\label{demo-2---student-sat-scores}}

Let's try a second example. This time we'll simulate data we might have where a dependent samples t-test would be appropriate.

We are going to simulate the scenario where we have student SAT scores on both the verbal section and math section.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{1000}

\NormalTok{student\_id }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(samp\_size)}
\NormalTok{sat\_verbal }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{620}\NormalTok{, }\AttributeTok{sd =} \DecValTok{55}\NormalTok{), }\DecValTok{0}\NormalTok{)}
\NormalTok{sat\_math }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{700}\NormalTok{, }\AttributeTok{sd =} \DecValTok{40}\NormalTok{), }\DecValTok{0}\NormalTok{)}

\NormalTok{sat\_verbal\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_verbal, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}
\NormalTok{sat\_math\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_math, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}

\NormalTok{sat\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{id =}\NormalTok{ student\_id,}
                 \AttributeTok{verbal =}\NormalTok{ sat\_verbal\_capped,}
                 \AttributeTok{math =}\NormalTok{ sat\_math\_capped)}

\NormalTok{sat\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Verbal Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Verbal Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-212-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Math Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Math Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-213-1.pdf}

Alternatively, we could plot these together by either making a long data set or just overlaying histograms and modifying transparency (the alpha parameter).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math, }\AttributeTok{fill =} \StringTok{"red"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Scores Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"SAT Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal, }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{name =} \StringTok{"Category"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"verbal"}\NormalTok{, }\StringTok{"math"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-214-1.pdf}

Looking at the histogram, we can see that there appears to be a systematic difference in the scores. Running a t-test will help us see if that initial observation is statistically correct.

Since we will be comparing verbal and math scores for each student, this will be a dependent samples (or paired samples) t-test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_t\_test }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(sat\_df}\SpecialCharTok{$}\NormalTok{verbal, sat\_df}\SpecialCharTok{$}\NormalTok{math, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# don\textquotesingle{}t forget to add: paired = TRUE}
\CommentTok{\# now look at the results}
\NormalTok{sat\_t\_test}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  sat_df$verbal and sat_df$math
## t = -38.699, df = 999, p-value < 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -84.23739 -76.10661
## sample estimates:
## mean of the differences 
##                 -80.172
\end{verbatim}

We see there was a statistically significant difference, but now let's try changing the distributions and see what happens.

First, we'll change make the means very close together and see how sensitive the test is to that

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{1000}

\NormalTok{student\_id\_2 }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(samp\_size)}
\NormalTok{sat\_verbal\_2 }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{690}\NormalTok{, }\AttributeTok{sd =} \DecValTok{55}\NormalTok{), }\DecValTok{0}\NormalTok{)}
\NormalTok{sat\_math\_2 }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{700}\NormalTok{, }\AttributeTok{sd =} \DecValTok{40}\NormalTok{), }\DecValTok{0}\NormalTok{)}

\CommentTok{\# let\textquotesingle{}s cap the simulated scores at 800}
\NormalTok{sat\_verbal\_2\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_verbal\_2, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}
\NormalTok{sat\_math\_2\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_math\_2, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}


\NormalTok{sat\_df\_2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{id =}\NormalTok{ student\_id,}
                 \AttributeTok{verbal =}\NormalTok{ sat\_verbal\_2\_capped,}
                 \AttributeTok{math =}\NormalTok{ sat\_math\_2\_capped)}

\NormalTok{sat\_df\_2 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Verbal Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Verbal Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-216-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df\_2 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Math Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Math Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-217-1.pdf}

Alternatively, we could plot these together by either making a long data set or just overlaying histograms and modifying transparency (the alpha parameter).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df\_2 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math, }\AttributeTok{fill =} \StringTok{"red"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Scores Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"SAT Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal, }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{name =} \StringTok{"Category"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"verbal"}\NormalTok{, }\StringTok{"math"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-218-1.pdf}

Looking at the histogram, we can see that there appears to be a systematic difference in the scores. Running a t-test will help us see if that initial observation is statistically correct.

Since we will be comparing verbal and math scores for each student, this will be a dependent samples (or paired samples) t-test

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_t\_test\_2 }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(sat\_df\_2}\SpecialCharTok{$}\NormalTok{verbal, sat\_df\_2}\SpecialCharTok{$}\NormalTok{math, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# don\textquotesingle{}t forget to add: paired = TRUE}
\CommentTok{\# now look at the results}
\NormalTok{sat\_t\_test\_2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  sat_df_2$verbal and sat_df_2$math
## t = -5.7463, df = 999, p-value = 1.21e-08
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -15.724989  -7.719011
## sample estimates:
## mean of the differences 
##                 -11.722
\end{verbatim}

Let's try a third test - this time we'll change the sample size to be 25 students rather than 1000

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{25}

\NormalTok{student\_id\_3 }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(samp\_size)}
\NormalTok{sat\_verbal\_3 }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{690}\NormalTok{, }\AttributeTok{sd =} \DecValTok{55}\NormalTok{), }\DecValTok{0}\NormalTok{)}
\NormalTok{sat\_math\_3 }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{700}\NormalTok{, }\AttributeTok{sd =} \DecValTok{40}\NormalTok{), }\DecValTok{0}\NormalTok{)}

\CommentTok{\# cap the scores at 800}
\NormalTok{sat\_verbal\_3\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_verbal\_3, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}
\NormalTok{sat\_math\_3\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_math\_3, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}



\NormalTok{sat\_df\_3 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{id =}\NormalTok{ student\_id\_3,}
                 \AttributeTok{verbal =}\NormalTok{ sat\_verbal\_3\_capped,}
                 \AttributeTok{math =}\NormalTok{ sat\_math\_3\_capped)}

\NormalTok{sat\_df\_3 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Verbal Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Verbal Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-220-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df\_3 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Math Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Math Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-220-2.pdf}

Alternatively, we could plot these together by either making a long data set or just overlaying histograms and modifying transparency (the alpha parameter)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df\_3 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math, }\AttributeTok{fill =} \StringTok{"red"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Scores Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"SAT Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal, }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{name =} \StringTok{"Category"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"verbal"}\NormalTok{, }\StringTok{"math"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-221-1.pdf}

Looking at the histogram, we can see that there appears to be a systematic difference in the scores. Running a t-test will help us see if that initial observation is statistically correct.Since we will be comparing verbal and math scores for each student, this will be a dependent samples (or paired samples) t-test

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_t\_test\_3 }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(sat\_df\_3}\SpecialCharTok{$}\NormalTok{verbal, sat\_df\_3}\SpecialCharTok{$}\NormalTok{math, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# don\textquotesingle{}t forget to add: paired = TRUE}
\CommentTok{\# now look at the results}
\NormalTok{sat\_t\_test\_3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  sat_df_3$verbal and sat_df_3$math
## t = -0.14479, df = 24, p-value = 0.8861
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -30.50846  26.50846
## sample estimates:
## mean of the differences 
##                      -2
\end{verbatim}

Now we see that the statistically significant difference is gone. How about if we go back to having a large difference in the means

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp\_size }\OtherTok{\textless{}{-}} \DecValTok{25}

\NormalTok{student\_id\_4 }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(samp\_size)}
\NormalTok{sat\_verbal\_4 }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{620}\NormalTok{, }\AttributeTok{sd =} \DecValTok{55}\NormalTok{), }\DecValTok{0}\NormalTok{)}
\NormalTok{sat\_math\_4 }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ samp\_size, }\AttributeTok{mean =} \DecValTok{700}\NormalTok{, }\AttributeTok{sd =} \DecValTok{40}\NormalTok{), }\DecValTok{0}\NormalTok{)}

\CommentTok{\#cap the scores at 800}
\NormalTok{sat\_verbal\_4\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_verbal\_4, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}
\NormalTok{sat\_math\_4\_capped }\OtherTok{\textless{}{-}} \FunctionTok{modify}\NormalTok{(}\AttributeTok{.x =}\NormalTok{ sat\_math\_4, }\AttributeTok{.f =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{min}\NormalTok{(}\DecValTok{800}\NormalTok{, .x))}


\NormalTok{sat\_df\_4 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{id =}\NormalTok{ student\_id\_4,}
                   \AttributeTok{verbal =}\NormalTok{ sat\_verbal\_4\_capped,}
                   \AttributeTok{math =}\NormalTok{ sat\_math\_4\_capped)}

\CommentTok{\# visualize the distributions of scores}
\NormalTok{sat\_df\_4 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Verbal Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Verbal Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-223-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df\_4 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Math Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Math Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-223-2.pdf}

Alternatively, we could plot these together by either making a long data set or just overlaying histograms and modifying transparency (the alpha parameter)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_df\_4 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ math, }\AttributeTok{fill =} \StringTok{"red"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Simulated SAT Scores Histogram"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"SAT Score"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Count"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ verbal, }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{name =} \StringTok{"Category"}\NormalTok{, }\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"verbal"}\NormalTok{, }\StringTok{"math"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{test_course_notes_files/figure-latex/unnamed-chunk-224-1.pdf}

Looking at the histogram, we can see that there appears to be a systematic difference in the scores. Running a t-test will help us see if that initial observation is statistically correct.
Since we will be comparing verbal and math scores for each student, this will be a dependent samples (or paired samples) t-test

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sat\_t\_test\_4 }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(sat\_df\_4}\SpecialCharTok{$}\NormalTok{math, sat\_df\_4}\SpecialCharTok{$}\NormalTok{verbal, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# don\textquotesingle{}t forget to add: paired = TRUE}
\CommentTok{\# now look at the results}
\NormalTok{sat\_t\_test\_4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  sat_df_4$math and sat_df_4$verbal
## t = 7.1392, df = 24, p-value = 2.226e-07
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   63.8111 115.7089
## sample estimates:
## mean of the differences 
##                   89.76
\end{verbatim}

We should see that the t-test will pick up differences between means if there is a sufficiently large difference.

  \bibliography{book.bib,packages.bib}

\end{document}
